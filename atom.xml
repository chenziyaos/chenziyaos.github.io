<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>非衣</title>
  <subtitle>心静如水</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://iceziyao.github.io/"/>
  <updated>2016-07-09T21:53:35.558Z</updated>
  <id>https://iceziyao.github.io/</id>
  
  <author>
    <name>陈子瑶</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Python的内存管理机制</title>
    <link href="https://iceziyao.github.io/2016/05/21/python01/"/>
    <id>https://iceziyao.github.io/2016/05/21/python01/</id>
    <published>2016-05-20T16:00:00.000Z</published>
    <updated>2016-07-09T21:53:35.558Z</updated>
    
    <content type="html">&lt;h2 id=&quot;python的内存管理分为三个方面：&quot;&gt;&lt;a href=&quot;#python的内存管理分为三个方面：&quot; class=&quot;headerlink&quot; title=&quot;python的内存管理分为三个方面：&quot;&gt;&lt;/a&gt;python的内存管理分为三个方面：&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;em&gt;引用计数&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;垃圾回收&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;内存池机制&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;浅析引用计数&lt;br&gt;python内部使用引用计数，来保持追踪内存中的对象，Python内部记录了对象有多少个引用，即引用计数，当对象被创建时就创建了一个引用计数，当对象不再需要时，这个对象的引用计数为0时，它被垃圾回收。  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;引用计数增加的情况：  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;1.对象被创建：x=4&lt;br&gt;2.另外的别人被创建：y=x&lt;br&gt;3.被作为参数传递给函数：foo(x)&lt;br&gt;4.作为容器对象的一个元素：a=[1,x,’33’]  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;引用计数减少情况  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;1.一个本地引用离开了它的作用域。比如上面的foo(x)函数结束时，x指向的对象引用减1。&lt;br&gt;2.对象的别名被显式的销毁：del x ；或者del y&lt;br&gt;3.对象的一个别名被赋值给其他对象：x=789&lt;br&gt;4.对象从一个窗口对象中移除：myList.remove(x)&lt;br&gt;5.窗口对象本身被销毁：del myList，或者窗口对象本身离开了作用域。  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;如何获取一个变量的引用计数&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
&gt;&gt; import sys
&gt;&gt; x = 1
&gt;&gt; sys.getrefcount(x)
599
&gt;&gt; y = x
&gt;&gt; sys.getrefcount(x)
600
&gt;&gt; del y
&gt;&gt; sys.getrefcount(x)
599
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;垃圾回收&lt;br&gt;python的垃圾回收机制以引用计数为主，标记-清除和分代收集为辅。  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;2.1 引用计数  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;优点：“实时性”，任何内存，一旦没有指向它的引用，就会立即被回收。&lt;br&gt;缺点：&lt;br&gt;(1). 效率底下：引用计数机制带来的计数操作，与引用赋值成正比。频繁的技术操作，会给CPU带来大量消耗。&lt;br&gt;(2). 循环引用：也就是两个对象相互引用，这样的话，两个对象的引用计数永远不会为0，及它们永远不被清除。  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;2.2 标记-清除&lt;br&gt;标记-清除是为了解决循环引用的问题。可以包含其他对象引用的容器对象（比如：list，set，dict，class，instance）都可能产生循环引用。  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;2.2.1 假设&lt;br&gt;如果两个对象的引用计数都为1的话，但仅仅存在它们之间的相互引用，那么，我们可以认为这两个对象的实际引用计数为0.如果我们将这个引用循环去掉，那么它们的实际引用计数才会显现。&lt;br&gt;案例：有循环引用的A,B两个对象，从A出发，因为它有一个对B的引用，则将B的引用计数减1；然后顺着引用达到B，因为B有一个对A的引用，同样将A的引用减1，这样，就完成了循环引用对象间环摘除。&lt;br&gt;问题：如果A,B间没有循环引用，但A引用了B，B没有以用A，贸然的将B计数引用减1，而A没有被回收，这将导致在未来的某个时刻出现一个对B的悬空引用，类似与C的空指针异常。这就要求我们必须在A没有被删除的情况下复原B的引用计数，那么维护引用计数的复杂度将成倍增加。&lt;br&gt;2.2.2 标记-清除的原理&lt;br&gt;原理：&lt;br&gt;我们并不改动真实的引用计数，而是将集合中对象的引用计数复制一份副本，改动该对象引用的副本。对于副本做任何的改动，都不会影响到对象生命走起的维护。&lt;br&gt;这个计数副本的唯一作用是寻找root object集合（该集合中的对象是不能被回收的）。当成功寻找到root object集合之后，首先将现在的内存链表一分为二，一条链表中维护root object集合，成为root链表，而另外一条链表中维护剩下的对象，成为unreachable链表。之所以要剖成两个链表，是基于这样的一种考虑：现在的unreachable可能存在被root链表中的对象，直接或间接引用的对象，这些对象是不能被回收的，一旦在标记的过程中，发现这样的对象，就将其从unreachable链表中移到root链表中；当完成标记后，unreachable链表中剩下的所有对象就是名副其实的垃圾对象了，接下来的垃圾回收只需限制在unreachable链表中即可。&lt;br&gt;效率分析：&lt;br&gt;从垃圾收集机制来看，这种垃圾收集机制所带来的额外操作实际上与系统中总的内存块的数量是相关的，当需要回收的内存块越多时，垃圾检测带来的额外操作就越多，而垃圾回收带来的额外操作就越少；反之，当需回收的内存块越少时，垃圾检测就将比垃圾回收带来更少的额外操作。  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;2.3 分代回收  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;2.3.1 理论：&lt;br&gt;无论使用何种语言开发，无论开发的是何种类型，何种规模的程序，都存在这样一点相同之处。即：一定比例的内存块的生存周期都比较短，通常是几百万条机器指令的时间，而剩下的内存块，起生存周期比较长，甚至会从程序开始一直持续到程序结束。&lt;br&gt;2.3.2 原理：&lt;br&gt;将系统中的所有内存块根据其存活时间划分为不同的集合，每一个集合就成为一个“代”，垃圾收集的频率随着“代”的存活时间的增大而减小。也就是说，活得越长的对象，就越不可能是垃圾，就应该减少对它的垃圾收集频率。那么如何来衡量这个存活时间：通常是利用几次垃圾收集动作来衡量，如果一个对象经过的垃圾收集次数越多，可以得出：该对象存活时间就越长。也就是符合马太福音，存活久的让它继续存活下去。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;内存池机制    &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;3.1 内存分配层次：  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Python的内存机制以金字塔层次：&lt;br&gt;　　   -1，-2层主要有操作系统进行操作，&lt;br&gt;　　第0层是C中的malloc，free等内存分配和释放函数进行操作；&lt;br&gt;　　第1层和第2层是内存池，有Python的接口函数PyMem_Malloc函数实现，当对象小于256K时有该层直接分配内存；&lt;br&gt;　　第3层是最上层，也就是我们对Python对象的直接操作；  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;3.2 原因  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;在 C 中如果频繁的调用 malloc 与 free 时,是会产生性能问题的.再加上频繁的分配与释放小块的内存会产生内存碎片。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;3.3 具现化  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;　　Python提供了对内存的垃圾收集机制，但是它将不用的内存放到内存池而不是返回给操作系统。&lt;br&gt;　　Python中所有小于256个字节的对象都使用pymalloc实现的分配器，而大的对象则使用系统的 malloc。另外Python对象，如整数，浮点数和List，都有其独立的私有内存池，对象间不共享他们的内存池。也就是说如果你分配又释放了大量的整数，用于缓存这些整数的内存就不能再分配给浮点数。&lt;br&gt;　　在Python中，许多时候申请的内存都是小块的内存，这些小块内存在申请后，很快又会被释放，由于这些内存的申请并不是为了创建对象，所以并没有对象一级的内存池机制。这就意味着Python在运行期间会大量地执行malloc和free的操作，频繁地在用户态和核心态之间进行切换，这将严重影响 Python的执行效率。为了加速Python的执行效率，Python引入了一个内存池机制，用于管理对小块内存的申请和释放。这也就是之前提到的 Pymalloc机制。&lt;br&gt;　　Pymalloc 关于释放内存方面，当一个对象的 引用计数变为0时，python就会调用它的析构函数。在析构时，也采用了内存池机制，从内存池来的内存会被归还到内存池中，以避免频繁地释放动作。&lt;br&gt;　　Pymalloc分配一系列256KB的内存块，称之为arena。每个arena分割为4KB大小的内存池Pool，每个Pool再切分为固定大小的Block。在内存分配时，分配给进程的就是这些Blocks。&lt;br&gt;&lt;a href=&quot;http://nodefe.com/implement-of-pymalloc-from-source/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;需要了解Pymalloc的看这篇博文&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ol&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;python的内存管理分为三个方面：&quot;&gt;&lt;a href=&quot;#python的内存管理分为三个方面：&quot; class=&quot;headerlink&quot; title=&quot;python的内存管理分为三个方面：&quot;&gt;&lt;/a&gt;python的内存管理分为三个方面：&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;
    
    </summary>
    
      <category term="python" scheme="https://iceziyao.github.io/categories/python/"/>
    
    
      <category term="python" scheme="https://iceziyao.github.io/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>初探node.js</title>
    <link href="https://iceziyao.github.io/2016/05/06/nodejs/"/>
    <id>https://iceziyao.github.io/2016/05/06/nodejs/</id>
    <published>2016-05-06T13:49:33.000Z</published>
    <updated>2016-07-10T17:39:53.226Z</updated>
    
    <content type="html">&lt;h3 id=&quot;什么是node-js&quot;&gt;&lt;a href=&quot;#什么是node-js&quot; class=&quot;headerlink&quot; title=&quot;什么是node.js&quot;&gt;&lt;/a&gt;什么是node.js&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;node.js != Javascript&lt;br&gt;事实上，Node.js采用C++语言编写而成，是一个Javascript的运行环境。  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Node.js 是构建于Chrome的JavaScript引擎的&lt;br&gt;Google的浏览器Chrome，有一个非常快速的JavaScript引擎，叫做V8。这个JS引擎可以被独立出来，该解释器拥有另一个独特特征；可以下载该引擎并将其嵌入任何 应用程序。Node.js就是建立在V8之上的。这也是为什么Node.js会运行的如此之快。对于开发者来说，有几个好处：&lt;ul&gt;
&lt;li&gt;js完全通用&lt;/li&gt;
&lt;li&gt;v8的发展影响着node.js&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Node.js 不仅仅是一个网页服务器或者平台&lt;br&gt;Node.js 不是以网页为中心的。Node.js 是通用目的的JS运行时，带有很多功能强大的库。其中有一个库提供了 HTTP/HTTPS 的实现。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Node.js是面向对象的&lt;br&gt;Node.js的实质就是用Javascript的代码规范通过C++进行了实现和封装。一般在前端用js时，无非是ajax以及特效，仅仅针对一个页面。所以，不用面向对象也可以完成，但在后台，我们常用一些代码，所以进行封装，等用的时候新建一个对象。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;node.js能做什么？&lt;br&gt;正如 JavaScript 为客户端而生，Node.js 为网络而生。Node.js 能做的远不止开发一个网站那么简单，使用 Node.js，你可以轻松地开发：  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt; 具有复杂逻辑的网站；&lt;br&gt; 基于社交网络的大规模 Web 应用；&lt;br&gt; Web Socket 服务器；&lt;br&gt; TCP/UDP 套接字应用程序；&lt;br&gt; 命令行工具；&lt;br&gt; 交互式终端程序；&lt;br&gt; 带有图形用户界面的本地应用程序；&lt;br&gt; 单元测试工具；&lt;br&gt; 客户端 JavaScript 编译器。  &lt;/p&gt;
&lt;p&gt;Node.js 内建了 HTTP 服务器支持，也就是说你可以轻而易举地实现一个网站和服务器的组合。这和 PHP、Perl 不一样，因为在使用 PHP 的时候，必须先搭建一个 Apache 之类的HTTP 服务器，然后通过 HTTP 服务器的模块加载或 CGI 调用，才能将 PHP 脚本的执行结果呈现给用户。而当你使用 Node.js 时，不用额外搭建一个 HTTP 服务器，因为 Node.js 本身就内建了一个。这个服务器不仅可以用来调试代码，而且它本身就可以部署到产品环境，它的性能足以满足要求。&lt;br&gt;Node.js 还可以部署到非网络应用的环境下，比如一个命令行工具  。Node.js 还可以调用C/C++ 的代码，这样可以充分利用已有的诸多函数库，也可以将对性能要求非常高的部分用C/C++ 来实现。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;node.js的原理  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;单线程&lt;/li&gt;
&lt;li&gt;异步非阻塞&lt;/li&gt;
&lt;li&gt;事件驱动&lt;br&gt;用高并发解释  &lt;blockquote&gt;
&lt;p&gt;一般来说，高并发解决方案会提供多线程模型，为每个业务逻辑提供一个线程，通过系统线程切换来来弥补同步I/O调用的时间开销。node.js使用的是单线程模型，对所有I/O都采用异步的请求方式，避免频繁的上下文切换，在node.js执行的时候维护着一个事件队列；程序在执行时进入事件循环等待下一个事件到来，每个异步I/O请求完成后都会被推送到事件队列中的等待执行。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;例子：&lt;br&gt;对于一个简单的数据库访问操作，传统方式是这样实现的   &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;res = db.query(&amp;apos;SELECT * from some_table&amp;apos;);
res.output();
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;代码执行到第一行的时候线程会阻塞，等待query返回结果，然后继续处理。由于数据库查询、磁盘读写、网络通信等原因（所谓的I/O）阻塞时间会非常大（相对于CPU始终频率）。对于高并发的访问，一方面线程长期阻塞等待，另一方面为了应付新情求而不断添加新线程，会浪费大量系统资源，同时线程的增加也会也会占用大量的CPU时间来处理内存上下文切换。&lt;br&gt;node.js的处理方式：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;db.query(&amp;apos;SELECT * from some_table&amp;apos;，function(res) {   
        res.output();  
});  
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;query的第二个参数是一个回调函数，进程执行到db.query的时候不会等待结果返回，而是直接继续执行下面的语句，直到进入事件循环。当数据库执行结果返回的时候会将事件发送到事件队列，等到线程进入事件循环后才会调用之前的回调函数。&lt;br&gt;node.js的异步机制是基于事件的，所有的I/O、网络通信、数据库查询都以非阻塞的方式执行，返回结果由事件循环来处理。node.js在同一时刻只会处理一个事件，完成后立即进入事件循环检查后面事件。这样CPU和内存在同一时间集中处理一件事，同时尽量让耗时的I/O等操作并行执行。   &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;事件循环机制&lt;br&gt;所谓事件循环是指node.js会把所有的异步操作使用事件机制解决，有个线程在不断地循环检测事件队列。&lt;br&gt;node.js中所有的逻辑都是事件的回调函数，所以node.js始终在事件循环中，程序入口就是事件循环第一个事件的回调函数。事件的回调函数中可能会发出I/O请求或直接发射（ emit）事件，执行完毕后返回事件循环。事件循环会检查事件队列中有没有未处理的事件，直到程序结束。node.js的事件循环对开发者不可见，由libev库实现，libev不断检查是否有活动的、可供检测的事件监听器，直到检查不到时才退出事件循环，程序结束。   &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;node.js的优缺点&lt;ul&gt;
&lt;li&gt;优点：&lt;ul&gt;
&lt;li&gt;简单&lt;/li&gt;
&lt;li&gt;高性能，避免了频繁的线程切换开销，一个线程而已&lt;/li&gt;
&lt;li&gt;占用资源小，因为是单线程，在大负荷情况下，对内存占用仍然很低&lt;/li&gt;
&lt;li&gt;线程安全，没有加锁、解锁、死锁这些问题&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;缺点：&lt;ul&gt;
&lt;li&gt;CPU密集型任务存在短板&lt;br&gt;  事件循环机制，处理所有的请求。在事件处理过程中，它会智能地将一些涉及到IO、网络通信等耗时比较长的操作，交由worker threads去执行，执行完了再回调。但是，那些非IO操作，只用CPU计算的操作，就只能自己抗了。&lt;/li&gt;
&lt;li&gt;无法利用CPU的多核&lt;br&gt;  Node.js是单线程程序，它只有一个event loop，也只占用一个CPU/内核。&lt;/li&gt;
&lt;li&gt;如果有异常抛出，因为是单线程，整个项目将不可用&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
</content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;什么是node-js&quot;&gt;&lt;a href=&quot;#什么是node-js&quot; class=&quot;headerlink&quot; title=&quot;什么是node.js&quot;&gt;&lt;/a&gt;什么是node.js&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;node.js != Javascript&lt;br&gt;事实上，
    
    </summary>
    
      <category term="后台" scheme="https://iceziyao.github.io/categories/%E5%90%8E%E5%8F%B0/"/>
    
    
      <category term="node.js" scheme="https://iceziyao.github.io/tags/node-js/"/>
    
  </entry>
  
  <entry>
    <title>python编写一个端口扫描器</title>
    <link href="https://iceziyao.github.io/2016/05/01/python%E7%AB%AF%E5%8F%A3/"/>
    <id>https://iceziyao.github.io/2016/05/01/python端口/</id>
    <published>2016-04-30T16:00:00.000Z</published>
    <updated>2016-07-10T17:39:53.810Z</updated>
    
    <content type="html">&lt;h3 id=&quot;编写一个端口扫描器&quot;&gt;&lt;a href=&quot;#编写一个端口扫描器&quot; class=&quot;headerlink&quot; title=&quot;编写一个端口扫描器&quot;&gt;&lt;/a&gt;编写一个端口扫描器&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;任何一个靠谱的网络攻击，都是起步于侦察。所以攻击服务器，也就是检查服务的漏洞。我使用的两种方式无非是web注入和端口扫描。所以先编写一个端口扫描器&lt;/li&gt;
&lt;li&gt;端口扫描是基于TCP的，一共分为三个步骤，分别编写三个方法：  &lt;ul&gt;
&lt;li&gt;处理数据，也就是处理用户输入数据的，此处我们定义为main函数，用来获取主机名和端口  &lt;/li&gt;
&lt;li&gt;将主机名转换为对应的IPv4互联网地址，采socket.gethostbyname(hostname),获取到IP,然后调用处理端口扫描的函数.定义为portScan(tgtHost,tgtPorts)&lt;/li&gt;
&lt;li&gt;端口扫描，也是就TCP的全连接，对目标地址和端口进行连接。最后为了确定该端口上运行的什么服务，我们还会发送垃圾信息，并读取返回的Banner.函数定义为connScan(tgtHost,tgtPort)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;实现端口扫描器&quot;&gt;&lt;a href=&quot;#实现端口扫描器&quot; class=&quot;headerlink&quot; title=&quot;实现端口扫描器&quot;&gt;&lt;/a&gt;实现端口扫描器&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;main函数&lt;pre&gt;&lt;code&gt;
def main():
 parser = optparse.OptionParser(&quot;usage: %prog&quot; + \
 &quot;-H &lt;tgthost host=&quot;&quot;&gt; -P &lt;tgtport&gt;&quot; ,version=&quot;%prog 1.0&quot;)
 &#39;&#39;&#39; 添加命令行参 &#39;&#39;&#39;
 parser.add_option(&#39;-H&#39;,dest=&#39;Host&#39;,type=&#39;string&#39;,help=&#39;specify target host&#39;)
 parser.add_option(&#39;-P&#39;,dest=&#39;Port&#39;,type=&#39;string&#39;,\
 help=&#39;specify target port[s] separated by command&#39;)
 (options ,args) = parser.parse_args()
 tgtHost = options.Host
 tgtPorts = str(options.Port).split(&quot;,&quot;)
 if (tgtHost == None) or (tgtPorts[0] == None):
     print &#39;[-] You must specify a target host and port[s]&#39;
     exit(0)
 portScan(tgtHost,tgtPorts)
&lt;/tgtport&gt;&lt;/tgthost&gt;&lt;/code&gt;&lt;/pre&gt;  &lt;/li&gt;
&lt;li&gt;portScan(tgtHost,tgtPorts)&lt;pre&gt;&lt;code&gt;
def portScan(tgtHost,tgtPorts):
 try:
   tgtIP = gethostbyname(tgtHost)
 except:
   print &quot;[-] cannot resolve &#39;%s&#39;:Unknown host&quot; %(tgtHost)
 try:
   tgtName = gethostbyaddr(tgtIP)
   print &#39;\n[+] Scan Reselts for:&#39; + tgtName[0]
 except:
   print &#39;\n[+] Scan Results for: &#39;+ tgtIP
 setdefaulttimeout(1)
 for tgtPort in tgtPorts:
   connScan(tgtHost,tgtPort)  
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;connScan(tgtHost, tgtPort)  &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
def connScan(tgtHost, tgtPort):
 try:
     connSkt = socket(AF_INET,SOCK_STREAM)
     connSkt.connect((tgtHost,tgtPort))
     connSkt.send(&#39;Hello\r\n&#39;)
     results = connSkt.recv(100)
     lock.acquire()
     print &quot;[+]%d/TCP open&quot; %(tgtPort)
     print &quot;[+] &quot;+str(results)
 except:
     lock.acquire()
     print &quot;[-]%d/TCP closed&quot; %(tgtPort)
 finally:
     lock.release()
     connSkt.close()
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;使用&lt;br&gt;运行后如下结果  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;python portscanner.py -H localhost -P 21,22&lt;br&gt;[+] Scan Reselts for:localhost&lt;br&gt;[+]22/TCP open&lt;br&gt;[+] SSH-2.0-OpenSSH_6.4&lt;br&gt;[+]21/TCP open&lt;br&gt;[+] 220 (vsFTPd 3.0.2)  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;优化&quot;&gt;&lt;a href=&quot;#优化&quot; class=&quot;headerlink&quot; title=&quot;优化&quot;&gt;&lt;/a&gt;优化&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;线程优化&lt;br&gt;采用多线程扫描&lt;br&gt;&lt;pre&gt;&lt;code&gt;&lt;br&gt;for tgtPort in tgtPorts:&lt;br&gt; t=threading.Thread(target=connScan,args=(tgtIP,int(tgtPort)))&lt;br&gt; t.start()&lt;br&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br&gt;这让扫描速度有了很大改进，但又是一个缺点，多个线程同时打印输出，可能出现乱码和失序。我们需要一个信号量来控制，这样代码就会变成这样：&lt;br&gt;&lt;pre&gt;&lt;code&gt;&lt;br&gt;import threading&lt;br&gt;import multiprocessing&lt;br&gt;lock = multiprocessing.Semaphore(value=1) #锁&lt;br&gt;def connScan(tgtHost, tgtPort):&lt;br&gt; try:&lt;pre&gt;&lt;code&gt;connSkt = socket(AF_INET,SOCK_STREAM)
connSkt.connect((tgtHost,tgtPort))
connSkt.send(&amp;apos;Hello\r\n&amp;apos;)
results = connSkt.recv(100)
lock.acquire()
print &amp;quot;[+]%d/TCP open&amp;quot; %(tgtPort)
print &amp;quot;[+] &amp;quot;+str(results)
&lt;/code&gt;&lt;/pre&gt; except:&lt;pre&gt;&lt;code&gt;lock.acquire()
print &amp;quot;[-]%d/TCP closed&amp;quot; %(tgtPort)
&lt;/code&gt;&lt;/pre&gt; finally:&lt;pre&gt;&lt;code&gt;lock.release()
connSkt.close()
&lt;/code&gt;&lt;/pre&gt;def portScan(tgtHost,tgtPorts):&lt;br&gt; try:&lt;pre&gt;&lt;code&gt;tgtIP = gethostbyname(tgtHost)
&lt;/code&gt;&lt;/pre&gt; except:&lt;pre&gt;&lt;code&gt;print &amp;quot;[-] cannot resolve &amp;apos;%s&amp;apos;:Unknown host&amp;quot; %(tgtHost)
&lt;/code&gt;&lt;/pre&gt; try:&lt;pre&gt;&lt;code&gt;tgtName = gethostbyaddr(tgtIP)
print &amp;apos;\n[+] Scan Reselts for:&amp;apos; + tgtName[0]
&lt;/code&gt;&lt;/pre&gt; except:&lt;pre&gt;&lt;code&gt;print &amp;apos;\n[+] Scan Results for: &amp;apos;+ tgtIP
&lt;/code&gt;&lt;/pre&gt; setdefaulttimeout(1)&lt;br&gt; for tgtPort in tgtPorts:&lt;pre&gt;&lt;code&gt;#print &amp;apos;Scanning port &amp;apos; + tgtPort
t=threading.Thread(target=connScan,args=(tgtIP,int(tgtPort)))
t.start()
&lt;/code&gt;&lt;/pre&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br&gt;完整代码请参考&lt;a href=&quot;https://github.com/iceziYao/Grocery/blob/master/portscanner.py&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;portscanner.py&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;使用nmap端口扫描代码&lt;br&gt;2.1 下载Python-Nmap&lt;br&gt;&lt;code&gt;pip install Python-Nmap&lt;/code&gt;&lt;br&gt;2.2 实现&lt;br&gt;&lt;pre&gt;&lt;code&gt;&lt;br&gt;import nmap&lt;br&gt;import optparse&lt;br&gt;from socket import *&lt;br&gt;import os,sys&lt;br&gt;def nmapScan(tgtHost,tgtPort):&lt;br&gt;   nmScan = nmap.PortScanner()&lt;br&gt;   nmScan.scan(tgtHost,tgtPort)&lt;br&gt;   status = nmScan[tgtHost][‘tcp’][int(tgtPort)][‘state’]&lt;br&gt;   print ‘[!] %s tcp/%s %s’ %(tgtHost,tgtPort,status)&lt;br&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br&gt;详细代码查看&lt;a href=&quot;https://github.com/iceziYao/Grocery/blob/master/nmapport.py&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;nmapport.py&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;编写一个端口扫描器&quot;&gt;&lt;a href=&quot;#编写一个端口扫描器&quot; class=&quot;headerlink&quot; title=&quot;编写一个端口扫描器&quot;&gt;&lt;/a&gt;编写一个端口扫描器&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;任何一个靠谱的网络攻击，都是起步于侦察。所以攻击服务器，也就是检查服务的
    
    </summary>
    
      <category term="Python" scheme="https://iceziyao.github.io/categories/Python/"/>
    
    
      <category term="Python" scheme="https://iceziyao.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>浅析docker实现思想</title>
    <link href="https://iceziyao.github.io/2016/04/04/docker02/"/>
    <id>https://iceziyao.github.io/2016/04/04/docker02/</id>
    <published>2016-04-03T16:00:00.000Z</published>
    <updated>2016-07-10T17:39:45.772Z</updated>
    
    <content type="html">&lt;h2 id=&quot;从虚拟化的种类和层级说起&quot;&gt;&lt;a href=&quot;#从虚拟化的种类和层级说起&quot; class=&quot;headerlink&quot; title=&quot;从虚拟化的种类和层级说起&quot;&gt;&lt;/a&gt;从虚拟化的种类和层级说起&lt;/h2&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;cpu虚拟化：可以模拟不同CPU，例如bochs&lt;/li&gt;
&lt;li&gt;完全虚拟化：只能模拟同样CPU，但是可以执行不同系统，例如vmware&lt;/li&gt;
&lt;li&gt;半虚拟化&lt;/li&gt;
&lt;li&gt;硬件虚拟化：可以当作获得硬件加速的完全虚拟化&lt;/li&gt;
&lt;li&gt;系统虚拟化：host和guest共享一样的内核，例如Openvz&lt;/li&gt;
&lt;li&gt;语言沙盒：只能在语言的范围内使用&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;虚拟化的级别越偏底层，速度越慢，用户越难察觉到虚拟化的存在。 虚拟化的级别越偏上层，速度越快，用户越容易感知。也就是虚拟幻的包装，如何一个虚拟化完全包装底层，呈现给用户一个新的操作系统，那么用户会知道他用的什么吗？&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;cpu虚拟化和完全虚拟化时，用户几乎可以阿不察觉到虚拟化的存在&lt;/li&gt;
&lt;li&gt;半虚拟化时，guest内核必须存在补丁&lt;ul&gt;
&lt;li&gt;系统虚拟化时，用户不能控制自己的内核&lt;/li&gt;
&lt;li&gt;语言沙盒时，用户没有使用api的自由&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;docker的原理&quot;&gt;&lt;a href=&quot;#docker的原理&quot; class=&quot;headerlink&quot; title=&quot;docker的原理&quot;&gt;&lt;/a&gt;docker的原理&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;doceker实现结构&lt;br&gt;–&amp;gt;lxc&lt;br&gt;–&amp;gt;namespace: 仅沙盒隔离，不限制资源。&lt;br&gt;–&amp;gt;cgroup: 仅限制资源，不沙盒隔离。&lt;br&gt;–&amp;gt;aufs&lt;br&gt;–&amp;gt;image管理  &lt;/li&gt;
&lt;li&gt;底层技术&lt;blockquote&gt;
&lt;p&gt;Docker使用Go语言编写，并且使用了一系列Linux内核提供的性能来实现我们已经看到的这些功能。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;lxc&lt;blockquote&gt;
&lt;p&gt;LXC是Linux containers的简称，是一种基于容器的操作系统层级的虚拟化技术,linux原生支持的容器.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;XC可以在操作系统层次上为进程提供的虚拟的执行环境，一个虚拟的执行环境就是一个容器。可以为容器绑定特定的cpu和memory节点，分配特定比例的cpu时间、IO时间，限制可以使用的内存大小（包括内存和是swap空间），提供device访问控制，提供独立的namespace（网络、pid、ipc、mnt、uts）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;命名空间(Namespaces)&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Docker充分利用了一项称为namespaces的技术来提供隔离的工作空间，我们称之为 container(容器)。当你运行一个容器的时候，Docker为该容器创建了一个命名空间集合。其实我们在c++也见过类似的namespace    &lt;/li&gt;
&lt;li&gt;这样提供了一个隔离层，每一个应用在它们自己的命名空间中运行而且不会访问到命名空间之外。&lt;br&gt;通俗来讲，就是给将每一个应用放在小房子的，也就是容器，使不同应用不会冲突。  &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一些Docker使用到的命名空间有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;pid命名空间: 使用在进程隔离(PID: Process ID)。&lt;/li&gt;
&lt;li&gt;net命名空间: 使用在管理网络接口(NET: Networking&lt;/li&gt;
&lt;li&gt;ipc命名空间: 使用在管理进程间通信资源 (IPC: InterProcess Communication)&lt;/li&gt;
&lt;li&gt;mnt命名空间: 使用在管理挂载点 (MNT: Mount)。&lt;/li&gt;
&lt;li&gt;uts命名空间: 使用在隔离内核和版本标识 (UTS: Unix Timesharing System)。&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;群组控制(cgroup)&lt;blockquote&gt;
&lt;p&gt;Docker还使用到了cgroups技术来管理群组。使应用隔离运行的关键是让它们只使用你想要的资源。这样可以确保在机器上运行的容器都是良民(good multi-tenant citizens)。群组控制允许Docker分享或者限制容器使用硬件资源。例如，限制指定的容器的内容使用&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;联合文件系统(UnionFS)&lt;blockquote&gt;
&lt;p&gt;联合文件系统(UnionFS)是用来操作创建层的，使它们轻巧快速。Docker使用UnionFS提供容器的构造块。Docker可以使用很多种类的UnionFS包括AUFS, btrfs, vfs, and DeviceMapper。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;结语&quot;&gt;&lt;a href=&quot;#结语&quot; class=&quot;headerlink&quot; title=&quot;结语&quot;&gt;&lt;/a&gt;结语&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;为什么使用go语言实现docker&lt;br&gt;部署简单，依赖性小，开发效率高(相比C/C++)，性能好(相比JAVA)  &lt;/li&gt;
&lt;li&gt;docker与LXC的联系&lt;br&gt;在我理解，docker是LXC的一个高速引擎&lt;/li&gt;
&lt;li&gt;为什么我只解析了docker实现思想&lt;br&gt;我不会go语言，也不了解LXC，我只是一个使用者，只是在自己的理解下探讨docker实现了什么。&lt;/li&gt;
&lt;/ul&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;从虚拟化的种类和层级说起&quot;&gt;&lt;a href=&quot;#从虚拟化的种类和层级说起&quot; class=&quot;headerlink&quot; title=&quot;从虚拟化的种类和层级说起&quot;&gt;&lt;/a&gt;从虚拟化的种类和层级说起&lt;/h2&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;cpu虚拟化：可以模拟
    
    </summary>
    
      <category term="docker" scheme="https://iceziyao.github.io/categories/docker/"/>
    
    
      <category term="docker" scheme="https://iceziyao.github.io/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>浅析docker使用</title>
    <link href="https://iceziyao.github.io/2016/04/03/docker01/"/>
    <id>https://iceziyao.github.io/2016/04/03/docker01/</id>
    <published>2016-04-02T16:00:00.000Z</published>
    <updated>2016-07-10T17:39:49.100Z</updated>
    
    <content type="html">&lt;h2 id=&quot;docker是什么？&quot;&gt;&lt;a href=&quot;#docker是什么？&quot; class=&quot;headerlink&quot; title=&quot;docker是什么？&quot;&gt;&lt;/a&gt;docker是什么？&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;简单的说Docker是一个构建在LXC之上的,基于进程容器(Processcontainer)的轻量级VM解决方案&lt;br&gt;Docker的初衷也就是将各种应用程序和他们所依赖的运行环境打包成标准的Container/image,进而发布到不同的平台上运行。  也是由go写成的轻量级容器&lt;/li&gt;
&lt;li&gt;Docker container和普通的虚拟机Image相比, 最大的区别是它并不包含操作系统内核   &lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;普通虚拟机将整个操作系统运行在虚拟的硬件平台上, 进而提供完整的运行环境供应用程序运行, 而Docker则直接在宿主平台上加载运行应用程序. 本质上他在底层使用LXC启动一个Linux Container,通过cgroup等机制对不同的container内运行的应用程序进行隔离,权限管理和quota分配等  &lt;/li&gt;
&lt;li&gt;每个container拥有自己独立的各种命名空间(亦即资源)包括:&lt;br&gt;PID 进程, MNT 文件系统, NET 网络, IPC , UTS 主机名 等&lt;br&gt;与任何容器技术一样，就该程序而言，它有自己的文件系统、存储系统、处理器和内存等部件。容器与虚拟机之间的区别主要在于，虚拟机管理程序对整个设备进行抽象处理，而容器只是对操作系统内核进行抽象处理。  &lt;/li&gt;
&lt;li&gt;虚拟机管理程序能做容器做不了的一件事就是，使kernel-3.10.0-229.el7.x86_64用不同的操作系统或内核。所以，举例说，你可以使用微软Azure，同时运行Windows Server2012的实例和SUSE Linux企业级服务器的实例。至于Docker，所有容器都必须使用同样的操作系统和内核。&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;Docker 概念及相互作用&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;主机， 运行容器的机器。&lt;/li&gt;
&lt;li&gt;镜像，文件的层次结构，以及包含如何运行容器的元数据&lt;/li&gt;
&lt;li&gt;容器，一个从镜像中启动，包含正在运行的程序的进程&lt;/li&gt;
&lt;li&gt;Registry， 镜像仓库&lt;/li&gt;
&lt;li&gt;卷，容器外的存储  &lt;/li&gt;
&lt;li&gt;Dockerfile， 用于创建镜像的脚本  &lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;docker能用来干什么？&quot;&gt;&lt;a href=&quot;#docker能用来干什么？&quot; class=&quot;headerlink&quot; title=&quot;docker能用来干什么？&quot;&gt;&lt;/a&gt;docker能用来干什么？&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;快速交付你的应用程序&lt;br&gt;Docker可以为你的开发过程提供完美的帮助。Docker允许开发者在本地包含了应用程序和服务的容器进行开发，之后可以集成到连续的一体化和部署工作流中。&lt;/li&gt;
&lt;li&gt;开发和拓展更加简单&lt;br&gt;Docker的以容器为基础的平台允许高度可移植的工作。Docker容器可以在开发者机器上运行，也可以在实体或者虚拟机上运行，也可以在云平台上运行。&lt;br&gt;Docker的可移植、轻量特性同样让动态地管理负载更加简单。你可以用Docker快速地增加应用规模或者关闭应用程序和服务。Docker的快速意味着变动几乎是实时的。&lt;/li&gt;
&lt;li&gt;达到高密度和更多负载&lt;br&gt;Docker轻巧快速，它提供了一个可行的、 符合成本效益的替代基于虚拟机管理程序的虚拟机。这在高密度的环境下尤其有用。例如，构建你自己的云平台或者PaaS，在中小的部署环境下同样可以获取到更多的资源性能。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;docker主要组成有哪些？&quot;&gt;&lt;a href=&quot;#docker主要组成有哪些？&quot; class=&quot;headerlink&quot; title=&quot;docker主要组成有哪些？&quot;&gt;&lt;/a&gt;docker主要组成有哪些？&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Docker有两个主要的部件：  &lt;blockquote&gt;
&lt;p&gt;Docker: 开源的容器虚拟化平台。&lt;br&gt;Docker Hub: 用于分享、管理Docker容器的Docker SaaS平台。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;Docker的内部&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Docker镜像 (Docker images)。&lt;/li&gt;
&lt;li&gt;Docker仓库 (Docker registeries)。&lt;/li&gt;
&lt;li&gt;Docker容器(Docker containers)。&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;Docker镜像&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Docker镜像是一个只读的模板。举个例子，一个镜像可以包含一个运行在Apache上的Web应用和其使用的Ubuntu操作系统。&lt;/li&gt;
&lt;li&gt;镜像是用来创建容器的。Docker提供了简单的放来来建立新的镜像或者升级现有的镜像，你也可以下载别人已经创建好的镜像。Docker镜像是Docker的 构造 部分&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;Docker仓库&lt;blockquote&gt;
&lt;p&gt;Docker仓库用来保存镜像。可以理解为代码控制中的代码仓库。同样的，Docker仓库也有公有和私有的概念。公有的Docker仓库名字是Docker Hub。Docker Hub提供了庞大的镜像集合供使用。这些镜像可以是你自己创建的，或者你也可以在别人的镜像基础上创建。Docker仓库是Docker的 分发 部分。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;Docker容器&lt;blockquote&gt;
&lt;p&gt;Docker容器和文件夹很类似。一个Docker容器包含了所有的某个应用运行所需要的环境。每一个Docker容器都是从Docker镜像创建 的。Docker容器可以运行、开始、停止、移动和删除。每一个Docker容器都是独立和安全的应用平台。Docker容器是Docker的 运行 部分。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;安装docker&quot;&gt;&lt;a href=&quot;#安装docker&quot; class=&quot;headerlink&quot; title=&quot;安装docker&quot;&gt;&lt;/a&gt;安装docker&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;首先更新yum源，添加rhel7.1的iso镜像，来更新内核kernel(因为docker对内核有要求，rhel7.0时启动慢)  &lt;blockquote&gt;
&lt;p&gt;1.自己下载cestos7.1的镜像，构建本地yum&lt;br&gt;2.使用163或者网易的yum源&lt;br&gt;yum update kernel -y&lt;br&gt;rpm -q kernel&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;kernel-3.10.0-123.el7.x86_64&lt;br&gt;kernel-3.10.0-229.el7.x86_64  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;重启，选择kernel-3.10.0-229.el7.x86_64进入系统&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;更新相关组件  &lt;blockquote&gt;
&lt;p&gt;yum update device-mapper -y&lt;br&gt;rpm -qa | grep device-mapper&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;device-mapper-persistent-data-0.3.2-1.el7.x86_64&lt;br&gt;device-mapper-libs-1.02.93-3.el7.x86_64&lt;br&gt;device-mapper-multipath-0.4.9-66.el7.x86_64&lt;br&gt;device-mapper-event-libs-1.02.93-3.el7.x86_64&lt;br&gt;device-mapper-multipath-libs-0.4.9-66.el7.x86_64&lt;br&gt;device-mapper-event-1.02.93-3.el7.x86_64&lt;br&gt;device-mapper-1.02.93-3.el7.x86_64  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;安装docker  &lt;blockquote&gt;
&lt;p&gt;3.1 执行Docker安装脚本&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt; curl -sSL &lt;a href=&quot;https://get.docker.com/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://get.docker.com/&lt;/a&gt; | sh&lt;br&gt;yum install -y docker-selinux&lt;br&gt;这个脚本会添加 docker.repo 配置并安装Docker。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;3.2 自动添加添加yum仓库&lt;br&gt;&lt;pre&gt;&lt;code&gt;&lt;br&gt;cat &amp;gt;/etc/yum.repos.d/docker.repo &amp;lt;&amp;lt;-EOF&lt;br&gt;[dockerrepo]&lt;br&gt;name=Docker Repository&lt;br&gt;baseurl=&lt;a href=&quot;https://yum.dockerproject.org/repo/main/centos/7&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://yum.dockerproject.org/repo/main/centos/7&lt;/a&gt;&lt;br&gt;enabled=1&lt;br&gt;gpgcheck=1&lt;br&gt;gpgkey=&lt;a href=&quot;https://yum.dockerproject.org/gpg&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://yum.dockerproject.org/gpg&lt;/a&gt;&lt;br&gt;EOF&lt;br&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br&gt;安装Docker包&lt;br&gt;yum install -y docker-engine&lt;br&gt;yum install -y docker-selinux&lt;br&gt;yum list installed | grep docker  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;docker-engine.x86_64             1.8.1-1.el7.centos                    @dockerrepo&lt;br&gt;docker-selinux.x86_64            1.7.1-108.el7.centos                  @extras  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;3.3 rpm安装&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;yum install docker-engine-1.8.3-1.el7.centos.x86_64.rpm  -y&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;启动docker&lt;blockquote&gt;
&lt;p&gt;systemctl start docker&lt;br&gt;docker version   &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Client:&lt;br&gt;Version:      1.8.1&lt;br&gt;API version:  1.20&lt;br&gt;Go version:   go1.4.2&lt;br&gt;Git commit:   d12ea79&lt;br&gt;Built:        Thu Aug 13 02:19:43 UTC 2015&lt;br&gt;OS/Arch:      linux/amd64  &lt;/p&gt;
&lt;p&gt;Server:&lt;br&gt;Version:      1.8.1&lt;br&gt;API version:  1.20&lt;br&gt;Go version:   go1.4.2&lt;br&gt;Git commit:   d12ea79&lt;br&gt;Built:        Thu Aug 13 02:19:43 UTC 2015&lt;br&gt;OS/Arch:      linux/amd64  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;docker使用&quot;&gt;&lt;a href=&quot;#docker使用&quot; class=&quot;headerlink&quot; title=&quot;docker使用&quot;&gt;&lt;/a&gt;docker使用&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;有关镜像的操作  &lt;blockquote&gt;
&lt;p&gt;$ docker images  # 查看所有镜像.&lt;br&gt;$ docker import  # 从tarball创建镜像&lt;br&gt;$ docker build   # 通过Dockerfile创建镜像&lt;br&gt;$ docker commit  # 从容器中创建镜像&lt;br&gt;$ docker rmi     # 删除镜像&lt;br&gt;$ docker history # 列出镜像的变更历史  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;运行的容器  &lt;blockquote&gt;
&lt;p&gt;$ docker create  # 创建一个容器，但不启动它&lt;br&gt;$ docker run     #  创建并启动一个容器&lt;br&gt;$ docker stop    # 停止容器&lt;br&gt;$ docker start   #  启动容器&lt;br&gt;$ docker restart # 重启容器&lt;br&gt;$ docker rm      # 删除容器&lt;br&gt;$ docker kill    #  给容器发送kill信号&lt;br&gt;$ docker attach  # 连接到正在运行的容器中&lt;br&gt;$ docker wait    # 阻塞直到容器停止为止&lt;br&gt;$ docker exec    # 在运行的容器中执行一条命令  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;检查容器  &lt;blockquote&gt;
&lt;p&gt;$ docker ps      # 显示运行的容器&lt;br&gt;$ docker inspect # 显示容器信息（包括ip地址）&lt;br&gt;$ docker logs    # 获取容器中的日志&lt;br&gt;$ docker events  # 获取容器事件&lt;br&gt;$ docker port    # 显示容器的公开端口&lt;br&gt;$ docker top     # 显示容器中运行的进程&lt;br&gt;$ docker diff    # 查看容器文件系统中改变的文件&lt;br&gt;$ docker stats   # 查看各种纬度数据、内存、CPU、文件系统等  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;之后的会继续更新博客&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;docker是什么？&quot;&gt;&lt;a href=&quot;#docker是什么？&quot; class=&quot;headerlink&quot; title=&quot;docker是什么？&quot;&gt;&lt;/a&gt;docker是什么？&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;简单的说Docker是一个构建在LXC之上的,基于进程容器(Pr
    
    </summary>
    
      <category term="docker" scheme="https://iceziyao.github.io/categories/docker/"/>
    
    
      <category term="docker" scheme="https://iceziyao.github.io/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>Haproxy负载均衡</title>
    <link href="https://iceziyao.github.io/2016/01/16/haproxy/"/>
    <id>https://iceziyao.github.io/2016/01/16/haproxy/</id>
    <published>2016-01-15T16:00:00.000Z</published>
    <updated>2016-07-10T17:39:50.160Z</updated>
    
    <content type="html">&lt;ol&gt;
&lt;li&gt;&lt;p&gt;HAProxy简介&lt;br&gt;&lt;em&gt;HAProxy提供高可用性、负载均衡以及基于TCP和HTTP应用的代理，支持虚拟主机，它是免费、快速并且可靠的一种解决方案。HAProxy特别适用于那些负载特大的web站点，这些站点通常又需要会话保持或七层处理。HAProxy运行在时下的硬件上，完全可以支持数以万计的并发连接。并且它的运行模式使得它可以很简单安全的整合进您当前的架构中， 同时可以保护你的web服务器不被暴露到网络上.&lt;/em&gt;&lt;br&gt;&lt;em&gt;HAProxy实现了一种事件驱动、单一进程模型，此模型支持非常大的并发连接数。多进程或多线程模型受内存限制 、系统调度器限制以及无处不在的锁限制，很少能处理数千并发连接。事件驱动模型因为在有更好的资源和时间管理的用户端(User-Space) 实现所有这些任务，所以没有这些问题。此模型的弊端是，在多核系统上，这些程序通常扩展性较差。这就是为什么他们必须进行优化以 使每个CPU时间片(Cycle)做更多的工作。&lt;/em&gt;&lt;br&gt;————百度百科&lt;br&gt;HAProxy是免费、极速且可靠的用于为TCP和基于HTTP应用程序提供高可用、负载均衡和代理服务的解决方案，尤其适用于高负载且需要持久连接或7层处理机制的web站点。&lt;br&gt;1.1 HAProxy目前主要有两个版本&lt;br&gt;1.1.1  提供较好的弹性：衍生于1.2版本，并提供了额外的新特性，其中大多数是期待已久的。&lt;br&gt; 客户端侧的长连接(client-side keep-alive)&lt;br&gt; TCP加速(TCP speedups)&lt;br&gt; 响应池(response buffering)&lt;br&gt; RDP协议&lt;br&gt; 基于源的粘性(source-based stickiness)&lt;br&gt; 更好的统计数据接口(a much better stats interfaces)&lt;br&gt; 更详细的健康状态检测机制(more verbose health checks)&lt;br&gt; 基于流量的健康评估机制(traffic-based health)&lt;br&gt; 支持HTTP认证&lt;br&gt; 服务器管理命令行接口(server management from the CLI)&lt;br&gt; 基于ACL的持久性(ACL-based persistence)&lt;br&gt; 日志分析器&lt;br&gt;1.1.2 内容交换和超强负载：&lt;br&gt;衍生于1.2版本，并提供了额外的新特性。&lt;br&gt; 内容交换(content switching)：基于任何请求标准挑选服务器池；&lt;br&gt; ACL：编写内容交换规则；&lt;br&gt; 负载均衡算法(load-balancing algorithms)：更多的算法支持；&lt;br&gt; 内容探测(content inspection)：阻止非授权协议；&lt;br&gt; 透明代理(transparent proxy)：在Linux系统上允许使用客户端IP直接连入服务器；&lt;br&gt; 内核TCP拼接(kernel TCP splicing)：无copy方式在客户端和服务端之间转发数据以实现数G级别的数据速率；&lt;br&gt; 分层设计(layered design)：分别实现套接字、TCP、HTTP处理以提供更好的健壮性、更快的处理机制及便捷的演进能力；&lt;br&gt; 快速、公平调度器(fast and fair scheduler)：为某些任务指定优先级可实现理好的QoS；&lt;br&gt; 会话速率限制(session rate limiting)：适用于托管环境；&lt;br&gt;1.2 性能&lt;br&gt;HAProxy借助于OS上几种常见的技术来实现性能的最大化。&lt;br&gt; 单进程、事件驱动模型显著降低了上下文切换的开销及内存占用。&lt;br&gt; O(1)事件检查器(event checker)允许其在高并发连接中对任何连接的任何事件实现即时探测。&lt;br&gt; 在任何可用的情况下，单缓冲(single buffering)机制能以不复制任何数据的方式完成读写操作，这会节约大量的CPU时钟周期及内存带宽；&lt;br&gt; 借助于Linux 2.6 (&amp;gt;= 2.6.27.19)上的splice()系统调用，HAProxy可以实现零复制转发(Zero-copy forwarding)，在Linux 3.5及以上的OS中还可以实现零复制启动(zero-starting)；&lt;br&gt; MRU内存分配器在固定大小的内存池中可实现即时内存分配，这能够显著减少创建一个会话的时长；&lt;br&gt; 树型存储：侧重于使用作者多年前开发的弹性二叉树，实现了以O(log(N))的低开销来保持计时器命令、保持运行队列命令及管理轮询及最少连接队列；&lt;br&gt; 优化的HTTP首部分析：优化的首部分析功能避免了在HTTP首部分析过程中重读任何内存区域；&lt;br&gt; 精心地降低了昂贵的系统调用，大部分工作都在用户空间完成，如时间读取、缓冲聚合及文件描述符的启用和禁用等；&lt;br&gt;所有的这些细微之处的优化实现了在中等规模负载之上依然有着相当低的CPU负载，甚至于在非常高的负载场景中，5%的用户空间占用率和95%的系统空间占用率也是非常普遍的现象，这意味着HAProxy进程消耗比系统空间消耗低20倍以上。因此，对OS进行性能调优是非常重要的。即使用户空间的占用率提高一倍，其CPU占用率也仅为10%，这也解释了为何7层处理对性能影响有限这一现象。由此，在高端系统上HAProxy的7层性能可轻易超过硬件负载均衡设备。&lt;br&gt;在生产环境中，在7层处理上使用HAProxy作为昂贵的高端硬件负载均衡设备故障故障时的紧急解决方案也时长可见。硬件负载均衡设备在“报文”级别处理请求，这在支持跨报文请求(request across multiple packets)有着较高的难度，并且它们不缓冲任何数据，因此有着较长的响应时间。对应地，软件负载均衡设备使用TCP缓冲，可建立极长的请求，且有着较大的响应时间。&lt;br&gt;可以从三个因素来评估负载均衡器的性能：&lt;br&gt;(1)    会话率&lt;br&gt;(2)    会话并发能力&lt;br&gt;(3) 数据率  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;配置HAProxy&lt;br&gt;2.1 配置文件格式&lt;br&gt;HAProxy的配置处理3类来主要参数来源：&lt;br&gt; ——最优先处理的命令行参数，&lt;br&gt; ——“global”配置段，用于设定全局配置参数；&lt;br&gt; ——proxy相关配置段，如“defaults”、“listen”、“frontend”和“backend”；&lt;br&gt;2.2 时间格式&lt;br&gt;一些包含了值的参数表示时间，如超时时长。这些值一般以毫秒为单位，但也可以使用其它的时间单位后缀。&lt;br&gt; us: 微秒(microseconds)，即1/1000000秒；&lt;br&gt; ms: 毫秒(milliseconds)，即1/1000秒；&lt;br&gt; s: 秒(seconds)；&lt;br&gt; m: 分钟(minutes)；&lt;br&gt; h：小时(hours)；&lt;br&gt; d: 天(days)；&lt;br&gt;2.3 例子&lt;br&gt;下面的例子配置了一个监听在所有接口的80端口上HTTP proxy服务，它转发所有的请求至后端监听在127.0.0.1:8000上的”server”。&lt;br&gt;&lt;pre&gt;&lt;code&gt;&lt;br&gt; global&lt;br&gt; daemon&lt;br&gt; maxconn 25600&lt;br&gt;defaults&lt;br&gt; mode http&lt;br&gt; timeout connect 5000ms&lt;br&gt; timeout client 50000ms&lt;br&gt; timeout server 50000ms&lt;br&gt;frontend http-in&lt;br&gt; bind &lt;em&gt;:80&lt;br&gt; default_backend servers&lt;br&gt;backend servers&lt;br&gt; server server1 127.0.0.1:8080 maxconn 32&lt;br&gt;&lt;/em&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br&gt;2.4 全局配置&lt;br&gt;“”“global”配置中的参数为进程级别的参数，且通常与其运行的OS相关。&lt;br&gt;\ 进程管理及安全相关的参数&lt;br&gt;- chroot &lt;jail dir=&quot;&quot;&gt;：修改haproxy的工作目录至指定的目录并在放弃权限之前执行chroot()操作，可以提升haproxy的安全级别，不过需要注意的是要确保指定的目录为空目录且任何用户均不能有写权限；&lt;br&gt;- daemon：让haproxy以守护进程的方式工作于后台，其等同于“-D”选项的功能，当然，也可以在命令行中以“-db”选项将其禁用；&lt;br&gt;- gid &lt;number&gt;：以指定的GID运行haproxy，建议使用专用于运行haproxy的GID，以免因权限问题带来风险；&lt;br&gt;- group &lt;group name=&quot;&quot;&gt;：同gid，不过指定的组名；&lt;br&gt;- log  &lt;address&gt; &lt;facility&gt; [max level [min level]]：定义全局的syslog服务器，最多可以定义两个；&lt;br&gt;- log-send-hostname [&lt;string&gt;]：在syslog信息的首部添加当前主机名，可以为“string”指定的名称，也可以缺省使用当前主机名；&lt;br&gt;- nbproc &lt;number&gt;：指定启动的haproxy进程个数，只能用于守护进程模式的haproxy；默认只启动一个进程，鉴于调试困难等多方面的原因，一般只在单进程仅能打开少数文件描述符的场景中才使用多进程模式；&lt;br&gt;- pidfile：&lt;br&gt;- uid：以指定的UID身份运行haproxy进程；&lt;br&gt;- ulimit-n：设定每进程所能够打开的最大文件描述符数目，默认情况下其会自动进行计算，因此不推荐修改此选项；&lt;br&gt;- user：同uid，但使用的是用户名；&lt;br&gt;- stats：&lt;br&gt;- node：定义当前节点的名称，用于HA场景中多haproxy进程共享同一个IP地址时；&lt;br&gt;- description：当前实例的描述信息；&lt;br&gt;* 性能调整相关的参数&lt;br&gt;- maxconn &lt;number&gt;：设定每个haproxy进程所接受的最大并发连接数，其等同于命令行选项“-n”；“ulimit -n”自动计算的结果正是参照此参数设定的；&lt;br&gt;- maxpipes &lt;number&gt;：haproxy使用pipe完成基于内核的tcp报文重组，此选项则用于设定每进程所允许使用的最大pipe个数；每个pipe会打开两个文件描述符，因此，“ulimit -n”自动计算时会根据需要调大此值；默认为maxconn/4，其通常会显得过大；&lt;br&gt;- noepoll：在Linux系统上禁用epoll机制；&lt;br&gt;- nokqueue：在BSE系统上禁用kqueue机制；&lt;br&gt;- nopoll：禁用poll机制；&lt;br&gt;- nosepoll：在Linux禁用启发式epoll机制；&lt;br&gt;- nosplice：禁止在Linux套接字上使用内核tcp重组，这会导致更多的recv/send系统调用；不过，在Linux 2.6.25-28系列的内核上，tcp重组功能有bug存在；&lt;br&gt;- spread-checks &lt;0..50, in=&quot;&quot; percent=&quot;&quot;&gt;：在haproxy后端有着众多服务器的场景中，在精确的时间间隔后统一对众服务器进行健康状况检查可能会带来意外问题；此选项用于将其检查的时间间隔长度上增加或减小一定的随机时长；&lt;br&gt;- tune.bufsize &lt;number&gt;：设定buffer的大小，同样的内存条件小，较小的值可以让haproxy有能力接受更多的并发连接，较大的值可以让某些应用程序使用较大的cookie信息；默认为16384，其可以在编译时修改，不过强烈建议使用默认值；&lt;br&gt;- tune.chksize &lt;number&gt;：设定检查缓冲区的大小，单位为字节；更大的值有助于在较大的页面中完成基于字符串或模式的文本查找，但也会占用更多的系统资源；不建议修改；&lt;br&gt;- tune.maxaccept &lt;number&gt;：设定haproxy进程内核调度运行时一次性可以接受的连接的个数，较大的值可以带来较大的吞吐率，默认在单进程模式下为100，多进程模式下为8，设定为-1可以禁止此限制；一般不建议修改；&lt;br&gt;- tune.maxpollevents  &lt;number&gt;：设定一次系统调用可以处理的事件最大数，默认值取决于OS；其值小于200时可节约带宽，但会略微增大网络延迟，而大于200时会降低延迟，但会稍稍增加网络带宽的占用量；&lt;br&gt;- tune.maxrewrite &lt;number&gt;：设定为首部重写或追加而预留的缓冲空间，建议使用1024左右的大小；在需要使用更大的空间时，haproxy会自动增加其值；&lt;br&gt;- tune.rcvbuf.client &lt;number&gt;：&lt;br&gt;- tune.rcvbuf.server &lt;number&gt;：设定内核套接字中服务端或客户端接收缓冲的大小，单位为字节；强烈推荐使用默认值；&lt;br&gt;- tune.sndbuf.client：&lt;br&gt;- tune.sndbuf.server：&lt;br&gt;* Debug相关的参数&lt;br&gt;- debug&lt;br&gt;- quiet&lt;br&gt;2.5 代理&lt;br&gt;代理相关的配置可以如下配置段中。&lt;br&gt;(1) defaults name&lt;br&gt;(2) frontend name&lt;br&gt;(3) backend  name&lt;br&gt;(4) listen   name&lt;br&gt;“defaults”段用于为所有其它配置段提供默认参数，这配置默认配置参数可由下一个“defaults”所重新设定。&lt;br&gt;“frontend”段用于定义一系列监听的套接字，这些套stats&lt;em&gt;auth接字可接受客户端请求并与之建立连接。&lt;br&gt;“backend”段用于定义一系列“后端”服务器，代理将会将对应客户端的请求转发至这些服务器。&lt;br&gt;“listen”段通过关联“前端”和“后端”定义了一个完整的代理，通常只对TCP流量有用。&lt;br&gt;所有代理的名称只能使用大写字母、小写字母、数字、-(中线)、\&lt;/em&gt;(下划线)、.(点号)和\:(冒号)。此外，ACL名称会区分字母大小写。  &lt;/number&gt;&lt;/number&gt;&lt;/number&gt;&lt;/number&gt;&lt;/number&gt;&lt;/number&gt;&lt;/number&gt;&lt;/0..50,&gt;&lt;/number&gt;&lt;/number&gt;&lt;/number&gt;&lt;/string&gt;&lt;/facility&gt;&lt;/address&gt;&lt;/group&gt;&lt;/number&gt;&lt;/jail&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;配置文件中的关键字参考&lt;br&gt;3.1 balance&lt;br&gt;&lt;code&gt;balance &amp;lt;algorithm&amp;gt; [ &amp;lt;arguments&amp;gt; ]&lt;/code&gt;&lt;br&gt;&lt;code&gt;balance url_param &amp;lt;param&amp;gt; [check_post   [&amp;lt;max_wait&amp;gt;]]&lt;/code&gt;&lt;br&gt;3.2 bind&lt;br&gt;&lt;code&gt;bind [&amp;lt;address&amp;gt;]:&amp;lt;port_range&amp;gt; [, ...]&lt;/code&gt;&lt;br&gt;&lt;code&gt;bind [&amp;lt;address&amp;gt;]:&amp;lt;port_range&amp;gt; [, ...] interface &amp;lt;interface&amp;gt;&lt;/code&gt;&lt;br&gt;-此指令仅能用于frontend和listen区段，用于定义一个或几个监听的套接字。&lt;br&gt;&lt;code&gt;&amp;lt;address&amp;gt;&lt;/code&gt;：可选选项，其可以为主机名、IPv4地址、IPv6地址或&lt;em&gt;；省略此选项、将其指定为&lt;/em&gt;或0.0.0.0时，将监听当前系统的所有IPv4地址；&lt;br&gt;&lt;code&gt;&amp;lt;port_range&amp;gt;&lt;/code&gt;：可以是一个特定的TCP端口，也可是一个端口范围(如5005-5010)，代理服务器将通过指定的端口来接收客户端请求；需要注意的是，每组监听的套接字&lt;address:port&gt;在同一个实例上只能使用一次，而且小于1024的端口需要有特定权限的用户才能使用，这可能需要通过uid参数来定义；&lt;br&gt;&lt;code&gt;&amp;lt;interface&amp;gt;：&lt;/code&gt;指定物理接口的名称，仅能在Linux系统上使用；其不能使用接口别名，而仅能使用物理接口名称，而且只有管理有权限指定绑定的物理接口；&lt;br&gt;3.3 mode&lt;br&gt;&lt;code&gt;mode { tcp|http|health }&lt;/code&gt;&lt;br&gt;设定实例的运行模式或协议。当实现内容交换时，前端和后端必须工作于同一种模式(一般说来都是HTTP模式)，否则将无法启动实例。&lt;br&gt;tcp：实例运行于纯TCP模式，在客户端和服务器端之间将建立一个全双工的连接，且不会对7层报文做任何类型的检查；此为默认模式，通常用于SSL、SSH、SMTP等应用；&lt;br&gt;http：实例运行于HTTP模式，客户端请求在转发至后端服务器之前将被深度分析，所有不与RFC格式兼容的请求都会被拒绝；&lt;br&gt;health：实例工作于health模式，其对入站请求仅响应“OK”信息并关闭连接，且不会记录任何日志信息；此模式将用于响应外部组件的健康状态检查请求；目前业讲，此模式已经废弃，因为tcp或http模式中的monitor关键字可完成类似功能；&lt;br&gt;3.4 hash-type&lt;br&gt;&lt;code&gt;hash-type &amp;lt;method&amp;gt;&lt;/code&gt;&lt;br&gt;定义用于将hash码映射至后端服务器的方法；其不能用于frontend区段；可用方法有map-based和consistent，在大多数场景下推荐使用默认的map-based方法&lt;br&gt;map-based：hash表是一个包含了所有在线服务器的静态数组。其hash值将会非常平滑，会将权重考虑在列，但其为静态方法，对在线服务器的权重进行调整将不会生效，这意味着其不支持慢速启动。此外，挑选服务器是根据其在数组中的位置进行的，因此，当一台服务器宕机或添加了一台新的服务器时，大多数连接将会被重新派发至一个与此前不同的服务器上，对于缓存服务器的工作场景来说，此方法不甚适用。&lt;br&gt;consistent：hash表是一个由各服务器填充而成的树状结构；基于hash键在hash树中查找相应的服务器时，最近的服务器将被选中。此方法是动态的，支持在运行时修改服务器权重，因此兼容慢速启动的特性。添加一个新的服务器时，仅会对一小部分请求产生影响，因此，尤其适用于后端服务器为cache的场景。不过，此算法不甚平滑，派发至各服务器的请求未必能达到理想的均衡效果，因此，可能需要不时的调整服务器的权重以获得更好的均衡性。&lt;br&gt;3.5 log&lt;br&gt;&lt;code&gt;log global&lt;/code&gt;&lt;br&gt;&lt;code&gt;log &amp;lt;address&amp;gt; &amp;lt;facility&amp;gt; [&amp;lt;level&amp;gt; [&amp;lt;minlevel&amp;gt;]]&lt;/code&gt;&lt;br&gt;为每个实例启用事件和流量日志，因此可用于所有区段。每个实例最多可以指定两个log参数，不过，如果使用了“log global”且”global”段已经定了两个log参数时，多余了log参数将被忽略。&lt;br&gt;global：当前实例的日志系统参数同”global”段中的定义时，将使用此格式；每个实例仅能定义一次“log global”语句，且其没有任何额外参数；&lt;br&gt;&lt;code&gt;&amp;lt;address&amp;gt;&lt;/code&gt;：定义日志发往的位置，其格式之一可以为&lt;code&gt;&amp;lt;IPv4_address:PORT&amp;gt;&lt;/code&gt;，其中的port为UDP协议端口，默认为514；格式之二为Unix套接字文件路径，但需要留心chroot应用及用户的读写权限；&lt;br&gt;&lt;code&gt;&amp;lt;facility&amp;gt;&lt;/code&gt;：可以为syslog系统的标准facility之一；&lt;br&gt;&lt;code&gt;&amp;lt;level&amp;gt;&lt;/code&gt;：定义日志级别，即输出信息过滤器，默认为所有信息；指定级别时，所有等于或高于此别的日志信息将会被发送；&lt;br&gt;3.6 maxconn&lt;br&gt;&lt;code&gt;maxconn &amp;lt;conns&amp;gt;&lt;/code&gt;&lt;br&gt;设定一个前端的最大并发连接数，因此，其不能用于backend区段。对于大型站点来说，可以尽可能提高此值以便让haproxy管理连接队列，从而避免无法应答用户请求。当然，此最大值不能超出“global”段中的定义。此外，需要留心的是，haproxy会为每个连接维持两个缓冲，每个缓冲的大小为8KB，再加上其它的数据，每个连接将大约占用17KB的RAM空间。这意味着经过适当优化后，有着1GB的可用RAM空间时将能维护40000-50000并发连接。&lt;br&gt;如果为&lt;code&gt;&amp;lt;conns&amp;gt;&lt;/code&gt;指定了一个过大值，极端场景下，其最终占据的空间可能会超出当前主机的可用内存，这可能会带来意想不到的结果；因此，将其设定了一个可接受值方为明智决定。其默认为2000。&lt;br&gt;3.7 default_backend&lt;br&gt;default_backend &lt;code&gt;&amp;lt;backend&amp;gt;&lt;/code&gt;&lt;br&gt;在没有匹配的”use_backend”规则时为实例指定使用的默认后端，因此，其不可应用于backend区段。在”frontend”和”backend”之间进行内容交换时，通常使用”use-backend”定义其匹配规则；而没有被规则匹配到的请求将由此参数指定的后端接收。&lt;br&gt;&lt;code&gt;&amp;lt;backend&amp;gt;&lt;/code&gt;：指定使用的后端的名称；&lt;br&gt;使用案例：  &lt;/address:port&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
use_backend     dynamic  if  url_dyn
use_backend     static   if  url_css url_img extension_img
default_backend dynamic
&lt;/code&gt;&lt;/pre&gt;  
3.8 服务  
&lt;pre&gt;&lt;code&gt;
server &lt;name&gt; &lt;address&gt;[:port] [param*]
为后端声明一个server，因此，不能用于defaults和frontend区段。
&lt;name&gt;：为此服务器指定的内部名称，其将出现在日志及警告信息中；如果设定了&quot;http-send-server-name&quot;，它还将被添加至发往此服务器的请求首部中；
&lt;address&gt;：此服务器的的IPv4地址，也支持使用可解析的主机名，只不过在启动时需要解析主机名至相应的IPv4地址；
[:port]：指定将连接请求所发往的此服务器时的目标端口，其为可选项；未设定时，将使用客户端请求时的同一相端口；
[param*]：为此服务器设定的一系参数；其可用的参数非常多，具体请参考官方文档中的说明，下面仅说明几个常用的参数；
服务器或默认服务器参数：
backup：设定为备用服务器，仅在负载均衡场景中的其它server均不可用于启用此server；
check：启动对此server执行健康状态检查，其可以借助于额外的其它参数完成更精细的设定，如：
 inter &lt;delay&gt;：设定健康状态检查的时间间隔，单位为毫秒，默认为2000；也可以使用fastinter和downinter来根据服务器端状态优化此时间延迟；
 rise &lt;count&gt;：设定健康状态检查中，某离线的server从离线状态转换至正常状态需要成功检查的次数；
 fall &lt;count&gt;：确认server从正常状态转换为不可用状态需要检查的次数；
cookie &lt;value&gt;：为指定server设定cookie值，此处指定的值将在请求入站时被检查，第一次为此值挑选的server将在后续的请求中被选中，其目的在于实现持久连接的功能；
maxconn &lt;maxconn&gt;：指定此服务器接受的最大并发连接数；如果发往此服务器的连接数目高于此处指定的值，其将被放置于请求队列，以等待其它连接被释放；
maxqueue &lt;maxqueue&gt;：设定请求队列的最大长度；
observe &lt;mode&gt;：通过观察服务器的通信状况来判定其健康状态，默认为禁用，其支持的类型有“layer4”和“layer7”，“layer7”仅能用于http代理场景；
redir &lt;prefix&gt;：启用重定向功能，将发往此服务器的GET和HEAD请求均以302状态码响应；需要注意的是，在prefix后面不能使用/，且不能使用相对地址，以免造成循环；例如：
 server srv1 172.16.100.6:80 redir http://imageserver.magedu.com check
weight &lt;weight&gt;：权重，默认为1，最大值为256，0表示不参与负载均衡；
检查方法：
option httpchk
option httpchk &lt;uri&gt;
option httpchk &lt;method&gt; &lt;uri&gt;
option httpchk &lt;method&gt; &lt;uri&gt; &lt;version&gt;：不能用于frontend段，例如：
backend https_relay
 mode tcp
 option httpchk OPTIONS * HTTP/1.1\r\nHost:\ www.magedu.com
 server apache1 192.168.1.1:443 check port 80
使用案例：
server first  172.16.100.7:1080 cookie first  check inter 1000
server second 172.16.100.8:1080 cookie second check inter 1000
&lt;/version&gt;&lt;/uri&gt;&lt;/method&gt;&lt;/uri&gt;&lt;/method&gt;&lt;/uri&gt;&lt;/weight&gt;&lt;/prefix&gt;&lt;/mode&gt;&lt;/maxqueue&gt;&lt;/maxconn&gt;&lt;/value&gt;&lt;/count&gt;&lt;/count&gt;&lt;/delay&gt;&lt;/address&gt;&lt;/name&gt;&lt;/address&gt;&lt;/name&gt;&lt;/code&gt;&lt;/pre&gt;  
3.9 capture request header  
&lt;pre&gt;&lt;code&gt;
capture request header &lt;name&gt; len &lt;length&gt;
捕获并记录指定的请求首部最近一次出现时的第一个值，仅能用于“frontend”和“listen”区段。捕获的首部值使用花括号{}括起来后添加进日志中。如果需要捕获多个首部值，它们将以指定的次序出现在日志文件中，并以竖线“|”作为分隔符。不存在的首部记录为空字符串，最常需要捕获的首部包括在虚拟主机环境中使用的“Host”、上传请求首部中的“Content-length”、快速区别真实用户和网络机器人的“User-agent”，以及代理环境中记录真实请求来源的“X-Forward-For”。
&lt;name&gt;：要捕获的首部的名称，此名称不区分字符大小写，但建议与它们出现在首部中的格式相同，比如大写首字母。需要注意的是，记录在日志中的是首部对应的值，而非首部名称。
&lt;length&gt;：指定记录首部值时所记录的精确长度，超出的部分将会被忽略。
可以捕获的请求首部的个数没有限制，但每个捕获最多只能记录64个字符。为了保证同一个frontend中日志格式的统一性，首部捕获仅能在frontend中定义。
&lt;/length&gt;&lt;/name&gt;&lt;/length&gt;&lt;/name&gt;&lt;/code&gt;&lt;/pre&gt;
3.10 capture response header  
&lt;pre&gt;&lt;code&gt;
capture response header &lt;name&gt; len &lt;length&gt;
捕获并记录响应首部，其格式和要点同请求首部。
&lt;/length&gt;&lt;/name&gt;&lt;/code&gt;&lt;/pre&gt;  
3.11 stats enable
&lt;pre&gt;&lt;code&gt;
启用基于程序编译时默认设置的统计报告，不能用于“frontend”区段。只要没有另外的其它设定，它们就会使用如下的配置：
\- stats uri   : /haproxy?stats
\- stats realm : &quot;HAProxy Statistics&quot;
\- stats auth  : no authentication
\- stats scope : no restriction   
尽管“stats enable”一条就能够启用统计报告，但还是建议设定其它所有的参数，以免其依赖于默认设定而带来非期后果。下面是一个配置案例。  
backend public_www
 server websrv1 172.16.100.11:80
 stats enable
 stats hide-version
 stats scope   .
 stats uri     /haproxyadmin?stats
 stats realm   Haproxy\ Statistics
 stats auth    statsadmin:password
 stats auth    statsmaster:password
&lt;/code&gt;&lt;/pre&gt;  
3.12 stats hide-version
&lt;pre&gt;&lt;code&gt;
stats hide-version  
启用统计报告并隐藏HAProxy版本报告，不能用于“frontend”区段。默认情况下，统计页面会显示一些有用信息，包括HAProxy的版本号，然而，向所有人公开HAProxy的精确版本号是非常有风险的，因为它能帮助恶意用户快速定位版本的缺陷和漏洞。尽管“stats hide-version”一条就能够启用统计报告，但还是建议设定其它所有的参数，以免其依赖于默认设定而带来非期后果。具体请参照“stats enable”一节的说明。
&lt;/code&gt;&lt;/pre&gt;
3.13 stats realm  
&lt;pre&gt;&lt;code&gt;
stats realm &lt;realm&gt;
启用统计报告并高精认证领域，不能用于“frontend”区段。haproxy在读取realm时会将其视作一个单词，因此，中间的任何空白字符都必须使用反斜线进行转义。此参数仅在与“stats auth”配置使用时有意义。
&lt;realm&gt;：实现HTTP基本认证时显示在浏览器中的领域名称，用于提示用户输入一个用户名和密码。
尽管“stats realm”一条就能够启用统计报告，但还是建议设定其它所有的参数，以免其依赖于默认设定而带来非期后果。具体请参照“stats enable”一节的说明。
&lt;/realm&gt;&lt;/realm&gt;&lt;/code&gt;&lt;/pre&gt;
3.14 stats scope  
&lt;pre&gt;&lt;code&gt;
stats scope { &lt;name&gt; | &quot;.&quot; }
启用统计报告并限定报告的区段，不能用于“frontend”区段。当指定此语句时，统计报告将仅显示其列举出区段的报告信息，所有其它区段的信息将被隐藏。如果需要显示多个区段的统计报告，此语句可以定义多次。需要注意的是，区段名称检测仅仅是以字符串比较的方式进行，它不会真检测指定的区段是否真正存在。
name&gt;：可以是一个“listen”、“frontend”或“backend”区段的名称，而“.”则表示stats scope语句所定义的当前区段。  
尽管“stats scope”一条就能够启用统计报告，但还是建议设定其它所有的参数，以免其依赖于默认设定而带来非期后果。下面是一个配置案例。
backend private_monitoring
 stats enable
 stats uri     /haproxyadmin?stats
 stats refresh 10s
&lt;/name&gt;&lt;/code&gt;&lt;/pre&gt;
3.15 stats auth  
&lt;pre&gt;&lt;code&gt;
stats auth &lt;user&gt;:&lt;passwd&gt;
启用带认证的统计报告功能并授权一个用户帐号，其不能用于“frontend”区段。
&lt;user&gt;：授权进行访问的用户名；
&lt;passwd&gt;：此用户的访问密码，明文格式；
此语句将基于默认设定启用统计报告功能，并仅允许其定义的用户访问，其也可以定义多次以授权多个用户帐号。可以结合“stats realm”参数在提示用户认证时给出一个领域说明信息。在使用非法用户访问统计功能时，其将会响应一个“401 Forbidden”页面。其认证方式为HTTP Basic认证，密码传输会以明文方式进行，因此，配置文件中也使用明文方式存储以说明其非保密信息故此不能相同于其它关键性帐号的密码。
尽管“stats auth”一条就能够启用统计报告，但还是建议设定其它所有的参数，以免其依赖于默认设定而带来非期后果。
&lt;/passwd&gt;&lt;/user&gt;&lt;/passwd&gt;&lt;/user&gt;&lt;/code&gt;&lt;/pre&gt;
3.16 stats admin  
&lt;pre&gt;&lt;code&gt;
stats admin { if | unless } &lt;cond&gt;
在指定的条件满足时启用统计报告页面的管理级别功能，它允许通过web接口启用或禁用服务器，不过，基于安全的角度考虑，统计报告页面应该尽可能为只读的。此外，如果启用了HAProxy的多进程模式，启用此管理级别将有可能导致异常行为。
目前来说，POST请求方法被限制于仅能使用缓冲区减去保留部分之外的空间，因此，服务器列表不能过长，否则，此请求将无法正常工作。因此，建议一次仅调整少数几个服务器。下面是两个案例，第一个限制了仅能在本机打开报告页面时启用管理级别功能，第二个定义了仅允许通过认证的用户使用管理级别功能。
backend stats_localhost
 stats enable
 stats admin if LOCALHOST
backend stats_auth
 stats enable
 stats auth  haproxyadmin:password
 stats admin if TRUE
&lt;/cond&gt;&lt;/code&gt;&lt;/pre&gt;
3.17 option httplog  
&lt;pre&gt;&lt;code&gt;
option httplog [ clf ]
启用记录HTTP请求、会话状态和计时器的功能。
clf：使用CLF格式来代替HAProxy默认的HTTP格式，通常在使用仅支持CLF格式的特定日志分析器时才需要使用此格式。
默认情况下，日志输入格式非常简陋，因为其仅包括源地址、目标地址和实例名称，而“option httplog”参数将会使得日志格式变得丰富许多，其通常包括但不限于HTTP请求、连接计时器、会话状态、连接数、捕获的首部及cookie、“frontend”、“backend”及服务器名称，当然也包括源地址和端口号等。
&lt;/code&gt;&lt;/pre&gt;
3.18 option logasap  
&lt;pre&gt;&lt;code&gt;
     option logasap  
 no option logasap  
启用或禁用提前将HTTP请求记入日志，不能用于“backend”区段。  
默认情况下，HTTP请求是在请求结束时进行记录以便能将其整体传输时长和字节数记入日志，由此，传较大的对象时，其记入日志的时长可能会略有延迟。“option logasap”参数能够在服务器发送complete首部时即时记录日志，只不过，此时将不记录整体传输时长和字节数。此情形下，捕获“Content-Length”响应首部来记录传输的字节数是一个较好选择。下面是一个例子。  
listen http_proxy 0.0.0.0:80
   mode http
   option httplog
   option logasap
   log 172.16.100.9 local2
&lt;/code&gt;&lt;/pre&gt;
3.19 option forwardfor  
&lt;pre&gt;&lt;code&gt;
option forwardfor [ except &lt;network&gt; ] [ header &lt;name&gt; ] [ if-none ]
允许在发往服务器的请求首部中插入“X-Forwarded-For”首部。  
&lt;network&gt;：可选参数，当指定时，源地址为匹配至此网络中的请求都禁用此功能。  
&lt;name&gt;：可选参数，可使用一个自定义的首部，如“X-Client”来替代“X-Forwarded-For”。有些独特的web服务器的确需要用于一个独特的首部
if-none：仅在此首部不存在时才将其添加至请求报文问道中
HAProxy工作于反向代理模式，其发往服务器的请求中的客户端IP均为HAProxy主机的地址而非真正客户端的地址，这会使得服务器端的日志信息记录不了真正的请求来源，“X-Forwarded-For”首部则可用于解决此问题。HAProxy可以向每个发往服务器的请求上添加此首部，并以客户端IP为其value
需要注意的是，HAProxy工作于隧道模式，其仅检查每一个连接的第一个请求，因此，仅第一个请求报文被附加此首部。如果想为每一个请求都附加此首部，请确保同时使用了“option httpclose”、“option forceclose”和“option http-server-close”几个option。  
下面是一个例子
frontend www
 mode http
 option forwardfor except 127.0.0.1
&lt;/name&gt;&lt;/network&gt;&lt;/name&gt;&lt;/network&gt;&lt;/code&gt;&lt;/pre&gt;
3.20 errorfile  
&lt;pre&gt;&lt;code&gt;
errorfile &lt;code&gt; &lt;file&gt;
在用户请求不存在的页面时，返回一个页面文件给客户端而非由haproxy生成的错误代码；可用于所有段中
&lt;code&gt;：指定对HTTP的哪些状态码返回指定的页面；这里可用的状态码有200、400、403、408、500、502、503和504；
&lt;file&gt;：指定用于响应的页面文件；
例如
errorfile 400 /etc/haproxy/errorpages/400badreq.http
errorfile 403 /etc/haproxy/errorpages/403forbid.http
errorfile 503 /etc/haproxy/errorpages/503sorry.http
&lt;/file&gt;&lt;/code&gt;&lt;/file&gt;&lt;/code&gt;&lt;/code&gt;&lt;/pre&gt;
3.21 errorloc 和 errorloc302  
&lt;pre&gt;&lt;code&gt;
errorloc &lt;code&gt; &lt;url&gt;
errorloc302 &lt;code&gt; &lt;url&gt;
请求错误时，返回一个HTTP重定向至某URL的信息；可用于所有配置段中。
&lt;code&gt;：指定对HTTP的哪些状态码返回指定的页面；这里可用的状态码有200、400、403、408、500、502、503和504；
&lt;url&gt;：Location首部中指定的页面位置的具体路径，可以是在当前服务器上的页面的相对路径，也可以使用绝对路径；需要注意的是，如果URI自身错误时产生某特定状态码信息的话，有可能会导致循环定向；
需要留意的是，这两个关键字都会返回302状态吗，这将使得客户端使用同样的HTTP方法获取指定的URL，对于非GET法的场景(如POST)来说会产生问题，因为返回客户的URL是不允许使用GET以外的其它方法的。如果的确有这种问题，可以使用errorloc303来返回303状态码给客户端。
&lt;/url&gt;&lt;/code&gt;&lt;/url&gt;&lt;/code&gt;&lt;/url&gt;&lt;/code&gt;&lt;/code&gt;&lt;/pre&gt;
3.22 errorloc303
&lt;pre&gt;&lt;code&gt;
`errorloc303 &lt;code&gt; &lt;url&gt;`  
请求错误时，返回一个HTTP重定向至某URL的信息给客户端；可用于所有配置段中。  
`&lt;code&gt;`：指定对HTTP的哪些状态码返回指定的页面；这里可用的状态码有400、403、408、500、502、503和504；  
&lt;url&gt;：Location首部中指定的页面位置的具体路径，可以是在当前服务器上的页面的相对路径，也可以使用绝对路径；需要注意的是，如果URI自身错误时产生某特定状态码信息的话，有可能会导致循环定向；  
例如：
backend webserver
server 172.16.100.6 172.16.100.6:80 check maxconn 3000 cookie srv01
server 172.16.100.7 172.16.100.7:80 check maxconn 3000 cookie srv02
errorloc 403 /etc/haproxy/errorpages/sorry.htm
errorloc 503 /etc/haproxy/errorpages/sorry.htm
&lt;/url&gt;&lt;/code&gt;&lt;/url&gt;&lt;/code&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;一个配置示例：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
\#---------------------------------------------------------------------
\# Global settings
\#---------------------------------------------------------------------
global
    # to have these messages end up in /var/log/haproxy.log you will
    # need to:
    #
    # 1) configure syslog to accept network log events.  This is done
    #    by adding the &#39;-r&#39; option to the SYSLOGD_OPTIONS in
    #    /etc/sysconfig/syslog
    #
    # 2) configure local2 events to go to the /var/log/haproxy.log
    #   file. A line like the following can be added to
    #   /etc/sysconfig/syslog
    #
    #    local2.*                       /var/log/haproxy.log
    #
    log         127.0.0.1 local2
    chroot      /var/lib/haproxy
    pidfile     /var/run/haproxy.pid
    maxconn     4000
    user        haproxy
    group       haproxy
    daemon
defaults
    mode                    http
    log                     global
    option                  httplog
    option                  dontlognull
    option http-server-close
    option forwardfor       except 127.0.0.0/8
    option                  redispatch
    retries                 3
    timeout http-request    10s
    timeout queue           1m
    timeout connect         10s
    timeout client          1m
    timeout server          1m
    timeout http-keep-alive 10s
    timeout check           10s
    maxconn                 30000
listen stats
    mode http
    bind 0.0.0.0:1080
    stats enable
    stats hide-version
    stats uri     /haproxyadmin?stats
    stats realm   Haproxy\ Statistics
    stats auth    admin:admin
    stats admin   if TRUE
frontend http-in
    bind \*:80
    mode http
    log global
    option httpclose
    option logasap
    option dontlognull
    capture request  header Host len 20
    capture request  header Referer len 60
    default_backend servers
frontend healthcheck
    bind :1099
    mode http
    option httpclose
    option forwardfor
    default_backend servers
backend servers
    balance roundrobin
    server websrv1 192.168.10.11:80 check maxconn 2000
    server websrv2 192.168.10.12:80 check maxconn 2000
&lt;/code&gt;&lt;/pre&gt;  
负载均衡MySQL服务的配置示例  
&lt;pre&gt;&lt;code&gt;
\#---------------------------------------------------------------------
\# Global settings
\#---------------------------------------------------------------------
global
    \# to have these messages end up in /var/log/haproxy.log you will
    \# need to:
    \#
    \# 1) configure syslog to accept network log events.  This is done
    \#    by adding the &#39;-r&#39; option to the SYSLOGD_OPTIONS in
    \#    /etc/sysconfig/syslog
    \#
    \# 2) configure local2 events to go to the /var/log/haproxy.log
    \#   file. A line like the following can be added to
    \#   /etc/sysconfig/syslog
    \#
    \#    local2.*                       /var/log/haproxy.log
    \#
    log         127.0.0.1 local2
    chroot      /var/lib/haproxy
    pidfile     /var/run/haproxy.pid
    maxconn     4000
    user        haproxy
    group       haproxy
    daemon
defaults
    mode                    tcp
    log                     global
    option                  httplog
    option                  dontlognull
    retries                 3
    timeout http-request    10s
    timeout queue           1m
    timeout connect         10s
    timeout client          1m
    timeout server          1m
    timeout http-keep-alive 10s
    timeout check           10s
    maxconn                 600
listen stats
    mode http
    bind 0.0.0.0:1080
    stats enable
    stats hide-version
    stats uri     /haproxyadmin?stats
    stats realm   Haproxy\ Statistics
    stats auth    admin:admin
    stats admin if TRUE
frontend mysql
    bind \*:3306
    mode tcp
    log global
    default_backend mysqlservers
backend mysqlservers
    balance leastconn
    server dbsrv1 192.168.10.11:3306 check port 3306 intval 2 rise 1 fall 2 maxconn 300
    server dbsrv2 192.168.10.12:3306 check port 3306 intval 2 rise 1 fall 2 maxconn 300
&lt;/code&gt;&lt;/pre&gt;
</content>
    
    <summary type="html">
    
      &lt;ol&gt;
&lt;li&gt;&lt;p&gt;HAProxy简介&lt;br&gt;&lt;em&gt;HAProxy提供高可用性、负载均衡以及基于TCP和HTTP应用的代理，支持虚拟主机，它是免费、快速并且可靠的一种解决方案。HAProxy特别适用于那些负载特大的web站点，这些站点通常又需要会话保持或七层处理。HAPro
    
    </summary>
    
      <category term="负载均衡" scheme="https://iceziyao.github.io/categories/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"/>
    
    
      <category term="负载均衡" scheme="https://iceziyao.github.io/tags/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"/>
    
  </entry>
  
  <entry>
    <title>高可用集群系列之基础01</title>
    <link href="https://iceziyao.github.io/2016/01/16/%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A401/"/>
    <id>https://iceziyao.github.io/2016/01/16/高可用集群01/</id>
    <published>2016-01-15T16:00:00.000Z</published>
    <updated>2016-07-10T17:39:34.715Z</updated>
    
    <content type="html">&lt;ol&gt;
&lt;li&gt;&lt;p&gt;什么是集群?  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;集群（cluster）就是一组计算机，它们作为一个整体向用户提供一组网络资源。这些单个的计算机系统就是集群的节点（node）。一个理想的集群是，用户从来不会意识到集群系统底层的节点，在他/她们看来，集群是一个系统，而非多个计算机系统。并且集群系统的管理员可以随意增加和删改集群系统的节点。&lt;br&gt;　　更详细的说，集群（一组协同工作的计算机）是充分利用计算资源的一个重要概念，因为它能够将工作负载从一个超载的系统（或节点）迁移到集群中的另一个系统上。其处理能力是与专用计算机(小型机,大型机)可相比,但其性价比高于专用计算机.常见的硬件有:结点,网络,存储.软件有:机群系统,节点系统,应用支撑软件。&lt;br&gt;　　Cluster集群技术可如下定义：一组相互独立的服务器在网络中表现为单一的系统，并以单一系统的模式加以管理。此单一系统为客户工作站提供高可靠性的服务。大多数模式下，集群中所有的计算机拥有一个共同的名称，集群内任一系统上运行的服务可被所有的网络客户所使用。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;集群系统的主要优点:  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;(1)高可扩展性：&lt;br&gt; (2)高可用性HA：集群中的一个节点失效，它的任务可传递给其他节点。可以有效防止单点失效。&lt;br&gt; (3)高性能：负载平衡集群允许系统同时接入更多的用户。&lt;br&gt; (4)高性价比：可以采用廉价的符合工业标准的硬件构造高性能的系统。  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;集群系统的分类&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;1)、高可用(High Availability)集群,简称HA集群。&lt;br&gt; 这类集群致力于提供高度可靠的服务。就是利用集群系统的容错性对外提供7*24小时不间断的服务，如高可用的文件服务器、数据库服务等关键应用。&lt;br&gt; 负载均衡集群：使任务可以在集群中尽可能平均地分摊不同的计算机进行处理，充分利用集群的处理能力，提高对任务的处理效率。&lt;br&gt; 在实际应用中这几种集群类型可能会混合使用，以提供更加高效稳定的服务。如在一个使用的网络流量负载均衡集群中，就会包含高可用的网络文件系统、高可用的网络服务。&lt;br&gt; (2)、性能计算(High Perfermance Computing)集群，简称HPC集群，也称为科学计算集群。&lt;br&gt; 在这种集群上运行的是专门开发的并行应用程序，它可以把一个问题的数据分布到多台的计算机上，利用这些计算机的共同资源来完成计算任务，从而可以解决单机不能胜任的工作（如问题规模太大，单机计算速度太慢）。&lt;br&gt; 这类集群致力于提供单个计算机所不能提供的强大的计算能力。如天气预报、石油勘探与油藏模拟、分子模拟、生物计算等。  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;什么是高可用性 (HA)&lt;blockquote&gt;
&lt;p&gt;计算机系统的可用性(availability)是通过系统的可靠性(reliability)和可维护性(maintainability)来度量的。工程上通常用平均无故障时间(MTTF)来度量系统的可靠性,用平均维修时间（MTTR）来度量系统的可维护性。于是可用性被定义为：MTTF/(MTTF+MTTR)*100%  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;HA的容错备援运作过程  &lt;blockquote&gt;
&lt;p&gt;自动侦测(Auto-Detect)阶段 由主机上的软件通过冗余侦测线，经由复杂的监听程序。逻辑判断，来相互侦测对方运行的情况，所检查的项目有：主机硬件(CPU和周边)、主机网络、主机操作系统、数据库引擎及其它应用程序、主机与磁盘阵列连线。为确保侦测的正确性，而防止错误的判断，可设定安全侦测时间，包括侦测时间间隔，侦测次数以调整安全系数，并且由主机的冗余通信连线，将所汇集的讯息记录下来，以供维护参考。&lt;br&gt;自动切换(Auto-Switch)阶段 某一主机如果确认对方故障，则正常主机除继续进行原来的任务，还将依据各种容错备援模式接管预先设定的备援作业程序，并进行后续的程序及服务。&lt;br&gt;自动恢复(Auto-Recovery)阶段 在正常主机代替故障主机工作后，故障主机可离线进行修复工作。在故障主机修复后，透过冗余通讯线与原正常主机连线，自动切换回修复完成的主机上。整个回复过程完成由EDI-HA自动完成，亦可依据预先配置，选择回复动作为半自动或不回复。  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;HA三种工作方式：  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;（1）、主从方式 （非对称方式）&lt;br&gt;工作原理：主机工作，备机处于监控准备状况；当主机宕机时，备机接管主机的一切工作，待主机恢复正常后，按使用者的设定以自动或手动方式将服务切换到主机上运行，数据的一致性通过共享存储系统解决。&lt;br&gt;（2）、双机双工方式（互备互援）&lt;br&gt;工作原理：两台主机同时运行各自的服务工作且相互监测情况，当任一台主机宕机时，另一台主机立即接管它的一切工作，保证工作实时，应用服务系统的关键数据存放在共享存储系统中。&lt;br&gt;（3）、集群工作方式（多服务器互备方式）&lt;br&gt;工作原理：多台主机一起工作，各自运行一个或几个服务，各为服务定义一个或多个备用主机，当某个主机故障时，运行在其上的服务就可以被其它主机接管。  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ol&gt;
</content>
    
    <summary type="html">
    
      &lt;ol&gt;
&lt;li&gt;&lt;p&gt;什么是集群?  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;集群（cluster）就是一组计算机，它们作为一个整体向用户提供一组网络资源。这些单个的计算机系统就是集群的节点（node）。一个理想的集群是，用户从来不会意识到集群系统底层的节点，在他/她们看来，
    
    </summary>
    
      <category term="集群" scheme="https://iceziyao.github.io/categories/%E9%9B%86%E7%BE%A4/"/>
    
    
      <category term="集群" scheme="https://iceziyao.github.io/tags/%E9%9B%86%E7%BE%A4/"/>
    
  </entry>
  
  <entry>
    <title>Memcached简介</title>
    <link href="https://iceziyao.github.io/2016/01/01/Memcached/"/>
    <id>https://iceziyao.github.io/2016/01/01/Memcached/</id>
    <published>2016-01-01T13:49:33.000Z</published>
    <updated>2016-07-10T17:39:51.275Z</updated>
    
    <content type="html">&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Memcached是一款开源、高性能、分布式内存对象缓存系统，可应用各种需要缓存的场景，其主要目的是通过降低对Database的访问来加速web应用程序。它是一个基于内存的“键值对”存储，用于存储数据库调用、API调用或页面引用结果的直接数据，如字符串、对象等。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;memcached是以LiveJournal旗下Danga Interactive 公司的Brad Fitzpatric 为首开发的一款软件。现在&lt;br&gt;已成为mixi、hatena、Facebook、Vox、LiveJournal等众多服务中提高Web应用扩展性的重要因素。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Memcached是一款开发工具，它既不是一个代码加速器，也不是数据库中间件。其设计哲学思想主要反映在如下方面：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;简单key/value存储：服务器不关心数据本身的意义及结构，只要是可序列化数据即可。存储项由“键、过期时间、可选的标志及数据”四个部分组成；  &lt;/li&gt;
&lt;li&gt;功能的实现一半依赖于客户端，一半基于服务器端：客户负责发送存储项至服务器端、从服务端获取数据以及无法连接至服务器时采用相应的动作；服务端负责接收、存储数据，并负责数据项的超时过期；  &lt;/li&gt;
&lt;li&gt;各服务器间彼此无视：不在服务器间进行数据同步；  &lt;/li&gt;
&lt;li&gt;O(1)的执行效率  &lt;/li&gt;
&lt;li&gt;清理超期数据：默认情况下，Memcached是一个LRU缓存，同时，它按事先预订的时长清理超期数据；&lt;br&gt;但事实上，memcached不会删除任何已缓存数据，只是在其过期之后不再为客户所见；&lt;br&gt;而且，memcached也不会真正按期限清理缓存，而仅是当get命令到达时检查其时长；   &lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;Memcached提供了为数不多的几个命令来完成与服务器端的交互，这些命令基于memcached的协议实现。  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;存储类命令：set, add, replace, append, prepend&lt;br&gt;获取数据类命令：get, delete, incr/decr&lt;br&gt;统计类命令：stats, stats items, stats slabs, stats sizes&lt;br&gt;清理命令： flush_all  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;一、安装libevent&lt;br&gt;memcached依赖于libevent API，因此要事先安装之，项目主页：&lt;a href=&quot;http://libevent.org/，读者可自行选择需要的版本下载。本文采用的是目前最新版本的源码包libevent-2.0.16-stable.tar.gz。安装过程：&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://libevent.org/，读者可自行选择需要的版本下载。本文采用的是目前最新版本的源码包libevent-2.0.16-stable.tar.gz。安装过程：&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
# tar xf libevent-2.0.20-stable.tar.gz
# cd libevent-2.0.20
# ./configure --prefix=/usr/local/libevent
# make &amp;&amp; make install

# echo &quot;/usr/local/libevent/lib&quot; &gt; /etc/ld.so.conf.d/libevent.conf
# ldconfig
&lt;/code&gt;&lt;/pre&gt;
二、安装配置memcached

1. 安装memcached
&lt;pre&gt;&lt;code&gt;
# tar xf memcached-1.4.15.tar.gz
# cd memcached-1.4.15
# ./configure --prefix=/usr/local/memcached --with-libevent=/usr/local/libevent
# make &amp;&amp; make install
&lt;/code&gt;&lt;/pre&gt;
2. memcached SysV的startup脚本代码如下所示，将其建立为/etc/init.d/memcached文件：
&lt;pre&gt;&lt;code&gt;
#!/bin/bash
#
# Init file for memcached
#
# chkconfig: - 86 14
# description: Distributed memory caching daemon
#
# processname: memcached
# config: /etc/sysconfig/memcached
. /etc/rc.d/init.d/functions
## Default variables
PORT=&quot;11211&quot;
USER=&quot;nobody&quot;
MAXCONN=&quot;1024&quot;
CACHESIZE=&quot;64&quot;
OPTIONS=&quot;&quot;
RETVAL=0
prog=&quot;/usr/local/memcached/bin/memcached&quot;
desc=&quot;Distributed memory caching&quot;
lockfile=&quot;/var/lock/subsys/memcached&quot;
start() {
        echo -n $&quot;Starting $desc (memcached): &quot;
        daemon $prog -d -p $PORT -u $USER -c $MAXCONN -m $CACHESIZE -o &quot;$OPTIONS&quot;
        RETVAL=$?
        echo
        [ $RETVAL -eq 0 ] &amp;&amp; touch $lockfile
        return $RETVAL
}
stop() {
        echo -n $&quot;Shutting down $desc (memcached): &quot;
        killproc $prog
        RETVAL=$?
        echo
        [ $RETVAL -eq 0 ] &amp;&amp; rm -f $lockfile
        return $RETVAL
}
restart() {
        stop
        start
}
reload() {
        echo -n $&quot;Reloading $desc ($prog): &quot;
        killproc $prog -HUP
        RETVAL=$?
        echo
        return $RETVAL
}
case &quot;$1&quot; in
  start)
        start
        ;;
  stop)
        stop
        ;;
  restart)
        restart
        ;;
  condrestart)
        [ -e $lockfile ] &amp;&amp; restart
        RETVAL=$?
        ;;       
  reload)
        reload
        ;;
  status)
        status $prog
        RETVAL=$?
        ;;
   \*)
        echo $&quot;Usage: $0 {start|stop|restart|condrestart|status}&quot;
        RETVAL=1
esac
exit $RETVAL
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用如下命令配置memcached成为系统服务：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
# chmod +x /etc/init.d/memcached
# chkconfig --add memcached
# service memcached start
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;使用telnet命令测试memcached的使用&lt;br&gt;Memcached提供一组基本命令用于基于命令行调用其服务或查看服务器状态等。&lt;br&gt;&lt;code&gt;telnet 127.0.0.1 11211&lt;/code&gt;  &lt;blockquote&gt;
&lt;p&gt;add命令：&lt;br&gt;add keyname flag  timeout  datasize&lt;br&gt;如：&lt;br&gt;add mykey 0 10 12&lt;br&gt;Hello world!&lt;br&gt;get命令：&lt;br&gt;get keyname&lt;br&gt;如：get mykey&lt;br&gt;VALUE mykey 0 12&lt;br&gt;Hello world!&lt;br&gt;END  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;4.memcached的常用选项说明&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
-l &lt;ip_addr&gt;：指定进程监听的地址；
-d: 以服务模式运行；
-u &lt;username&gt;：以指定的用户身份运行memcached进程；
-m &lt;num&gt;：用于缓存数据的最大内存空间，单位为MB，默认为64MB；
-c &lt;num&gt;：最大支持的并发连接数，默认为1024；
-p &lt;num&gt;: 指定监听的TCP端口，默认为11211；
-U &lt;num&gt;：指定监听的UDP端口，默认为11211，0表示关闭UDP端口；
-t &lt;threads&gt;：用于处理入站请求的最大线程数，仅在memcached编译时开启了支持线程才有效；
-f &lt;num&gt;：设定Slab Allocator定义预先分配内存空间大小固定的块时使用的增长因子；
-M：当内存空间不够使用时返回错误信息，而不是按LRU算法利用空间；
-n: 指定最小的slab chunk大小；单位是字节；
-S: 启用sasl进行用户认证；
&lt;/num&gt;&lt;/threads&gt;&lt;/num&gt;&lt;/num&gt;&lt;/num&gt;&lt;/num&gt;&lt;/username&gt;&lt;/ip_addr&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;三、安装Memcache的PHP扩展&lt;/p&gt;
&lt;p&gt;①安装PHP的memcache扩展&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
# tar xf memcache-2.2.5.tgz
# cd memcache-2.2.5
/usr/local/php/bin/phpize
# ./configure --with-php-config=/usr/local/php/bin/php-config --enable-memcache
# make &amp;&amp; make install
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上述安装完后会有类似以下的提示：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Installing shared extensions:     /usr/local/php/lib/php/extensions/no-debug-non-zts-20090626/  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;②编辑/usr/local/php/lib/php.ini，在“动态模块”相关的位置添加如下一行来载入memcache扩展：&lt;br&gt;extension=/usr/local/php/lib/php/extensions/no-debug-non-zts-20090626/memcache.so&lt;br&gt;而后对memcached功能进行测试，在网站目录中建立测试页面test.php，添加如下内容：  &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
&lt;?php
$mem = new Memcache;
$mem-&gt;connect(&quot;127.0.0.1&quot;, 11211)  or die(&quot;Could not connect&quot;);
$version = $mem-&gt;getVersion();
echo &quot;Server&#39;s version: &quot;.$version.&quot;&lt;br&gt;\n&quot;;
$mem-&gt;set(&#39;testkey&#39;, &#39;Hello World&#39;, 0, 600) or die(&quot;Failed to save data at the memcached server&quot;);
echo &quot;Store data in the cache (data will expire in 600 seconds)&lt;br&gt;\n&quot;;
$get_result = $mem-&gt;get(&#39;testkey&#39;);
echo &quot;$get_result is from memcached server.&quot;;         
?&gt;
&lt;/code&gt;&lt;/pre&gt;  

&lt;p&gt;如果有输出”Hello World is from memcached”&lt;br&gt;等信息，则表明memcache已经能够正常工作&lt;/p&gt;
&lt;p&gt;四. 使用libmemcached的客户端工具:&lt;/p&gt;
&lt;p&gt;访问memcached的传统方法是使用基于perl语言开发的Cache::memcached模块，这个模块在大多数perl代码中都能良好的工作，但也有着众所周知的性能方面的问题。libMemcached则是基于C语言开发的开源的C/C++代码访问memcached的库文件，同时，它还提供了数个可以远程使用的memcached管理工具，如memcat, memping，memstat，memslap等。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;编译安装libmemcached&lt;pre&gt;&lt;code&gt;
# tar xf libmemcached-1.0.2.tar.gz
# cd libmemcached-1.0.2
# ./configure
# make &amp;&amp; make install
# ldconfig
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;客户端工具&lt;pre&gt;&lt;code&gt;
# memcat --servers=127.0.0.1:11211 mykey
# memping
# memslap
# memstat
&lt;/code&gt;&lt;/pre&gt;

&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;五. Nginx整合memcached:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
server {
        listen       80;
        server_name  www.magedu.com;
        #charset koi8-r;
        #access_log  logs/host.access.log  main;
        location / {
                set $memcached_key $uri;
                memcached_pass     127.0.0.1:11211;
                default_type       text/html;
                error_page         404 @fallback;
        }
        location @fallback {
                proxy_pass http://172.16.0.1;
        }
}
&lt;/code&gt;&lt;/pre&gt;
</content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;&lt;p&gt;Memcached是一款开源、高性能、分布式内存对象缓存系统，可应用各种需要缓存的场景，其主要目的是通过降低对Database的访问来加速web应用程序。它是一个基于内存的“键值对”存储，用于存储数据库调用、API调用或页面引用结果的直接数据，如字符串、对
    
    </summary>
    
      <category term="缓存" scheme="https://iceziyao.github.io/categories/%E7%BC%93%E5%AD%98/"/>
    
    
      <category term="缓存" scheme="https://iceziyao.github.io/tags/%E7%BC%93%E5%AD%98/"/>
    
  </entry>
  
  <entry>
    <title>PHP编译出错</title>
    <link href="https://iceziyao.github.io/2016/01/01/php/"/>
    <id>https://iceziyao.github.io/2016/01/01/php/</id>
    <published>2015-12-31T16:00:00.000Z</published>
    <updated>2016-07-09T21:55:23.922Z</updated>
    
    <content type="html">&lt;pre&gt;&lt;code&gt;
   /libxmlrpc/encoding.c:101:undefined reference to &#39;libiconv_close&#39;
   　　collect2: ld returned 1 exit status
   　　make:*** [sapi/fpm/php-fpm] Error 1
   　　解决方法：
   　　#make ZEND_EXTRA_LIBS=&#39;-liconv&#39;
   　　错误一、编译php出错
   　　/php-5.3.2/ext/fileinfo/libmagic/apprentice.c:147:internal compiler
   error:Segmentation fault
   　　Please submit a full bug report,
   　　with preprocessed source if appropriate.
   　　See &lt;url:http: bugzilla.redhat.com=&quot;&quot; bugzilla=&quot;&quot;&gt; for instructions.
   　　The bug is not reproducible,so it is likely a hardware or OS problem.
   　　make:*** [ext/fileinfo/libmagic/apprentice.lo] Error 1
   　　解决方法：内存大于1G即可，这是php5.3.2的一个bug
    或者在./configure加上选项:--disable-fileinfo
    　　--------------------------------------------------------------------
    　　错误二、重新构造configure文件出错
    　　./buildconf --force
    　　Forcing buildconf
    　　buildconf:checking installation…
    　　buildconf:autoconf version 2.59 （ok）
    　　buildconf:Your version of autoconf likely contains buggy cache code.
    　　Running vcsclean for you.
    　　To avoid this,install autoconf-2.13.
    　　Can&#39;t figure out your VCS, not cleaning.
    　　解决方法：编译安装autoconf-2.13
    　　再将autoconf-2.13的auotconf文件至/usr/local/autoconf
    　　--------------------------------------------------------------------
    　　错误三、编译时缺少库
    　　configure: error: libXpm.（a|so） not found.
    　　解决方法：yum install libXpm-devel
    　　--------------------------------------------------------------------
    　　错误四、编译时缺少gmp.h文件
    　　configure: error: Unable to locate gmp.h
    　　解决方法：yum install gmp-devel
    　　--------------------------------------------------------------------
    　　错误五
    　　Configure: error: xml2-config not found. Please check your libxml2
    installation.
    　　解决方法：
    　　#yum install libxml2 libxml2-devel （For Redhat &amp; Fedora）
    　　# aptitude install libxml2-dev      （For ubuntu）
    　　--------------------------------------------------------------------
    　　错误六
    　　Checking for pkg-config… /usr/bin/pkg-config
    　　configure: error: Cannot find OpenSSL’s &lt;evp.h&gt;
    　　解决方法：
    　　#yum install openssl openssl-devel
    　　--------------------------------------------------------------------
    　　错误七
    　　Configure: error: Please reinstall the BZip2 distribution
    　　解决方法：
    　　# yum install bzip2 bzip2-devel
    　　--------------------------------------------------------------------
    　　错误八
    　　Configure: error: Please reinstall the libcurl distribution -
    　　easy.h should be in &lt;curl-dir&gt;/include/curl/
    　　解决方法：
    　　# yum install curl curl-devel   （For Redhat &amp; Fedora）
    　　# install libcurl4-gnutls-dev    （For Ubuntu）
    　　--------------------------------------------------------------------
    　　错误九：
    　　Configure: error: libjpeg.（also） not found.
    　　解决方法：
    　　# yum install libjpeg libjpeg-devel
    　　--------------------------------------------------------------------
    　　错误十
    　　Configure: error: libpng.（also） not found.
    　　--------------------------------------------------------------------
    　　解决方法：
    　　# yum install libpng libpng-devel
    　　--------------------------------------------------------------------
    　　错误十一
    　　Configure: error: freetype.h not found.
    　　解决方法：
    　　#yum install freetype-devel
    　　--------------------------------------------------------------------
    　　错误十二
    　　Configure: error: Unable to locate gmp.h
    　　解决方法：
    　　# yum install gmp-devel
    　　--------------------------------------------------------------------
    　　错误十三
    　　Configure: error: Cannot find MySQL header files under /usr.
    　　Note that the MySQL client library is not bundled anymore!
    　　解决方法：
    　　# yum install mysql-devel            （For Redhat &amp; Fedora）
    　　# apt-get install libmysql++-dev      （For Ubuntu）
    　　--------------------------------------------------------------------
    　　错误十四
    　　Configure: error: Please reinstall the ncurses distribution
    　　解决方法：
    　　# yum install ncurses ncurses-devel
    　　--------------------------------------------------------------------
    　　错误十五
    　　Checking for unixODBC support… configure: error: ODBC header file ‘
    /usr/include/sqlext.h’ not found!
    　　解决方法：
    　　# yum install unixODBC-devel
    　　--------------------------------------------------------------------
    　　错误十六
    　　Configure: error: Cannot find pspell
    　　解决方法：
    　　# yum install pspell-devel
    　　--------------------------------------------------------------------
    　　错误十七
    　　configure: error: mcrypt.h not found. Please reinstall libmcrypt.
    　　解决方法：
    　　# yum install libmcrypt libmcrypt-devel    （For Redhat &amp; Fedora）
    　　# apt-get install libmcrypt-dev
    　　--------------------------------------------------------------------
    　　错误十八
    　　Configure: error: snmp.h not found. Check your SNMP installation.
    　　解决方法：
    　　# yum install net-snmp net-snmp-devel
    　　--------------------------------------------------------------------
    　　错误十九
    　　configure:error:Cannot find ldap.h
    　　解决方法：
    　　#yum install openldap-devel openldap
    　　错误二十
    　　configure:error:xslt-config not found. Please reinstall the libxslt
    &gt;= 1.1.0 distribution
    　　解决方法：
    　　#yum install libxslt libxslt-devel
    　　错误二十一
    　　checking for libevent &gt;=1.4.11 install prefix… configure: error:
    Could not find libevent &gt;=1.4.11 in /usr/local/php
    　　解决方法：
    　　安装libevent-1.4.11以上版本至/usr/local
    　　tar xzvf libevent-1.4.14-stable.tar.gz
    　　cd libevent-1.4.14-stable
    　　./configure --prefix=/usr/local
    　　make&amp;&amp;make install
    　　在编译。/configure时添加--with-libevent-dir=/usr/local即可
    　　错误二十二
    　　cc1: out of memory allocating 2036 bytes after a total of 81846272
    bytes
    　　make: *** [ext/date/lib/parse_date.lo] Error 1
    　　报错：
    　　/usr/bin/ld: cannot find -lltdl
    　　collect2: ld returned 1 exit status
    　　make:*** [sapi/fpm/php-fpm] Error 1
    　　解决方法：
    　　安装ltdl
    　　#cd /libmcrypt-2.5.7/libltdl/
    　　#./configure --enable-ltdl-install
    　　#ldconfig
    　　#cd php-5.3.6
    　　#make ZEND_EXTRA_LIBS=&#39;-liconv&#39;
&lt;/curl-dir&gt;&lt;/evp.h&gt;&lt;/url:http:&gt;&lt;/code&gt;&lt;/pre&gt;
</content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;
   /libxmlrpc/encoding.c:101:undefined reference to &#39;libiconv_close&#39;
   　　collect2: ld returned 1 exit status
   　　make:*** [sap
    
    </summary>
    
      <category term="lnmp" scheme="https://iceziyao.github.io/categories/lnmp/"/>
    
    
      <category term="php" scheme="https://iceziyao.github.io/tags/php/"/>
    
  </entry>
  
  <entry>
    <title>nginx负载均衡</title>
    <link href="https://iceziyao.github.io/2015/12/23/nginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"/>
    <id>https://iceziyao.github.io/2015/12/23/nginx负载均衡/</id>
    <published>2015-12-23T13:49:33.000Z</published>
    <updated>2016-07-09T21:35:22.277Z</updated>
    
    <content type="html">&lt;h3 id=&quot;安装nginx&quot;&gt;&lt;a href=&quot;#安装nginx&quot; class=&quot;headerlink&quot; title=&quot;安装nginx&quot;&gt;&lt;/a&gt;安装nginx&lt;/h3&gt;&lt;p&gt;请参考&lt;a href=&quot;http://www.yaolinux.cn/blog/lnmp%25E6%259E%25B6%25E6%259E%2584.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;lnmp架构&lt;/a&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;nginx 反向代理&lt;br&gt;nginx的负载均衡基于反向代理  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;1.1 正向代理  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt; 正向代理 是一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端必须要进行一些特别的设置才能使用正向代理。  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;1.2反向代理&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;反向代理正好相反，对于客户端而言它就像是原始服务器，并且客户端不需要进行任何特别的设置。客户端向反向代理的命名空间(name-space)中的内容发送普通请求，接着反向代理将判断向何处(原始服务器)转交请求，并将获得的内容返回给客户端，就像这些内容原本就是它自己的一样。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;区别:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;正向代理的典型用途是为在防火墙内的局域网客户端提供访问Internet的途径。正向代理还可以使用缓冲特性减少网络使用率。反向代理的典型用途是将防火墙后面的服务器提供给Internet用户访问。反向代理还可以为后端的多台服务器提供负载平衡，或为后端较慢的服务器提供缓冲服务。另外，反向代理还可以启用高级URL策略和管理技术，从而使处于不同web服务器系统的web页面同时存在于同一个URL空间下。&lt;br&gt;正向代理允许客户端通过它访问任意网站并且隐藏客户端自身，因此你必须采取安全措施以确保仅为经过授权的客户端提供服务。反向代理对外都是透明的，访问者并不知道自己访问的是一个代理。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;upstream&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;2.1 负载均衡算法&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;2.1.1 轮循&lt;br&gt;当weight不指定时，各服务器weight相同，&lt;br&gt;每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。  &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
upstream bakend {
server server1.example.com;
server server2.example.com;
}
&lt;/code&gt;&lt;/pre&gt;
2.1.2 weight    
指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。
如果后端服务器down掉，能自动剔除。
比如以下配置，则1.11服务器的访问量为1.10服务器的两倍。  
&lt;pre&gt;&lt;code&gt;
upstream bakend {
server server1.example.com weight=1;
server server2.example.com weight=2;
}
&lt;/code&gt;&lt;/pre&gt;
2.1.3 ip_hash        
每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session不能跨服务器的问题。  
&lt;pre&gt;&lt;code&gt;
upstream bakend {
ip_hash
server server1.example.com;
server server2.example.com;
}
&lt;/code&gt;&lt;/pre&gt;
2.1.4 fair  
按后端服务器的响应时间来分配请求，响应时间短的优先分配。  
&lt;pre&gt;&lt;code&gt;
upstream bakend {
server server1.example.com;
server server2.example.com;
fair;
}
&lt;/code&gt;&lt;/pre&gt;
2.1.5 url_hash  
按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存服务器时比较有效。
在upstream中加入hash语句，hash_method是使用的hash算法。  
&lt;pre&gt;&lt;code&gt;
upstream bakend {
server server1.example.com;
server server2.example.com;
hash $request_uri;
hash_method crc32;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;/blockquote&gt;
&lt;p&gt;2.2 参数&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;1.down 表示单前的server暂时不参与负载&lt;br&gt;2.weight 默认为1.weight越大，负载的权重就越大。&lt;br&gt;3.max_fails ：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream 模块定义的错误&lt;br&gt;4.fail_timeout:max_fails次失败后，暂停的时间。&lt;br&gt;5.backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。&lt;br&gt;nginx支持同时设置多组的负载均衡，用来给不用的server来使用。&lt;br&gt;client_body_in_file_only 设置为On 可以讲client post过来的数据记录到文件中用来做debug&lt;br&gt;client_body_temp_path 设置记录文件的目录 可以设置最多3层目录&lt;br&gt;location 对URL进行匹配.可以进行重定向或者进行新的代理 负载均衡  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;示例&lt;br&gt;3.1 网络拓扑&lt;br&gt;反向代理服务器 server1.example.com&lt;br&gt;后端服务器：&lt;br&gt;server2.example.com&lt;br&gt;server3.example.com&lt;br&gt;3.2 配置&lt;br&gt;3.2.1 server1&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
user nginx;
worker_processes 1;
events {
 use epoll;
 worker_connections  1024;
}
http {
 include       mime.types;
 default_type  application/octet-stream;
 sendfile        on;
 keepalive_timeout  65;
 upstream nginx.com{
        server server2.example.com:80;
        server server3.example.com:80;
 }  
 server {
     listen       80;
     server_name  localhost;
     location / {
         proxy_pass http://nginx.com;
     proxy_set_header  X-Real-IP  $remote_addr;
   }
 error_page   500 502 503 504  /50x.html;
 location = /50x.html {
         root   html;
 }  
}  
}  
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
</content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;安装nginx&quot;&gt;&lt;a href=&quot;#安装nginx&quot; class=&quot;headerlink&quot; title=&quot;安装nginx&quot;&gt;&lt;/a&gt;安装nginx&lt;/h3&gt;&lt;p&gt;请参考&lt;a href=&quot;http://www.yaolinux.cn/blog/lnmp%25E6%
    
    </summary>
    
    
      <category term="nginx" scheme="https://iceziyao.github.io/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>nginx配置文件详解</title>
    <link href="https://iceziyao.github.io/2015/12/23/nginx%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/"/>
    <id>https://iceziyao.github.io/2015/12/23/nginx配置文件详解/</id>
    <published>2015-12-23T13:49:33.000Z</published>
    <updated>2016-07-10T17:39:52.170Z</updated>
    
    <content type="html">&lt;pre&gt;&lt;code&gt;


    #运行用户
    user nginx;   
    #启动进程,通常设置成和cpu的数量相等
    worker_processes  1;

    #全局错误日志及PID文件
    error_log  /var/log/nginx/error.log;
    pid        /var/run/nginx.pid;

    #工作模式及连接数上限
    events {
        use   epoll;             #epoll是多路复用IO(I/O Multiplexing)中的一种方式,但是仅用于linux2.6以上内核,可以大大提高nginx的性能
        worker_connections  1024;#单个后台worker process进程的最大并发链接数
        # multi_accept on;
    }

    #设定http服务器，利用它的反向代理功能提供负载均衡支持
    http {
         #设定mime类型,类型由mime.type文件定义
        include       /etc/nginx/mime.types;
        default_type  application/octet-stream;
        #设定日志格式
        access_log    /var/log/nginx/access.log;

        #sendfile 指令指定 nginx 是否调用 sendfile 函数（zero copy 方式）来输出文件，对于普通应用，
        #必须设为 on,如果用来进行下载等应用磁盘IO重负载应用，可设置为 off，以平衡磁盘与网络I/O处理速度，降低系统的uptime.
        sendfile        on;
        #tcp_nopush     on;

        #连接超时时间
        #keepalive_timeout  0;
        keepalive_timeout  65;
        tcp_nodelay        on;

        #开启gzip压缩
        gzip  on;
        gzip_disable &quot;MSIE [1-6]\.(?!.*SV1)&quot;;

        #设定请求缓冲
        client_header_buffer_size    1k;
        large_client_header_buffers  4 4k;

        include /etc/nginx/conf.d/*.conf;
        include /etc/nginx/sites-enabled/*;

        #设定负载均衡的服务器列表
         upstream mysvr {
        #weigth参数表示权值，权值越高被分配到的几率越大
        #本机上的Squid开启3128端口
        server 192.168.8.1:3128 weight=5;
        server 192.168.8.2:80  weight=1;
        server 192.168.8.3:80  weight=6;
        }


       server {
        #侦听80端口
            listen       80;
            #定义使用www.xx.com访问
            server_name  www.xx.com;

            #设定本虚拟主机的访问日志
            access_log  logs/www.xx.com.access.log  main;

        #默认请求
        location / {
              root   /root;      #定义服务器的默认网站根目录位置
              index index.php index.html index.htm;   #定义首页索引文件的名称

              fastcgi_pass  www.xx.com;
             fastcgi_param  SCRIPT_FILENAME  $document_root/$fastcgi_script_name;
              include /etc/nginx/fastcgi_params;
            }

        # 定义错误提示页面
        error_page   500 502 503 504 /50x.html;
            location = /50x.html {
            root   /root;
        }

        #静态文件，nginx自己处理
        location ~ ^/(images|javascript|js|css|flash|media|static)/ {
            root /var/www/virtual/htdocs;
            #过期30天，静态文件不怎么更新，过期可以设大一点，如果频繁更新，则可以设置得小一点。
            expires 30d;
        }
        #PHP 脚本请求全部转发到 FastCGI处理. 使用FastCGI默认配置.
        location ~ \.php$ {
            root /root;
            fastcgi_pass 127.0.0.1:9000;
            fastcgi_index index.php;
            fastcgi_param SCRIPT_FILENAME /home/www/www$fastcgi_script_name;
            include fastcgi_params;
        }
        #设定查看Nginx状态的地址
        location /NginxStatus {
            stub_status              on;
            access_log               on;
            auth_basic              &quot;NginxStatus&quot;;
            auth_basic_user_file  conf/htpasswd;
        }
        #禁止访问 .htxxx 文件
        location ~ /\.ht {
            deny all;
        }

         }
    }

以上是一些基本的配置,使用Nginx最大的好处就是负载均衡

如果要使用负载均衡的话,可以修改配置http节点如下：

    #设定http服务器，利用它的反向代理功能提供负载均衡支持
    http {
         #设定mime类型,类型由mime.type文件定义
        include       /etc/nginx/mime.types;
        default_type  application/octet-stream;
        #设定日志格式
        access_log    /var/log/nginx/access.log;

        #省略上文有的一些配置节点

        #。。。。。。。。。。

        #设定负载均衡的服务器列表
        upstream mysvr {
        #weigth参数表示权值，权值越高被分配到的几率越大
        server 192.168.8.1x:3128 weight=5;#本机上的Squid开启3128端口
        server 192.168.8.2x:80  weight=1;
        server 192.168.8.3x:80  weight=6;
        }

        upstream mysvr2 {
        #weigth参数表示权值，权值越高被分配到的几率越大

            server 192.168.8.x:80  weight=1;
            server 192.168.8.x:80  weight=6;
        }

       #第一个虚拟服务器
       server {
        #侦听192.168.8.x的80端口
            listen       80;
            server_name  192.168.8.x;

            #对aspx后缀的进行负载均衡请求
            location ~ .*\.aspx$ {

                root   /root;      #定义服务器的默认网站根目录位置
                index index.php index.html index.htm;   #定义首页索引文件的名称

                proxy_pass  http://mysvr ;#请求转向mysvr 定义的服务器列表

                #以下是一些反向代理的配置可删除.

                proxy_redirect off;

                #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP
                proxy_set_header Host $host;
                proxy_set_header X-Real-IP $remote_addr;
                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
                client_max_body_size 10m;       #允许客户端请求的最大单文件字节数
                client_body_buffer_size 128k;   #缓冲区代理缓冲用户端请求的最大字节数，
                proxy_connect_timeout 90;       #nginx跟后端服务器连接超时时间(代理连接超时)
                proxy_send_timeout 90;          #后端服务器数据回传时间(代理发送超时)
                proxy_read_timeout 90;          #连接成功后，后端服务器响应时间(代理接收超时)
                proxy_buffer_size 4k;           #设置代理服务器（nginx）保存用户头信息的缓冲区大小
                proxy_buffers 4 32k;            #proxy_buffers缓冲区，网页平均在32k以下的话，这样设置
                proxy_busy_buffers_size 64k;    #高负荷下缓冲大小（proxy_buffers*2）
                proxy_temp_file_write_size 64k; #设定缓存文件夹大小，大于这个值，将从upstream服务器传

           }

         }
    }

&lt;/code&gt;&lt;/pre&gt;
</content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;


    #运行用户
    user nginx;   
    #启动进程,通常设置成和cpu的数量相等
    worker_processes  1;

    #全局错误日志及PID文件
    error_log  /var/log/ngin
    
    </summary>
    
      <category term="nginx" scheme="https://iceziyao.github.io/categories/nginx/"/>
    
    
      <category term="nginx" scheme="https://iceziyao.github.io/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>ftp+mysql搭建ftp认证</title>
    <link href="https://iceziyao.github.io/2015/11/24/ftp+mysql/"/>
    <id>https://iceziyao.github.io/2015/11/24/ftp+mysql/</id>
    <published>2015-11-24T03:49:33.000Z</published>
    <updated>2016-07-09T21:38:52.331Z</updated>
    
    <content type="html">&lt;p&gt;一、安装所需要程序&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;事先安装好开发环境和mysql数据库;&lt;br&gt;&lt;code&gt;# yum -y install mysql-server mysql-devel&lt;/code&gt;&lt;br&gt;&lt;code&gt;# yum -y groupinstall &amp;quot;Development Tools&amp;quot; &amp;quot;Development Libraries&amp;quot;&lt;/code&gt;  &lt;/li&gt;
&lt;li&gt;安装pam_mysql-0.7RC1  &lt;pre&gt;&lt;code&gt;# tar zxvf  pam_mysql-0.7RC1.tar.gz
# cd  pam_mysql-0.7RC1
# ./configure --with-mysql=/usr --with-openssl
# make
# make install  
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;安装vsftpd&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;yum -y install vsftpd&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;二、创建虚拟用户账号  &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;准备数据库及相关表&lt;br&gt;首先请确保mysql服务已经正常启动。而后，按需要建立存储虚拟用户的数据库即可，这里将其创建为vsftpd数据库。  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;create database vsftpd;&lt;br&gt;grant select on vsftpd.&lt;em&gt; to vsftpd@localhost identified by ‘www.magedu.com’;&lt;br&gt;mysql&amp;gt; grant select on vsftpd.&lt;/em&gt; to vsftpd@127.0.0.1 identified by ‘www.magedu.com’;&lt;br&gt;mysql&amp;gt; flush privileges;&lt;br&gt;mysql&amp;gt; use vsftpd;&lt;br&gt;mysql&amp;gt; create table users (&lt;br&gt; -&amp;gt; id int AUTO_INCREMENT NOT NULL,&lt;br&gt; -&amp;gt; name char(20) binary NOT NULL,&lt;br&gt; -&amp;gt; password char(48) binary NOT NULL,&lt;br&gt; -&amp;gt; primary key(id)&lt;br&gt; -&amp;gt; );  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;添加测试的虚拟用户&lt;br&gt;根据需要添加所需要的用户，需要说明的是，这里将其密码采用明文格式存储，原因是pam_mysql的password()函数与MySQL的password()函数可能会有所不同.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; insert into users(name,password) values(&amp;apos;tom&amp;apos;,&amp;apos;magedu&amp;apos;);
mysql&amp;gt; insert into users(name,password) values(&amp;apos;jerry&amp;apos;,&amp;apos;magedu&amp;apos;);
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;三、配置vsftpd&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;建立pam认证所需文件&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#vi /etc/pam.d/vsftpd.mysql
添加如下两行
auth required /lib/security/pam_mysql.so   user=vsftpd passwd=www.magedu.com
host=localhost
db=vsftpd
table=users
usercolumn=name
passwdcolumn=password
crypt=0
account required /lib/security/pam_mysql.so user=vsftpd
passwd=www.magedu.com
host=localhost
db=vsftpd
table=users
usercolumn=name
passwdcolumn=password
crypt=0
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;修改vsftpd的配置文件，使其适应mysql认证&lt;br&gt;建立虚拟用户映射的系统用户及对应的目录  &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#useradd -s /sbin/nologin -d /var/ftproot vuser
#chmod go+rx /var/ftproot
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;请确保/etc/vsftpd.conf中已经启用了以下选项  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;anonymous_enable=YES&lt;br&gt;local_enable=YES&lt;br&gt;write_enable=YES&lt;br&gt;anon_upload_enable=NO&lt;br&gt;anon_mkdir_write_enable=NO&lt;br&gt;chroot_local_user=YES&lt;br&gt;而后添加以下选项&lt;br&gt;guest_enable=YES&lt;br&gt;guest_username=vuser&lt;br&gt;并确保pam_service_name选项的值如下所示&lt;br&gt;pam_service_name=vsftpd.mysql  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;四、启动vsftpd服务&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# service vsftpd start
# chkconfig vsftpd on
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;查看端口开启情况  &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# netstat -tnlp |grep :21
tcp         0      0 0.0.0.0:21              0.0.0.0:*               LISTEN      23286/vsftpd
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;使用虚拟用户登录,验正配置结果，以下为本机的命令方式测试，你也可以在其它Win Box上用IE或者FTP客户端工具登录验正  &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# ftp localhost
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;五、配置虚拟用户具有不同的访问权限&lt;br&gt;vsftpd可以在配置文件目录中为每个用户提供单独的配置文件以定义其ftp服务访问权限，每个虚拟用户的配置文件名同虚拟用户的用户名。配置文件目录可以是任意未使用目录，只需要在vsftpd.conf指定其路径及名称即可。  &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;配置vsftpd为虚拟用户使用配置文件目录&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# vim vsftpd.conf
添加如下选项
user_config_dir=/etc/vsftpd/vusers_dir
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;创建所需要目录，并为虚拟用户提供配置文件&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# mkdir /etc/vsftpd/vusers_dir/
# cd /etc/vsftpd/vusers_dir/
# touch tom jerry
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;配置虚拟用户的访问权限&lt;br&gt;虚拟用户对vsftpd服务的访问权限是通过匿名用户的相关指令进行的。比如，如果需要让tom用户具有上传文件的权限，可以修改/etc/vsftpd/vusers/tom文件，在里面添加如下选项即可。&lt;br&gt;&lt;code&gt;anon_upload_enable=YES&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;一、安装所需要程序&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;事先安装好开发环境和mysql数据库;&lt;br&gt;&lt;code&gt;# yum -y install mysql-server mysql-devel&lt;/code&gt;&lt;br&gt;&lt;code&gt;# yum -y groupinstall &amp;quot
    
    </summary>
    
      <category term="ftp" scheme="https://iceziyao.github.io/categories/ftp/"/>
    
    
      <category term="ftp" scheme="https://iceziyao.github.io/tags/ftp/"/>
    
  </entry>
  
  <entry>
    <title>Linux基础</title>
    <link href="https://iceziyao.github.io/2015/10/06/linux%E5%9F%BA%E7%A1%80/"/>
    <id>https://iceziyao.github.io/2015/10/06/linux基础/</id>
    <published>2015-10-05T16:00:00.000Z</published>
    <updated>2016-07-09T23:06:20.144Z</updated>
    
    <content type="html">&lt;h3 id=&quot;如何在linux上活下去&quot;&gt;&lt;a href=&quot;#如何在linux上活下去&quot; class=&quot;headerlink&quot; title=&quot;如何在linux上活下去&quot;&gt;&lt;/a&gt;如何在linux上活下去&lt;/h3&gt;&lt;p&gt;1.cd 命令&lt;br&gt;用于切换当前目录，它的参数是要切换到的目录的路径，可以是绝对路径，也可以是相对路径。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;cd /mnt          进入/mnt&lt;br&gt;cd ~           进入用户家目录&lt;br&gt;cd 绝对路径 or 相对路径  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;2.ls 命令&lt;br&gt;查看文件与目录的命令，list之意,常用如下:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;-l ：列出长数据串，包含文件的属性与权限数据等&lt;br&gt;&lt;br&gt;-a ：列出全部的文件，连同隐藏文件（开头为.的文件）一起列出来（常用)&lt;br&gt;&lt;br&gt;-d ：仅列出目录本身，而不是列出目录的文件数据&lt;br&gt;&lt;br&gt;-h ：将文件容量以较易读的方式（GB，kB等）列出来&lt;br&gt;-R ：连同子目录的内容一起列出（递归列出），等于该目录下的所有文件都会显示出来  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;注：这些参数也可以组合使用  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ls -l #以长数据串的形式列出当前目录下的数据文件和目录&lt;br&gt;ls -lR #以长数据串的形式列出当前目录下的所有文件   &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;3.mkdir 命令&lt;br&gt;创建目录&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;mkdir dir&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;参数：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;-p 递归创建&lt;br&gt;-m 给于权限&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;4.touch 命令&lt;br&gt;创建文件&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;touch filename&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;5.grep 命令&lt;br&gt;命令常用于分析一行的信息，若当中有我们所需要的信息，就将该行显示出来，该命令通常与管道命令一起使用，用于对一些命令的输出进行筛选加工等等&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;grep [-acinv] [–color=auto] ‘查找字符串’ filename&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;它的常用参数如下：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;-a ：将binary文件以text文件的方式查找数据&lt;br&gt;-c ：计算找到‘查找字符串’的次数&lt;br&gt;-i ：忽略大小写的区别，即把大小写视为相同&lt;br&gt;-v ：反向选择，即显示出没有‘查找字符串’内容的那一行&lt;br&gt; 例如：&lt;br&gt; 取出文件/etc/man.config中包含MANPATH的行，并把找到的关键字加上颜色&lt;br&gt;grep –color=auto ‘MANPATH’ /etc/man.config&lt;br&gt;把ls -l的输出中包含字母file（不区分大小写）的内容输出&lt;br&gt;ls -l | grep -i file&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;6.find 命令&lt;br&gt;find是一个基于查找的功能非常强大的命令，相对而言，它的使用也相对较为复杂，参数也比较多，所以在这里将给把它们分类列出，它的基本语法如下：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;find [PATH] [option] [action]&lt;br&gt;与时间有关的参数：&lt;br&gt;-mtime n : n为数字，意思为在n天之前的“一天内”被更改过的文件；&lt;br&gt;-mtime +n : 列出在n天之前（不含n天本身）被更改过的文件名；&lt;br&gt;-mtime -n : 列出在n天之内（含n天本身）被更改过的文件名；&lt;br&gt;-newer file : 列出比file还要新的文件名&lt;br&gt;例如：&lt;br&gt;find /root -mtime 0 # 在当前目录下查找今天之内有改动的文件&lt;br&gt;与用户或用户组名有关的参数：&lt;br&gt;-user name : 列出文件所有者为name的文件&lt;br&gt;-group name : 列出文件所属用户组为name的文件&lt;br&gt;-uid n : 列出文件所有者为用户ID为n的文件&lt;br&gt;-gid n : 列出文件所属用户组为用户组ID为n的文件&lt;br&gt;例如：&lt;br&gt;find /home/ljianhui -user ljianhui # 在目录/home/ljianhui中找出所有者为ljianhui的文件&lt;br&gt;与文件权限及名称有关的参数：&lt;br&gt;-name filename ：找出文件名为filename的文件&lt;br&gt;-size [+-]SIZE ：找出比SIZE还要大（+）或小（-）的文件&lt;br&gt;-tpye TYPE ：查找文件的类型为TYPE的文件，TYPE的值主要有：一般文件（f)、设备文件（b、c）、&lt;br&gt;             目录（d）、连接文件（l）、socket（s）、FIFO管道文件（p）；&lt;br&gt;-perm mode ：查找文件权限刚好等于mode的文件，mode用数字表示，如0755；&lt;br&gt;-perm -mode ：查找文件权限必须要全部包括mode权限的文件，mode用数字表示&lt;br&gt;-perm +mode ：查找文件权限包含任一mode的权限的文件，mode用数字表示&lt;br&gt;例如：&lt;br&gt;find / -name passwd # 查找文件名为passwd的文件&lt;br&gt;find . -perm 0755 # 查找当前目录中文件权限的0755的文件&lt;br&gt;find . -size +12k # 查找当前目录中大于12KB的文件，注意c表示byte&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;7.cp 命令&lt;br&gt;拷贝命令,命令用于复制文件，copy:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;   -a ：将文件的特性一起复制&lt;br&gt;    -p ：连同文件的属性一起复制，而非使用默认方式，与-a相似，常用于备份&lt;br&gt;    -i ：若目标文件已经存在时，在覆盖时会先询问操作的进行&lt;br&gt;    -r ：递归持续复制，用于目录的复制行为&lt;br&gt;    -u ：目标文件与源文件有差异时才会复制  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;8.mv 命令&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;mv oldname newname&lt;br&gt;9.ps 命令&lt;br&gt;命令用于将某个时间点的进程运行情况选取下来并输出，process之意:&lt;br&gt;-A ：所有的进程均显示出来&lt;br&gt;-a ：不与terminal有关的所有进程&lt;br&gt;-u ：有效用户的相关进程&lt;br&gt;-x ：一般与a参数一起使用，可列出较完整的信息&lt;br&gt;-l ：较长，较详细地将PID的信息列出&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;常用如下:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ps aux # 查看系统所有的进程数据&lt;br&gt;ps ax # 查看不与terminal有关的所有进程&lt;br&gt;ps -lA # 查看系统所有的进程数据&lt;br&gt;ps axjf # 查看连同一部分进程树状态  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;10.kill 命令&lt;br&gt;该命令用于向某个工作（%jobnumber）或者是某个PID（数字）传送一个信号:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;kill -signal PID&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;signal的常用参数如下：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;1：SIGHUP，启动被终止的进程&lt;br&gt; 2：SIGINT，相当于输入ctrl+c，中断一个程序的进行&lt;br&gt; 9：SIGKILL，强制中断一个进程的进行&lt;br&gt; 15：SIGTERM，以正常的结束进程方式来终止进程&lt;br&gt; 17：SIGSTOP，相当于输入ctrl+z，暂停一个进程的进行  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;11.killall 命令&lt;br&gt;命令用于向一个命令启动的进程发送一个信号，它的一般语法如下&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;killall [-iIe] [command name]&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;具体参数解释:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;-i ：交互式的意思，若需要删除时，会询问用户&lt;br&gt;-e ：表示后面接的command name要一致，但command name不能超过15个字符&lt;br&gt;-I ：命令名称忽略大小写&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;12.file 命令&lt;br&gt;用于判断接在file命令后的文件的基本数据&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;file filename&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;13.tar 命令&lt;br&gt;该命令用于对文件进行打包，默认情况并不会压缩，如果指定了相应的参数，它还会调用相应的压缩程序:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;   -c ：新建打包文件&lt;br&gt;    -t ：查看打包文件的内容含有哪些文件名&lt;br&gt;    -x ：解打包或解压缩的功能，可以搭配-C（大写）指定解压的目录，注意-c,-t,-x不能同时出现在同一条命令中&lt;br&gt;    -j ：通过bzip2的支持进行压缩/解压缩&lt;br&gt;    -z ：通过gzip的支持进行压缩/解压缩&lt;br&gt;    -v ：在压缩/解压缩过程中，将正在处理的文件名显示出来&lt;br&gt;    -f filename ：filename为要处理的文件&lt;br&gt;    -C dir ：指定压缩/解压缩的目录dir  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;14.cat 命令&lt;br&gt;用于查看文本文件的内容&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;cat filename&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;15.gcc 命令&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;-o ：output之意，用于指定生成一个可执行文件的文件名&lt;br&gt;-c ：用于把源文件生成目标文件（.o)，并阻止编译器创建一个完整的程序&lt;br&gt;-I ：增加编译时搜索头文件的路径&lt;br&gt;-L ：增加编译时搜索静态连接库的路径&lt;br&gt;-S ：把源文件生成汇编代码文件&lt;br&gt;-lm：表示标准库的目录中名为libm.a的函数库&lt;br&gt;-lpthread ：连接NPTL实现的线程库&lt;br&gt;-std= ：用于指定把使用的C语言的版本&lt;br&gt;# 把源文件test.c按照c99标准编译成可执行程序test&lt;br&gt;&lt;code&gt;gcc -o test test.c -lm -std=c99&lt;/code&gt;&lt;br&gt;#把源文件test.c转换为相应的汇编程序源文件test.s&lt;br&gt;&lt;code&gt;gcc -S test.c&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;16.rm 命令&lt;br&gt;用于删除文件或目录，remove&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;-f ：就是force的意思，忽略不存在的文件，不会出现警告消息&lt;br&gt;-i ：互动模式，在删除前会询问用户是否操作&lt;br&gt;-r ：递归删除，最常用于目录删除，它是一个非常危险的参数&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;例如&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;rm -i file&lt;/code&gt; #删除文件file，在删除之前会询问是否进行该操作&lt;br&gt;&lt;code&gt;rm -fr dir&lt;/code&gt; # 强制删除目录dir中的所有文件&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;17.chgrp命令&lt;br&gt;用于改变文件所属用户组，它的使用非常简单，它的基本用法如下：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;chgrp [-R] dirname/filename&lt;br&gt;-R ：进行递归的持续对所有文件和子目录更改&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;18.chown命令&lt;br&gt;该命令用于改变文件的所有者，与chgrp命令的使用方法相同，只是修改的文件属性不同，不再详述。&lt;/p&gt;
&lt;p&gt;19.chmod命令&lt;br&gt;该命令用于改变文件的权限，一般的用法如下：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;chmod [-R] xyz 文件或目录&lt;br&gt;-R：进行递归的持续更改，即连同子目录下的所有文件都会更改&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;20.time命令&lt;br&gt;该命令用于测算一个命令（即程序）的执行时间。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;time ./process&lt;br&gt;time ps aux&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在程序或命令运行结束后，在最后输出了三个时间，它们分别是：&lt;br&gt;user：用户CPU时间，命令执行完成花费的用户CPU时间，即命令在用户态中执行时间总和；&lt;br&gt;system：系统CPU时间，命令执行完成花费的系统CPU时间，即命令在核心态中执行时间总和；&lt;br&gt;real：实际时间，从command命令行开始执行到运行终止的消逝时间；&lt;/p&gt;
&lt;p&gt;注：用户CPU时间和系统CPU时间之和为CPU时间，即命令占用CPU执行的时间总和。实际时间要大于CPU时间，因为Linux是多任务操作系统，往往在执行一条命令时，系统还要处理其它任务。另一个需要注意的问题是即使每次执行相同命令，但所花费的时间也是不一样，其花费时间是与系统运行相关的。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;如何在linux上活下去&quot;&gt;&lt;a href=&quot;#如何在linux上活下去&quot; class=&quot;headerlink&quot; title=&quot;如何在linux上活下去&quot;&gt;&lt;/a&gt;如何在linux上活下去&lt;/h3&gt;&lt;p&gt;1.cd 命令&lt;br&gt;用于切换当前目录，它的参数是要切换到的
    
    </summary>
    
      <category term="Linux" scheme="https://iceziyao.github.io/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://iceziyao.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>ajax初探</title>
    <link href="https://iceziyao.github.io/2015/01/02/ajax/"/>
    <id>https://iceziyao.github.io/2015/01/02/ajax/</id>
    <published>2015-01-01T16:00:00.000Z</published>
    <updated>2016-07-09T21:38:45.334Z</updated>
    
    <content type="html">&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ajax简介  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;AJAX即“Asynchronous Javascript And XML”（异步JavaScript和XML），是指一种创建交互式网页应用的网页开发技术。  &lt;/li&gt;
&lt;li&gt;AJAX = 异步 JavaScript和XML（标准通用标记语言的子集）。  &lt;/li&gt;
&lt;li&gt;AJAX 是一种用于创建快速动态网页的技术。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;发展  &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在web1.0中，我们需要对页面上的数据进行更新时，需要对整个页面进行重载。这样，每次更改局部信息时，都要进行所有后台数据的全部读取。在网速缓慢的情况下，这会让用户等待时间较长。&lt;/li&gt;
&lt;li&gt;在web2.0下，我们可以设想这样一种方式，局部的更改数据，而不是加载整个页面。&lt;br&gt;2.1 如何更改页面信息呢？&lt;br&gt;可以使用js，它可以将页面上的元素进行更改。学过前端的都知道，js是可以获取到页面元素，并且修改元素的。&lt;br&gt;2.2 如何与后台进行交互？&lt;br&gt;那么，我们必须向后台进行请求，可以用个超链接&lt;code&gt;&amp;lt;a href=&amp;#39;#&amp;#39; title=&amp;#39;&amp;#39; target=_blank&amp;lt;/a&amp;gt;&lt;/code&gt;,向后台请求。那么问题来了，页面上的很多东西都会改变，都用超链接？这不现实。&lt;br&gt;可不可以让js和后台通过一种机制，直接交互呢？所以ajax产生了。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;工作原理&lt;br&gt;Ajax的原理简单来说通过XmlHttpRequest对象来向服务器发异步请求，从服务器获得数据，然后用javascript来操作DOM而更新页面。这其中最关键的一步就是从服务器获得请求数据。&lt;br&gt;XMLHttpRequest是ajax的核心机制，它是在IE5中首先引入的，是一种支持异步请求的技术。简单的说，也就是javascript可以及时向服务器提出请求和处理响应，而不阻塞用户。达到无刷新的效果。    &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;所以我们先从XMLHttpRequest讲起，来看看它的工作原理。&lt;br&gt;　  首先，我们先来看看XMLHttpRequest这个对象的属性。&lt;br&gt;　　它的属性有:  &lt;ul&gt;
&lt;li&gt;onreadystatechange  每次状态改变所触发事件的事件处理程序。&lt;/li&gt;
&lt;li&gt;responseText     从服务器进程返回数据的字符串形式。&lt;/li&gt;
&lt;li&gt;responseXML    从服务器进程返回的DOM兼容的文档数据对象。&lt;/li&gt;
&lt;li&gt;status           从服务器返回的数字代码，比如常见的404（未找到）和200（已就绪）&lt;/li&gt;
&lt;li&gt;status Text       伴随状态码的字符串信息&lt;/li&gt;
&lt;li&gt;readyState       对象状态值  &lt;blockquote&gt;
&lt;p&gt;0 (未初始化) 对象已建立，但是尚未初始化（尚未调用open方法）&lt;br&gt;　　 1 (初始化) 对象已建立，尚未调用send方法&lt;br&gt;　　 2 (发送数据) send方法已调用，但是当前的状态及http头未知&lt;br&gt;　　 3 (数据传送中) 已接收部分数据，因为响应及http头不全，这时通过responseBody和responseText获取部分数据会出现错误，&lt;br&gt;　　4 (完成) 数据接收完毕,此时可以通过通过responseXml和responseText获取完整的回应数据  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;ajax的使用&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;创建XMLHTTPReq&lt;/li&gt;
&lt;li&gt;发送数据&lt;/li&gt;
&lt;li&gt;&lt;p&gt;接受回调数据&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
var XMLHttpReq=null;
//创建Ajax引擎对象
function createXMLHttpRequest() {
 try {
        XMLHttpReq = new ActiveXObject(&quot;Msxml2.XMLHTTP&quot;);//IE高版本创建XMLHTTP
     }
     catch(E) {
        try {
               XMLHttpReq = new ActiveXObject(&quot;Microsoft.XMLHTTP&quot;);//IE低版本创建XMLHTTP
        }
        catch(E) {
               XMLHttpReq = new XMLHttpRequest();//兼容非IE浏览器，直接创建XMLHTTP对象
        }
      }
}
//向后台发送数据
function sendGetAjaxRequest(url,text) {
      createXMLHttpRequest();                                //创建XMLHttpRequest对象
      XMLHttpReq.open(&quot;get&quot;, url+&quot;?&quot;+encodeURI(text), true);
     XMLHttpReq.onreadystatechange = doResult; //指定响应函数
     XMLHttpReq.send(null);
}
function sendPOSTAjaxRequest(url,text) {
      createXMLHttpRequest();                                //创建XMLHttpRequest对象
      XMLHttpReq.open(&quot;post&quot;, url, true);
      XMLHttpReq.setRequestHeader(&quot;Content-type&quot;, &quot;application/x-www-form-urlencoded&quot;);
      XMLHttpReq.setRequestHeader(&quot;Content-length&quot;, text.length);
      XMLHttpReq.setRequestHeader(&quot;Connection&quot;, &quot;close&quot;);
      XMLHttpReq.onreadystatechange = doResult; //指定响应函数
      XMLHttpReq.send(null);
}
function doResult() {
   if (XMLHttpReq.readyState == 4 &amp;&amp; XMLHttpReq.status == 200) {
     //4代表执行完成                
     //200代表执行成功，删除当前表格

   }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;ajax的优缺点&lt;ul&gt;
&lt;li&gt;优点：&lt;ul&gt;
&lt;li&gt;就是能在不更新整个页面的前提下维护数据。这使得Web应用程序更为迅捷地回应用户动作，并避免了在网络上发送那些没有改变过的信息。&lt;/li&gt;
&lt;li&gt;异步非阻塞&lt;/li&gt;
&lt;li&gt;可以把以前一些服务器负担的工作转嫁到客户端，利用客户端闲置的能力来处理，减轻服务器和带宽的负担，节约空间和宽带租用成本。并且减轻服务器的负担，ajax的原则是“按需取数据”，可以最大程度的减少冗余请求，和响应对服务器造成的负担。&lt;/li&gt;
&lt;li&gt;基于标准化的并被广泛支持的技术，不需要下载插件或者小程序。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;缺点：&lt;ul&gt;
&lt;li&gt;用户不知道数据是否更新&lt;/li&gt;
&lt;li&gt;无法回退&lt;/li&gt;
&lt;li&gt;安全问题&lt;br&gt;任何数据处理在前端，都会暴露后台&lt;/li&gt;
&lt;li&gt;对串流媒体的支持没有FLASH、Java Applet好;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;&lt;p&gt;ajax简介  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;AJAX即“Asynchronous Javascript And XML”（异步JavaScript和XML），是指一种创建交互式网页应用的网页开发技术。  &lt;/li&gt;
&lt;li&gt;AJAX = 异步 JavaSc
    
    </summary>
    
      <category term="前端" scheme="https://iceziyao.github.io/categories/%E5%89%8D%E7%AB%AF/"/>
    
    
      <category term="ajax" scheme="https://iceziyao.github.io/tags/ajax/"/>
    
  </entry>
  
</feed>
