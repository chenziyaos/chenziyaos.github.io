<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>羽非衣</title>
  <subtitle>心静如水</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://iceziyao.github.io/"/>
  <updated>2016-08-06T14:48:39.012Z</updated>
  <id>https://iceziyao.github.io/</id>
  
  <author>
    <name>陈子瑶</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Ycm，我的自动化运维之路</title>
    <link href="https://iceziyao.github.io/2016/06/17/Ycm%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"/>
    <id>https://iceziyao.github.io/2016/06/17/Ycm自动化运维/</id>
    <published>2016-06-16T16:00:00.000Z</published>
    <updated>2016-08-06T14:48:39.012Z</updated>
    
    <content type="html">&lt;h3 id=&quot;我的运维之路&quot;&gt;&lt;a href=&quot;#我的运维之路&quot; class=&quot;headerlink&quot; title=&quot;我的运维之路&quot;&gt;&lt;/a&gt;我的运维之路&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;手动ssh&lt;br&gt;每次弄服务器时，总是ssh连上去，执行命令   &lt;/li&gt;
&lt;li&gt;脚本&lt;br&gt;把自己要执行的命令写入脚本&lt;/li&gt;
&lt;li&gt;python&lt;br&gt;python提供了很多东西&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;pssh等类库&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;自动化运维工具&lt;br&gt;4.1 ansible&lt;br&gt;4.2 puppet&lt;br&gt;4.3 saltstack&lt;/li&gt;
&lt;li&gt;写一个属于自己的自动化运维平台&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;Ycm是一个基于python的B-S自动化运维平台&quot;&gt;&lt;a href=&quot;#Ycm是一个基于python的B-S自动化运维平台&quot; class=&quot;headerlink&quot; title=&quot;Ycm是一个基于python的B/S自动化运维平台&quot;&gt;&lt;/a&gt;Ycm是一个基于python的B/S自动化运维平台&lt;/h3&gt;&lt;p&gt;当然，我也是站在巨人的肩膀上完成这个任务。感谢bingbing大神的代码，以及刘天斯的&amp;lt;&amp;lt;自动化运维&amp;gt;&amp;gt;一书&lt;br&gt;项目地址&lt;a href=&quot;https://github.com/iceziYao/Ycm&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Ycm,我的自动化运维之路 &lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&quot;Ycm简介&quot;&gt;&lt;a href=&quot;#Ycm简介&quot; class=&quot;headerlink&quot; title=&quot;Ycm简介&quot;&gt;&lt;/a&gt;Ycm简介&lt;/h4&gt;&lt;h5 id=&quot;1-平台功能介绍&quot;&gt;&lt;a href=&quot;#1-平台功能介绍&quot; class=&quot;headerlink&quot; title=&quot;1.平台功能介绍&quot;&gt;&lt;/a&gt;1.平台功能介绍&lt;/h5&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt; 作为ITIL体系当中的一部分，本平台同样遵循ITIL标准设计规范。Ycm是本平台的名称，为了向vim伟大插件YouCompleteM致敬。Ycm实现了一个集中式的linux集群管理基础平台，提供了模块化的支持，可以随意增加集群操作任务模块，可实现日常运维远程操作，文件分发等任务，在安全方面，目前采用md5指令传输，操作日志记录，分离web server与主控设备，在效率方面，管理员只需要操作指定目标即可完成。另外采用ajax，已及mvc结构的实现。具有高度的可扩展性. &lt;/strong&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&quot;2-系统架构设计&quot;&gt;&lt;a href=&quot;#2-系统架构设计&quot; class=&quot;headerlink&quot; title=&quot;2.系统架构设计&quot;&gt;&lt;/a&gt;2.系统架构设计&lt;/h5&gt;&lt;p&gt;Ycm平台采用三层设计模式&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;第一层为Web交互层，采用Django+jquery,服务器端采用Nginx+uwsgi构建高效的web服务&lt;/li&gt;
&lt;li&gt;第二层业务逻辑层，有Python+Django  &lt;/li&gt;
&lt;li&gt;第三层为服务层&lt;br&gt;3.1 存储采用mysql&lt;br&gt;3.2 自动化运维ansible/Saltstack api&lt;br&gt;3.3 监控采用zabbix api&lt;br&gt;3.4 运维审计  &lt;/li&gt;
&lt;/ol&gt;
&lt;h5 id=&quot;3-数据库设计&quot;&gt;&lt;a href=&quot;#3-数据库设计&quot; class=&quot;headerlink&quot; title=&quot;3.数据库设计&quot;&gt;&lt;/a&gt;3.数据库设计&lt;/h5&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;用户列表  &lt;/p&gt;
&lt;ul&gt;

   &lt;td&gt;username&lt;/td&gt; &lt;td&gt;password&lt;/td&gt;

&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;资产管理&lt;br&gt;2.1 服务列表&lt;br&gt;&lt;ul&gt;&lt;td&gt;厂商&lt;/td&gt;&lt;td&gt;产品型号   &lt;/td&gt;&lt;td&gt;序列号&lt;/td&gt;&lt;td&gt;CPU型号&lt;/td&gt;&lt;td&gt;CPU线程数&lt;/td&gt;&lt;td&gt;CPU物理核数&lt;/td&gt;&lt;td&gt;内存大小&lt;/td&gt;&lt;td&gt;硬盘大小&lt;/td&gt;&lt;br&gt;&lt;td&gt;RAID级别&lt;/td&gt;&lt;br&gt;&lt;td&gt;主机名&lt;/td&gt;&lt;br&gt;&lt;td&gt;IP地址&lt;/td&gt;&lt;br&gt;&lt;td&gt;MAC地址&lt;/td&gt;&lt;br&gt;&lt;td&gt;操作系统&lt;/td&gt;&lt;br&gt;&lt;td&gt;是否为虚拟机&lt;/td&gt;&lt;br&gt;&lt;td&gt;所属机房&lt;/td&gt;

&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;br&gt;2.2 主机列表  &lt;/p&gt;
&lt;ul&gt;&lt;br&gt;&lt;br&gt;      &lt;td&gt;IP地址&lt;/td&gt;&lt;br&gt;      &lt;td&gt;主机名&lt;/td&gt;&lt;br&gt;      &lt;td&gt;产品&lt;/td&gt;&lt;br&gt;      &lt;td&gt;应用&lt;/td&gt;&lt;br&gt;      &lt;td&gt;机柜编号&lt;/td&gt;&lt;br&gt;      &lt;td&gt;使用状态&lt;/td&gt;&lt;br&gt;      &lt;td&gt;是否虚拟机&lt;/td&gt;&lt;br&gt;&lt;br&gt;&lt;/ul&gt;&lt;br&gt;2.3 IDC机房信息&lt;br&gt;&lt;ul&gt;&lt;br&gt;    &lt;td&gt;机房名称&lt;/td&gt;&lt;br&gt;      &lt;td&gt;机房类型&lt;/td&gt;&lt;br&gt;      &lt;td&gt;机房位置&lt;/td&gt;&lt;br&gt;      &lt;td&gt;合同时间&lt;/td&gt;&lt;br&gt;      &lt;td&gt;联系电话&lt;/td&gt;&lt;br&gt;      &lt;td&gt;备注&lt;/td&gt;&lt;br&gt; &lt;/ul&gt;&lt;br&gt;3. 运维审计&lt;br&gt;&lt;ul&gt;&lt;br&gt;   &lt;tr&gt;&lt;br&gt;      &lt;td&gt;操作人员&lt;/td&gt;&lt;br&gt;      &lt;td&gt;时间&lt;/td&gt;&lt;br&gt;        &lt;td&gt;类型&lt;/td&gt;&lt;br&gt;        &lt;td&gt;动作&lt;/td&gt;&lt;br&gt;        &lt;td&gt;执行IP&lt;/td&gt;&lt;br&gt;      &lt;td&gt;内容&lt;/td&gt;&lt;br&gt;   &lt;/tr&gt;&lt;br&gt; &lt;/ul&gt;

&lt;h4 id=&quot;Ycm开发环境&quot;&gt;&lt;a href=&quot;#Ycm开发环境&quot; class=&quot;headerlink&quot; title=&quot;Ycm开发环境&quot;&gt;&lt;/a&gt;Ycm开发环境&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;cestos 7.0&lt;/li&gt;
&lt;li&gt;python 2.75&lt;/li&gt;
&lt;li&gt;Django 1.85&lt;/li&gt;
&lt;li&gt;ansible/Saltstack/Func(其一) api&lt;/li&gt;
&lt;li&gt;clobbe&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&quot;功能简介&quot;&gt;&lt;a href=&quot;#功能简介&quot; class=&quot;headerlink&quot; title=&quot;功能简介&quot;&gt;&lt;/a&gt;功能简介&lt;/h4&gt;&lt;h5 id=&quot;装机管理&quot;&gt;&lt;a href=&quot;#装机管理&quot; class=&quot;headerlink&quot; title=&quot;装机管理&quot;&gt;&lt;/a&gt;装机管理&lt;/h5&gt;&lt;p&gt;略&lt;/p&gt;
&lt;h5 id=&quot;资产管理&quot;&gt;&lt;a href=&quot;#资产管理&quot; class=&quot;headerlink&quot; title=&quot;资产管理&quot;&gt;&lt;/a&gt;资产管理&lt;/h5&gt;&lt;p&gt;略&lt;/p&gt;
&lt;h5 id=&quot;服务部署&quot;&gt;&lt;a href=&quot;#服务部署&quot; class=&quot;headerlink&quot; title=&quot;服务部署&quot;&gt;&lt;/a&gt;服务部署&lt;/h5&gt;&lt;p&gt;略&lt;/p&gt;
&lt;h5 id=&quot;运维审计&quot;&gt;&lt;a href=&quot;#运维审计&quot; class=&quot;headerlink&quot; title=&quot;运维审计&quot;&gt;&lt;/a&gt;运维审计&lt;/h5&gt;&lt;p&gt;略&lt;/p&gt;
&lt;h5 id=&quot;监控&quot;&gt;&lt;a href=&quot;#监控&quot; class=&quot;headerlink&quot; title=&quot;监控&quot;&gt;&lt;/a&gt;监控&lt;/h5&gt;&lt;p&gt;zabbix api  &lt;/p&gt;
&lt;h5 id=&quot;日志分析&quot;&gt;&lt;a href=&quot;#日志分析&quot; class=&quot;headerlink&quot; title=&quot;日志分析&quot;&gt;&lt;/a&gt;日志分析&lt;/h5&gt;</content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;我的运维之路&quot;&gt;&lt;a href=&quot;#我的运维之路&quot; class=&quot;headerlink&quot; title=&quot;我的运维之路&quot;&gt;&lt;/a&gt;我的运维之路&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;手动ssh&lt;br&gt;每次弄服务器时，总是ssh连上去，执行命令   &lt;/li&gt;
&lt;li&gt;脚本&lt;br&gt;把自己要执行的命令写入脚本&lt;/li&gt;
&lt;li&gt;python&lt;br&gt;python提供了很多东西&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;pssh等类库&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;自动化运维工具&lt;br&gt;4.1 ansible&lt;br&gt;4.2 puppet&lt;br&gt;4.3 saltstack&lt;/li&gt;
&lt;li&gt;写一个属于自己的自动化运维平台
    
    </summary>
    
      <category term="运维" scheme="https://iceziyao.github.io/categories/%E8%BF%90%E7%BB%B4/"/>
    
    
      <category term="Python" scheme="https://iceziyao.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Python GIL那些事</title>
    <link href="https://iceziyao.github.io/2016/05/21/Python/Python_GIL/"/>
    <id>https://iceziyao.github.io/2016/05/21/Python/Python_GIL/</id>
    <published>2016-05-20T16:00:00.000Z</published>
    <updated>2016-08-06T14:49:25.694Z</updated>
    
    <content type="html">&lt;h2 id=&quot;GIL是什么？&quot;&gt;&lt;a href=&quot;#GIL是什么？&quot; class=&quot;headerlink&quot; title=&quot;GIL是什么？&quot;&gt;&lt;/a&gt;GIL是什么？&lt;/h2&gt;&lt;p&gt;GIL并不是Python的特性，它是在实现Python解析器(CPython)时所引入的一个概念。就好比C++是一套语言（语法）标准，但是可以用不同的编译器来编译成可执行代码。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CPython实现中的GIL？&lt;blockquote&gt;
&lt;p&gt;Global Interpreter Lock  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In CPython, the global interpreter lock, or GIL, is a mutex that prevents multiple native threads from executing Python bytecodes at once. This lock is necessary mainly because CPython’s memory management is not thread-safe. (However, since the GIL exists, other features have grown to depend on the guarantees that it enforces.)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;一个防止多线程并发执行机器码的一个Mutex&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt; 看起来就像一个BUG &lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;python为什么使用GIL的机制&quot;&gt;&lt;a href=&quot;#python为什么使用GIL的机制&quot; class=&quot;headerlink&quot; title=&quot;python为什么使用GIL的机制?&quot;&gt;&lt;/a&gt;python为什么使用GIL的机制?&lt;/h2&gt;&lt;p&gt;由于物理上得限制，各CPU厂商在核心频率上的比赛已经被多核所取代。为了更有效的利用多核处理器的性能，&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;多核时代的出现对于我们程序员而言意味着什么, 我们如何利用多核的优势?&lt;br&gt;可以采用 多进程, 也可以采用 多线程. 二者的最大区别就是, 是否共享资源, 后者是共享资源的,而前者是独立的. 所以你也可能想起了google chrome为什么又开始使用独立的进程 来作为每个tab服务了(不共享数据,意味着有更好的安全性).&lt;br&gt;相对于进程的轻型特征,多线程环境有个最大的问题就是 如何保证&lt;strong&gt;资源竞争,死锁, 数据修改&lt;/strong&gt;等.&lt;br&gt;于是,便有了 线程安全 (thread safety)的提出.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;线程安全&quot;&gt;&lt;a href=&quot;#线程安全&quot; class=&quot;headerlink&quot; title=&quot;线程安全&quot;&gt;&lt;/a&gt;线程安全&lt;/h3&gt;&lt;p&gt;线程安全 是在多线程的环境下, 线程安全能够保证多个线程同时执行时程序依旧运行正确, 而且要保证对于共享的数据,可以由多个线程存取,但是同一时刻只能有一个线程进行存取.&lt;br&gt;既然,多线程环境下必须存在资源的竞争,那么如何才能保证同一时刻只有一个线程对共享资源进行存取?&lt;br&gt;加锁, 对, 加锁可以保证存取操作的唯一性, 从而保证同一时刻只有一个线程对共享数据存取.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;通常加锁也有2种不同的粒度的锁:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;fine-grained(所谓的细粒度), 那么程序员需要自行地加,解锁来保证线程安全  &lt;/li&gt;
&lt;li&gt;coarse-grained(所谓的粗粒度), 那么语言层面本身维护着一个全局的锁机制,用来保证线程安全&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;前一种方式比较典型的是 java, Jython 等, 后一种方式比较典型的是 CPython (即Python).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;Python的GIL&quot;&gt;&lt;a href=&quot;#Python的GIL&quot; class=&quot;headerlink&quot; title=&quot;Python的GIL&quot;&gt;&lt;/a&gt;Python的GIL&lt;/h3&gt;&lt;p&gt;GIL是必要的，因为CPython的内存管理是非线程安全的。你不能简单地创建多个线程，并希望Python能在多核心的机器上运行得更快。这是因为GIL將会防止多个原生线程同时执行Python字节码。换句话说，GIL將序列化您的所有线程。然而，您可以使用线程管理多个派生进程加速程序，这些程序独立的运行于你的Python代码外。  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;过程&lt;br&gt;全局解释器锁（global interpreter lock）如其名运行在解释器主循环中，在多线程环境下，任何一条线程想要执行代码的时候，都必须获取（acquire）到这个锁，运行一定数量字节码，然后释放（release）掉，然后再尝试获取。这样 GIL 就保证了同时只有一条线程在执行。  &lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;GIL带来的性能问题&quot;&gt;&lt;a href=&quot;#GIL带来的性能问题&quot; class=&quot;headerlink&quot; title=&quot;GIL带来的性能问题&quot;&gt;&lt;/a&gt;GIL带来的性能问题&lt;/h4&gt;&lt;p&gt;一般来说，GIL 并不会带来麻烦，因为大多数程序的性能瓶颈都在 IO 上（IO-bound）。  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;顺序执行的单线程(single_thread.py)&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;11&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;12&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;13&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;14&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;15&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;16&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;17&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;18&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;19&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;20&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;21&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;#! /usr/bin/python&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;from threading import Thread&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;import time&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;def my_counter():&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  i = 0&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  for _ in range(100000000):&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    i = i + 1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  return True&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;def main():&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  thread_array = &amp;#123;&amp;#125;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  start_time = time.time()&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  for tid in range(2):&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    t = Thread(target=my_counter)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    t.start()&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    thread_array[tid] = t&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  for i in range(2):&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    thread_array[i].join()&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  end_time = time.time()&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  print(&amp;quot;Total time: &amp;#123;&amp;#125;&amp;quot;.format(end_time - start_time))&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;if __name__ == &amp;apos;__main__&amp;apos;:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  main()&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;同时执行的两个并发线程(multi_thread.py)&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;11&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;12&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;13&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;14&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;15&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;16&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;17&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;18&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;19&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;20&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;21&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;#! /usr/bin/python&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;from threading import Thread&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;import time&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;def my_counter():&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  i = 0&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  for _ in range(100000000):&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    i = i + 1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  return True&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;def main():&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  thread_array = &amp;#123;&amp;#125;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  start_time = time.time()&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  for tid in range(2):&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    t = Thread(target=my_counter)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    t.start()&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    thread_array[tid] = t&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  for i in range(2):&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    thread_array[i].join()&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  end_time = time.time()&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  print(&amp;quot;Total time: &amp;#123;&amp;#125;&amp;quot;.format(end_time - start_time))&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;if __name__ == &amp;apos;__main__&amp;apos;:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  main()&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;GIL设计上带来的缺陷&quot;&gt;&lt;a href=&quot;#GIL设计上带来的缺陷&quot; class=&quot;headerlink&quot; title=&quot;GIL设计上带来的缺陷&quot;&gt;&lt;/a&gt;GIL设计上带来的缺陷&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;基于pcode数量的调度方式&lt;br&gt;按照Python社区的想法，操作系统本身的线程调度已经非常成熟稳定了，没有必要自己搞一套。所以Python的线程就是C语言的一个pthread，并通过操作系统调度算法进行调度（例如linux是CFS）。为了让各个线程能够平均利用CPU时间，python会计算当前已执行的微代码数量，达到一定阈值后就强制释放GIL。而这时也会触发一次操作系统的线程调度（当然是否真正进行上下文切换由操作系统自主决定）。&lt;pre&gt;&lt;code class=&quot;+python&quot;&gt;while True:
  acquire GIL
  for i in 1000:
      do something
  release GIL
&lt;/code&gt;&lt;/pre&gt;
这种模式在只有一个CPU核心的情况下毫无问题。任何一个线程被唤起时都能成功获得到GIL（因为只有释放了GIL才会引发线程调度）。但当CPU有多个核心的时候，问题就来了。从伪代码可以看到，从 release GIL 到 acquire GIL 之间几乎是没有间隙的。所以当其他在其他核心上的线程被唤醒时，大部分情况下主线程已经又再一次获取到GIL了。这个时候被唤醒执行的线程只能白白的浪费CPU时间，看着另一个线程拿着GIL欢快的执行着。然后达到切换时间后进入待调度状态，再被唤醒，再等待，以此往复恶性循环。  &lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;为什么一定要用GIL&quot;&gt;&lt;a href=&quot;#为什么一定要用GIL&quot; class=&quot;headerlink&quot; title=&quot;为什么一定要用GIL&quot;&gt;&lt;/a&gt;为什么一定要用GIL&lt;/h4&gt;&lt;p&gt;参考其他实现的话，你可能会问一个问题，为什么要使用全局锁，而不是一个更细粒度的锁呢？实际上 Linux 的文件系统就是这样做的，进程给目标文件加锁的时候，可以只加一定字节数的锁，只要另一个进程准备加的锁与其没有交集的话，这两个锁就可以共存，这两个进程也可以同时修改这一个文件（的不同部分）。因此对于 Python，也许可以给对象加锁，同时不限制线程的并行执行。但从网上的信息来看，似乎这种思路曾经被尝试实现过，但细粒度的锁会给单线程模式下的性能造成明显影响。  &lt;/p&gt;
&lt;h3 id=&quot;如何避免python-GIL带来的性能影响&quot;&gt;&lt;a href=&quot;#如何避免python-GIL带来的性能影响&quot; class=&quot;headerlink&quot; title=&quot;如何避免python GIL带来的性能影响&quot;&gt;&lt;/a&gt;如何避免python GIL带来的性能影响&lt;/h3&gt;&lt;h4 id=&quot;用multiprocess替代Thread&quot;&gt;&lt;a href=&quot;#用multiprocess替代Thread&quot; class=&quot;headerlink&quot; title=&quot;用multiprocess替代Thread&quot;&gt;&lt;/a&gt;用multiprocess替代Thread&lt;/h4&gt;&lt;p&gt;multiprocess库的出现很大程度上是为了弥补thread库因为GIL而低效的缺陷。它完整的复制了一套thread所提供的接口方便迁移。唯一的不同就是它使用了多进程而不是多线程。每个进程有自己的独立的GIL，因此也不会出现进程之间的GIL争抢。&lt;br&gt;当然multiprocess也不是万能良药。它的引入会增加程序实现时线程间数据通讯和同步的困难。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;如果我们要多个线程累加同一个变量，对于thread来说，申明一个global变量，用thread.Lock的context包裹住三行就搞定了。而multiprocess由于进程之间无法看到对方的数据，只能通过在主线程申明一个Queue，put再get或者用share memory的方法。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;用其他解析器&quot;&gt;&lt;a href=&quot;#用其他解析器&quot; class=&quot;headerlink&quot; title=&quot;用其他解析器&quot;&gt;&lt;/a&gt;用其他解析器&lt;/h4&gt;&lt;p&gt;既然GIL只是CPython的产物，那么其他解析器是不是更好呢？没错，像JPython这样的解析器由于实现语言的特性，他们不需要GIL的帮助，程序员自身加锁。但这些解析器太小众，会失去很多第三方的支持。有得必有失，所以看自己的选择。  &lt;/p&gt;
&lt;h4 id=&quot;指定CPU运行&quot;&gt;&lt;a href=&quot;#指定CPU运行&quot; class=&quot;headerlink&quot; title=&quot;指定CPU运行&quot;&gt;&lt;/a&gt;指定CPU运行&lt;/h4&gt;&lt;p&gt;在linux下，也可以用taskset命令来设置进程运行的CPU  &lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;GIL是什么？&quot;&gt;&lt;a href=&quot;#GIL是什么？&quot; class=&quot;headerlink&quot; title=&quot;GIL是什么？&quot;&gt;&lt;/a&gt;GIL是什么？&lt;/h2&gt;&lt;p&gt;GIL并不是Python的特性，它是在实现Python解析器(CPython)时所引入的一个概念。就好比C++是一套语言（语法）标准，但是可以用不同的编译器来编译成可执行代码。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CPython实现中的GIL？&lt;blockquote&gt;
&lt;p&gt;Global Interpreter Lock  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In CPython, the global interpreter lock, or GIL, is a mutex that prevents multiple native threads from executing Python bytecodes at once. This lock is necessary mainly because CPython’s memory management is not thread-safe. (However, since the GIL exists, other features have grown to depend on the guarantees that it enforces.)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;一个防止多线程并发执行机器码的一个Mutex&lt;/p&gt;
    
    </summary>
    
      <category term="Python" scheme="https://iceziyao.github.io/categories/Python/"/>
    
    
      <category term="Python" scheme="https://iceziyao.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Python的内存管理机制</title>
    <link href="https://iceziyao.github.io/2016/05/21/Python/python01/"/>
    <id>https://iceziyao.github.io/2016/05/21/Python/python01/</id>
    <published>2016-05-20T16:00:00.000Z</published>
    <updated>2016-08-06T14:49:28.945Z</updated>
    
    <content type="html">&lt;h2 id=&quot;python的内存管理分为三个方面：&quot;&gt;&lt;a href=&quot;#python的内存管理分为三个方面：&quot; class=&quot;headerlink&quot; title=&quot;python的内存管理分为三个方面：&quot;&gt;&lt;/a&gt;python的内存管理分为三个方面：&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;em&gt;引用计数&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;垃圾回收&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;内存池机制&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h2 id=&quot;浅析引用计数&quot;&gt;&lt;a href=&quot;#浅析引用计数&quot; class=&quot;headerlink&quot; title=&quot;浅析引用计数&quot;&gt;&lt;/a&gt;浅析引用计数&lt;/h2&gt;&lt;p&gt;python内部使用引用计数，来保持追踪内存中的对象，Python内部记录了对象有多少个引用，即引用计数，当对象被创建时就创建了一个引用计数，当对象不再需要时，这个对象的引用计数为0时，它被垃圾回收。  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;引用计数增加的情况：  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;1.对象被创建：x=4&lt;br&gt;2.另外的别人被创建：y=x&lt;br&gt;3.被作为参数传递给函数：foo(x)&lt;br&gt;4.作为容器对象的一个元素：a=[1,x,’33’]  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;引用计数减少情况  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;1.一个本地引用离开了它的作用域。比如上面的foo(x)函数结束时，x指向的对象引用减1。&lt;br&gt;2.对象的别名被显式的销毁：del x ；或者del y&lt;br&gt;3.对象的一个别名被赋值给其他对象：x=789&lt;br&gt;4.对象从一个窗口对象中移除：myList.remove(x)&lt;br&gt;5.窗口对象本身被销毁：del myList，或者窗口对象本身离开了作用域。  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;如何获取一个变量的引用计数&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
&gt;&gt; import sys
&gt;&gt; x = 1
&gt;&gt; sys.getrefcount(x)
599
&gt;&gt; y = x
&gt;&gt; sys.getrefcount(x)
600
&gt;&gt; del y
&gt;&gt; sys.getrefcount(x)
599
&lt;/code&gt;&lt;/pre&gt;

&lt;/blockquote&gt;
&lt;h2 id=&quot;垃圾回收&quot;&gt;&lt;a href=&quot;#垃圾回收&quot; class=&quot;headerlink&quot; title=&quot;垃圾回收&quot;&gt;&lt;/a&gt;垃圾回收&lt;/h2&gt;&lt;p&gt;python的垃圾回收机制以引用计数为主，标记-清除和分代收集为辅。  &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;引用计数&lt;br&gt;优点：“实时性”，任何内存，一旦没有指向它的引用，就会立即被回收。&lt;br&gt;缺点：&lt;br&gt;(1). 效率底下：引用计数机制带来的计数操作，与引用赋值成正比。频繁的技术操作，会给CPU带来大量消耗。&lt;br&gt;(2). 循环引用：也就是两个对象相互引用，这样的话，两个对象的引用计数永远不会为0，及它们永远不被清除。  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;标记-清除&lt;br&gt;标记-清除是为了解决循环引用的问题。可以包含其他对象引用的容器对象（比如：list，set，dict，class，instance）都可能产生循环引用。&lt;br&gt;2.1 假设&lt;br&gt;如果两个对象的引用计数都为1的话，但仅仅存在它们之间的相互引用，那么，我们可以认为这两个对象的实际引用计数为0.如果我们将这个引用循环去掉，那么它们的实际引用计数才会显现。&lt;br&gt;案例：有循环引用的A,B两个对象，从A出发，因为它有一个对B的引用，则将B的引用计数减1；然后顺着引用达到B，因为B有一个对A的引用，同样将A的引用减1，这样，就完成了循环引用对象间环摘除。&lt;br&gt;问题：如果A,B间没有循环引用，但A引用了B，B没有以用A，贸然的将B计数引用减1，而A没有被回收，这将导致在未来的某个时刻出现一个对B的悬空引用，类似与C的空指针异常。这就要求我们必须在A没有被删除的情况下复原B的引用计数，那么维护引用计数的复杂度将成倍增加。&lt;br&gt;2.2 标记-清除的原理&lt;br&gt;原理：&lt;br&gt;我们并不改动真实的引用计数，而是将集合中对象的引用计数复制一份副本，改动该对象引用的副本。对于副本做任何的改动，都不会影响到对象生命走起的维护。&lt;br&gt;这个计数副本的唯一作用是寻找root object集合（该集合中的对象是不能被回收的）。当成功寻找到root object集合之后，首先将现在的内存链表一分为二，一条链表中维护root object集合，成为root链表，而另外一条链表中维护剩下的对象，成为unreachable链表。之所以要剖成两个链表，是基于这样的一种考虑：现在的unreachable可能存在被root链表中的对象，直接或间接引用的对象，这些对象是不能被回收的，一旦在标记的过程中，发现这样的对象，就将其从unreachable链表中移到root链表中；当完成标记后，unreachable链表中剩下的所有对象就是名副其实的垃圾对象了，接下来的垃圾回收只需限制在unreachable链表中即可。&lt;br&gt;效率分析：&lt;br&gt;从垃圾收集机制来看，这种垃圾收集机制所带来的额外操作实际上与系统中总的内存块的数量是相关的，当需要回收的内存块越多时，垃圾检测带来的额外操作就越多，而垃圾回收带来的额外操作就越少；反之，当需回收的内存块越少时，垃圾检测就将比垃圾回收带来更少的额外操作。  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;分代回收&lt;br&gt;3.1 理论：&lt;br&gt;无论使用何种语言开发，无论开发的是何种类型，何种规模的程序，都存在这样一点相同之处。即：一定比例的内存块的生存周期都比较短，通常是几百万条机器指令的时间，而剩下的内存块，起生存周期比较长，甚至会从程序开始一直持续到程序结束。&lt;br&gt;3.2 原理：&lt;br&gt;将系统中的所有内存块根据其存活时间划分为不同的集合，每一个集合就成为一个“代”，垃圾收集的频率随着“代”的存活时间的增大而减小。也就是说，活得越长的对象，就越不可能是垃圾，就应该减少对它的垃圾收集频率。那么如何来衡量这个存活时间：通常是利用几次垃圾收集动作来衡量，如果一个对象经过的垃圾收集次数越多，可以得出：该对象存活时间就越长。也就是符合马太福音，存活久的让它继续存活下去。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;内存池机制&quot;&gt;&lt;a href=&quot;#内存池机制&quot; class=&quot;headerlink&quot; title=&quot;内存池机制&quot;&gt;&lt;/a&gt;内存池机制&lt;/h2&gt;&lt;p&gt;Python的内存机制以金字塔层次：  &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;内存分配层次：  &lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;　　-1，-2层主要有操作系统进行操作，  
　&lt;/em&gt;　第0层是C中的malloc，free等内存分配和释放函数进行操作；&lt;br&gt;　&lt;em&gt;　第1层和第2层是内存池，有Python的接口函数PyMem_Malloc函数实现，当对象小于256K时有该层直接分配内存；  
　&lt;/em&gt; 　第3层是最上层，也就是我们对Python对象的直接操作；  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;原因  &lt;ul&gt;
&lt;li&gt;在 C 中如果频繁的调用 malloc 与 free 时,是会产生性能问题的.再加上频繁的分配与释放小块的内存会产生内存碎片。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;具现化&lt;br&gt;Python提供了对内存的垃圾收集机制，但是它将不用的内存放到内存池而不是返回给操作系统。&lt;br&gt;　　Python中所有小于256个字节的对象都使用pymalloc实现的分配器，而大的对象则使用系统的 malloc。另外Python对象，如整数，浮点数和List，都有其独立的私有内存池，对象间不共享他们的内存池。也就是说如果你分配又释放了大量的整数，用于缓存这些整数的内存就不能再分配给浮点数。&lt;br&gt;　　在Python中，许多时候申请的内存都是小块的内存，这些小块内存在申请后，很快又会被释放，由于这些内存的申请并不是为了创建对象，所以并没有对象一级的内存池机制。这就意味着Python在运行期间会大量地执行malloc和free的操作，频繁地在用户态和核心态之间进行切换，这将严重影响 Python的执行效率。为了加速Python的执行效率，Python引入了一个内存池机制，用于管理对小块内存的申请和释放。这也就是之前提到的 Pymalloc机制。&lt;br&gt;　　Pymalloc 关于释放内存方面，当一个对象的 引用计数变为0时，python就会调用它的析构函数。在析构时，也采用了内存池机制，从内存池来的内存会被归还到内存池中，以避免频繁地释放动作。&lt;br&gt;　　Pymalloc分配一系列256KB的内存块，称之为arena。每个arena分割为4KB大小的内存池Pool，每个Pool再切分为固定大小的Block。在内存分配时，分配给进程的就是这些Blocks。&lt;br&gt;&lt;a href=&quot;http://nodefe.com/implement-of-pymalloc-from-source/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;需要了解Pymalloc的看这篇博文&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;python的内存管理分为三个方面：&quot;&gt;&lt;a href=&quot;#python的内存管理分为三个方面：&quot; class=&quot;headerlink&quot; title=&quot;python的内存管理分为三个方面：&quot;&gt;&lt;/a&gt;python的内存管理分为三个方面：&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;em&gt;引用计数&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;垃圾回收&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;内存池机制&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="Python" scheme="https://iceziyao.github.io/categories/Python/"/>
    
    
      <category term="Python" scheme="https://iceziyao.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>初探node.js</title>
    <link href="https://iceziyao.github.io/2016/05/06/nodejs/"/>
    <id>https://iceziyao.github.io/2016/05/06/nodejs/</id>
    <published>2016-05-06T13:49:33.000Z</published>
    <updated>2016-08-06T14:49:13.900Z</updated>
    
    <content type="html">&lt;h3 id=&quot;什么是node-js&quot;&gt;&lt;a href=&quot;#什么是node-js&quot; class=&quot;headerlink&quot; title=&quot;什么是node.js&quot;&gt;&lt;/a&gt;什么是node.js&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;node.js != Javascript&lt;br&gt;事实上，Node.js采用C++语言编写而成，是一个Javascript的运行环境。  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Node.js 是构建于Chrome的JavaScript引擎的&lt;br&gt;Google的浏览器Chrome，有一个非常快速的JavaScript引擎，叫做V8。这个JS引擎可以被独立出来，该解释器拥有另一个独特特征；可以下载该引擎并将其嵌入任何 应用程序。Node.js就是建立在V8之上的。这也是为什么Node.js会运行的如此之快。对于开发者来说，有几个好处：&lt;ul&gt;
&lt;li&gt;js完全通用&lt;/li&gt;
&lt;li&gt;v8的发展影响着node.js&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Node.js 不仅仅是一个网页服务器或者平台&lt;br&gt;Node.js 不是以网页为中心的。Node.js 是通用目的的JS运行时，带有很多功能强大的库。其中有一个库提供了 HTTP/HTTPS 的实现。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Node.js是面向对象的&lt;br&gt;Node.js的实质就是用Javascript的代码规范通过C++进行了实现和封装。一般在前端用js时，无非是ajax以及特效，仅仅针对一个页面。所以，不用面向对象也可以完成，但在后台，我们常用一些代码，所以进行封装，等用的时候新建一个对象。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;node.js能做什么？&lt;br&gt;正如 JavaScript 为客户端而生，Node.js 为网络而生。Node.js 能做的远不止开发一个网站那么简单，使用 Node.js，你可以轻松地开发：  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt; 具有复杂逻辑的网站；&lt;br&gt; 基于社交网络的大规模 Web 应用；&lt;br&gt; Web Socket 服务器；&lt;br&gt; TCP/UDP 套接字应用程序；&lt;br&gt; 命令行工具；&lt;br&gt; 交互式终端程序；&lt;br&gt; 带有图形用户界面的本地应用程序；&lt;br&gt; 单元测试工具；&lt;br&gt; 客户端 JavaScript 编译器。  &lt;/p&gt;
&lt;p&gt;Node.js 内建了 HTTP 服务器支持，也就是说你可以轻而易举地实现一个网站和服务器的组合。这和 PHP、Perl 不一样，因为在使用 PHP 的时候，必须先搭建一个 Apache 之类的HTTP 服务器，然后通过 HTTP 服务器的模块加载或 CGI 调用，才能将 PHP 脚本的执行结果呈现给用户。而当你使用 Node.js 时，不用额外搭建一个 HTTP 服务器，因为 Node.js 本身就内建了一个。这个服务器不仅可以用来调试代码，而且它本身就可以部署到产品环境，它的性能足以满足要求。&lt;br&gt;Node.js 还可以部署到非网络应用的环境下，比如一个命令行工具  。Node.js 还可以调用C/C++ 的代码，这样可以充分利用已有的诸多函数库，也可以将对性能要求非常高的部分用C/C++ 来实现。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;node.js的原理  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;单线程&lt;/li&gt;
&lt;li&gt;异步非阻塞&lt;/li&gt;
&lt;li&gt;事件驱动&lt;br&gt;用高并发解释  &lt;blockquote&gt;
&lt;p&gt;一般来说，高并发解决方案会提供多线程模型，为每个业务逻辑提供一个线程，通过系统线程切换来来弥补同步I/O调用的时间开销。node.js使用的是单线程模型，对所有I/O都采用异步的请求方式，避免频繁的上下文切换，在node.js执行的时候维护着一个事件队列；程序在执行时进入事件循环等待下一个事件到来，每个异步I/O请求完成后都会被推送到事件队列中的等待执行。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;例子：&lt;br&gt;对于一个简单的数据库访问操作，传统方式是这样实现的   &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;res = db.query(&amp;apos;SELECT * from some_table&amp;apos;);
res.output();
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;代码执行到第一行的时候线程会阻塞，等待query返回结果，然后继续处理。由于数据库查询、磁盘读写、网络通信等原因（所谓的I/O）阻塞时间会非常大（相对于CPU始终频率）。对于高并发的访问，一方面线程长期阻塞等待，另一方面为了应付新情求而不断添加新线程，会浪费大量系统资源，同时线程的增加也会也会占用大量的CPU时间来处理内存上下文切换。&lt;br&gt;node.js的处理方式：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;db.query(&amp;apos;SELECT * from some_table&amp;apos;，function(res) {   
        res.output();  
});  
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;query的第二个参数是一个回调函数，进程执行到db.query的时候不会等待结果返回，而是直接继续执行下面的语句，直到进入事件循环。当数据库执行结果返回的时候会将事件发送到事件队列，等到线程进入事件循环后才会调用之前的回调函数。&lt;br&gt;node.js的异步机制是基于事件的，所有的I/O、网络通信、数据库查询都以非阻塞的方式执行，返回结果由事件循环来处理。node.js在同一时刻只会处理一个事件，完成后立即进入事件循环检查后面事件。这样CPU和内存在同一时间集中处理一件事，同时尽量让耗时的I/O等操作并行执行。   &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;事件循环机制&lt;br&gt;所谓事件循环是指node.js会把所有的异步操作使用事件机制解决，有个线程在不断地循环检测事件队列。&lt;br&gt;node.js中所有的逻辑都是事件的回调函数，所以node.js始终在事件循环中，程序入口就是事件循环第一个事件的回调函数。事件的回调函数中可能会发出I/O请求或直接发射（ emit）事件，执行完毕后返回事件循环。事件循环会检查事件队列中有没有未处理的事件，直到程序结束。node.js的事件循环对开发者不可见，由libev库实现，libev不断检查是否有活动的、可供检测的事件监听器，直到检查不到时才退出事件循环，程序结束。   &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;node.js的优缺点&lt;ul&gt;
&lt;li&gt;优点：&lt;ul&gt;
&lt;li&gt;简单&lt;/li&gt;
&lt;li&gt;高性能，避免了频繁的线程切换开销，一个线程而已&lt;/li&gt;
&lt;li&gt;占用资源小，因为是单线程，在大负荷情况下，对内存占用仍然很低&lt;/li&gt;
&lt;li&gt;线程安全，没有加锁、解锁、死锁这些问题&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;缺点：&lt;ul&gt;
&lt;li&gt;CPU密集型任务存在短板&lt;br&gt;  事件循环机制，处理所有的请求。在事件处理过程中，它会智能地将一些涉及到IO、网络通信等耗时比较长的操作，交由worker threads去执行，执行完了再回调。但是，那些非IO操作，只用CPU计算的操作，就只能自己抗了。&lt;/li&gt;
&lt;li&gt;无法利用CPU的多核&lt;br&gt;  Node.js是单线程程序，它只有一个event loop，也只占用一个CPU/内核。&lt;/li&gt;
&lt;li&gt;如果有异常抛出，因为是单线程，整个项目将不可用&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
</content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;什么是node-js&quot;&gt;&lt;a href=&quot;#什么是node-js&quot; class=&quot;headerlink&quot; title=&quot;什么是node.js&quot;&gt;&lt;/a&gt;什么是node.js&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;node.js != Javascript&lt;br&gt;事实上，Node.js采用C++语言编写而成，是一个Javascript的运行环境。  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Node.js 是构建于Chrome的JavaScript引擎的&lt;br&gt;Google的浏览器Chrome，有一个非常快速的JavaScript引擎，叫做V8。这个JS引擎可以被独立出来，该解释器拥有另一个独特特征；可以下载该引擎并将其嵌入任何 应用程序。Node.js就是建立在V8之上的。这也是为什么Node.js会运行的如此之快。对于开发者来说，有几个好处：&lt;ul&gt;
&lt;li&gt;js完全通用&lt;/li&gt;
&lt;li&gt;v8的发展影响着node.js
    
    </summary>
    
      <category term="后台" scheme="https://iceziyao.github.io/categories/%E5%90%8E%E5%8F%B0/"/>
    
    
      <category term="node.js" scheme="https://iceziyao.github.io/tags/node-js/"/>
    
  </entry>
  
  <entry>
    <title>python编写一个端口扫描器</title>
    <link href="https://iceziyao.github.io/2016/05/01/Python/python%E7%AB%AF%E5%8F%A3/"/>
    <id>https://iceziyao.github.io/2016/05/01/Python/python端口/</id>
    <published>2016-04-30T16:00:00.000Z</published>
    <updated>2016-08-06T14:49:31.890Z</updated>
    
    <content type="html">&lt;h3 id=&quot;编写一个端口扫描器&quot;&gt;&lt;a href=&quot;#编写一个端口扫描器&quot; class=&quot;headerlink&quot; title=&quot;编写一个端口扫描器&quot;&gt;&lt;/a&gt;编写一个端口扫描器&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;任何一个靠谱的网络攻击，都是起步于侦察。所以攻击服务器，也就是检查服务的漏洞。我使用的两种方式无非是web注入和端口扫描。所以先编写一个端口扫描器&lt;/li&gt;
&lt;li&gt;端口扫描是基于TCP的，一共分为三个步骤，分别编写三个方法：  &lt;ul&gt;
&lt;li&gt;处理数据，也就是处理用户输入数据的，此处我们定义为main函数，用来获取主机名和端口  &lt;/li&gt;
&lt;li&gt;将主机名转换为对应的IPv4互联网地址，采socket.gethostbyname(hostname),获取到IP,然后调用处理端口扫描的函数.定义为portScan(tgtHost,tgtPorts)&lt;/li&gt;
&lt;li&gt;端口扫描，也是就TCP的全连接，对目标地址和端口进行连接。最后为了确定该端口上运行的什么服务，我们还会发送垃圾信息，并读取返回的Banner.函数定义为connScan(tgtHost,tgtPort)&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;实现端口扫描器&quot;&gt;&lt;a href=&quot;#实现端口扫描器&quot; class=&quot;headerlink&quot; title=&quot;实现端口扫描器&quot;&gt;&lt;/a&gt;实现端口扫描器&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;main函数&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;11&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;12&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;13&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;14&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;15&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;16&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;17&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;18&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;19&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;20&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;21&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;22&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;23&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;24&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;25&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;26&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;27&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;28&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;29&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;30&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;31&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;32&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;33&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;34&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;35&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;36&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;37&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;38&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;39&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;40&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;41&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;42&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;43&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;44&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;45&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;46&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;47&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;48&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;def main():&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    parser = optparse.OptionParser(&amp;quot;usage: %prog&amp;quot; + \&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;-H &amp;lt;tgtHost host&amp;gt; -P &amp;lt;tgtPort&amp;gt;&amp;quot; ,version=&amp;quot;%prog 1.0&amp;quot;)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;apos;&amp;apos;&amp;apos; 添加命令行参 &amp;apos;&amp;apos;&amp;apos;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    parser.add_option(&amp;apos;-H&amp;apos;,dest=&amp;apos;Host&amp;apos;,type=&amp;apos;string&amp;apos;,help=&amp;apos;specify target host&amp;apos;)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    parser.add_option(&amp;apos;-P&amp;apos;,dest=&amp;apos;Port&amp;apos;,type=&amp;apos;string&amp;apos;,\&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    help=&amp;apos;specify target port[s] separated by command&amp;apos;)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    (options ,args) = parser.parse_args()&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    tgtHost = options.Host&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    tgtPorts = str(options.Port).split(&amp;quot;,&amp;quot;)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    if (tgtHost == None) or (tgtPorts[0] == None):&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        print &amp;apos;[-] You must specify a target host and port[s]&amp;apos;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        exit(0)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    portScan(tgtHost,tgtPorts)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt;  &lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2. portScan(tgtHost,tgtPorts)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;lt;pre&amp;gt;&amp;lt;code&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;def portScan(tgtHost,tgtPorts):&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    try:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      tgtIP = gethostbyname(tgtHost)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    except:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      print &amp;quot;[-] cannot resolve &amp;apos;%s&amp;apos;:Unknown host&amp;quot; %(tgtHost)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    try:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      tgtName = gethostbyaddr(tgtIP)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      print &amp;apos;\n[+] Scan Reselts for:&amp;apos; + tgtName[0]&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    except:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      print &amp;apos;\n[+] Scan Results for: &amp;apos;+ tgtIP&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    setdefaulttimeout(1)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    for tgtPort in tgtPorts:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      connScan(tgtHost,tgtPort)  &lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3. connScan(tgtHost, tgtPort)  &lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;lt;pre&amp;gt;&amp;lt;code&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;def connScan(tgtHost, tgtPort):&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    try:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        connSkt = socket(AF_INET,SOCK_STREAM)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        connSkt.connect((tgtHost,tgtPort))&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        connSkt.send(&amp;apos;Hello\r\n&amp;apos;)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        results = connSkt.recv(100)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        lock.acquire()&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        print &amp;quot;[+]%d/TCP open&amp;quot; %(tgtPort)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        print &amp;quot;[+] &amp;quot;+str(results)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    except:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        lock.acquire()&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        print &amp;quot;[-]%d/TCP closed&amp;quot; %(tgtPort)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    finally:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        lock.release()&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        connSkt.close()&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;使用&lt;br&gt;运行后如下结果  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;python portscanner.py -H localhost -P 21,22&lt;br&gt;[+] Scan Reselts for:localhost&lt;br&gt;[+]22/TCP open&lt;br&gt;[+] SSH-2.0-OpenSSH_6.4&lt;br&gt;[+]21/TCP open&lt;br&gt;[+] 220 (vsFTPd 3.0.2)  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;优化&quot;&gt;&lt;a href=&quot;#优化&quot; class=&quot;headerlink&quot; title=&quot;优化&quot;&gt;&lt;/a&gt;优化&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;线程优化&lt;br&gt;采用多线程扫描  &lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;for tgtPort in tgtPorts:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    t=threading.Thread(target=connScan,args=(tgtIP,int(tgtPort)))&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    t.start()&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这让扫描速度有了很大改进，但又是一个缺点，多个线程同时打印输出，可能出现乱码和失序。我们需要一个信号量来控制，这样代码就会变成这样：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;11&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;12&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;13&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;14&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;15&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;16&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;17&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;18&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;19&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;20&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;21&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;22&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;23&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;24&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;25&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;26&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;27&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;28&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;29&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;30&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;31&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;32&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;33&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;import threading&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;import multiprocessing&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;lock = multiprocessing.Semaphore(value=1) #锁&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;def connScan(tgtHost, tgtPort):&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    try:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        connSkt = socket(AF_INET,SOCK_STREAM)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        connSkt.connect((tgtHost,tgtPort))&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        connSkt.send(&amp;apos;Hello\r\n&amp;apos;)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        results = connSkt.recv(100)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        lock.acquire()&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        print &amp;quot;[+]%d/TCP open&amp;quot; %(tgtPort)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        print &amp;quot;[+] &amp;quot;+str(results)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    except:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        lock.acquire()&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        print &amp;quot;[-]%d/TCP closed&amp;quot; %(tgtPort)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    finally:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        lock.release()&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        connSkt.close()&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;def portScan(tgtHost,tgtPorts):&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    try:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        tgtIP = gethostbyname(tgtHost)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    except:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        print &amp;quot;[-] cannot resolve &amp;apos;%s&amp;apos;:Unknown host&amp;quot; %(tgtHost)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    try:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        tgtName = gethostbyaddr(tgtIP)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        print &amp;apos;\n[+] Scan Reselts for:&amp;apos; + tgtName[0]&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    except:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        print &amp;apos;\n[+] Scan Results for: &amp;apos;+ tgtIP&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    setdefaulttimeout(1)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    for tgtPort in tgtPorts:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        #print &amp;apos;Scanning port &amp;apos; + tgtPort&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        t=threading.Thread(target=connScan,args=(tgtIP,int(tgtPort)))&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        t.start()&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;完整代码请参考&lt;a href=&quot;https://github.com/iceziYao/Grocery/blob/master/portscanner.py&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;portscanner.py&lt;/a&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;使用nmap端口扫描代码&lt;br&gt;2.1 下载Python-Nmap&lt;br&gt;&lt;code&gt;pip install Python-Nmap&lt;/code&gt;&lt;br&gt;2.2 实现&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;import nmap&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;import optparse&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;from socket import *&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;import os,sys&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;def nmapScan(tgtHost,tgtPort):&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      nmScan = nmap.PortScanner()&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      nmScan.scan(tgtHost,tgtPort)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      status = nmScan[tgtHost][&amp;apos;tcp&amp;apos;][int(tgtPort)][&amp;apos;state&amp;apos;]&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      print &amp;apos;[!] %s tcp/%s %s&amp;apos; %(tgtHost,tgtPort,status)&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;详细代码查看&lt;a href=&quot;https://github.com/iceziYao/Grocery/blob/master/nmapport.py&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;nmapport.py&lt;/a&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;编写一个端口扫描器&quot;&gt;&lt;a href=&quot;#编写一个端口扫描器&quot; class=&quot;headerlink&quot; title=&quot;编写一个端口扫描器&quot;&gt;&lt;/a&gt;编写一个端口扫描器&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;任何一个靠谱的网络攻击，都是起步于侦察。所以攻击服务器，也就是检查服务的漏洞。我使用的两种方式无非是web注入和端口扫描。所以先编写一个端口扫描器&lt;/li&gt;
&lt;li&gt;端口扫描是基于TCP的，一共分为三个步骤，分别编写三个方法：  &lt;ul&gt;
&lt;li&gt;处理数据，也就是处理用户输入数据的，此处我们定义为main函数，用来获取主机名和端口  &lt;/li&gt;
&lt;li&gt;将主机名转换为对应的IPv4互联网地址，采socket.gethostbyname(hostname),获取到IP,然后调用处理端口扫描的函数.定义为portScan(tgtHost,tgtPorts)&lt;/li&gt;
&lt;li&gt;端口扫描，也是就TCP的全连接，对目标地址和端口进行连接。最后为了确定该端口上运行的什么服务，我们还会发送垃圾信息，并读取返回的Banner.函数定义为connScan(tgtHost,tgtPort)
    
    </summary>
    
      <category term="Python" scheme="https://iceziyao.github.io/categories/Python/"/>
    
    
      <category term="Python" scheme="https://iceziyao.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>浅析docker实现思想</title>
    <link href="https://iceziyao.github.io/2016/04/04/Docker/docker02/"/>
    <id>https://iceziyao.github.io/2016/04/04/Docker/docker02/</id>
    <published>2016-04-03T16:00:00.000Z</published>
    <updated>2016-08-06T14:50:37.949Z</updated>
    
    <content type="html">&lt;h2 id=&quot;从虚拟化的种类和层级说起&quot;&gt;&lt;a href=&quot;#从虚拟化的种类和层级说起&quot; class=&quot;headerlink&quot; title=&quot;从虚拟化的种类和层级说起&quot;&gt;&lt;/a&gt;从虚拟化的种类和层级说起&lt;/h2&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;cpu虚拟化：可以模拟不同CPU，例如bochs&lt;/li&gt;
&lt;li&gt;完全虚拟化：只能模拟同样CPU，但是可以执行不同系统，例如vmware&lt;/li&gt;
&lt;li&gt;半虚拟化&lt;/li&gt;
&lt;li&gt;硬件虚拟化：可以当作获得硬件加速的完全虚拟化&lt;/li&gt;
&lt;li&gt;系统虚拟化：host和guest共享一样的内核，例如Openvz&lt;/li&gt;
&lt;li&gt;语言沙盒：只能在语言的范围内使用&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;虚拟化的级别越偏底层，速度越慢，用户越难察觉到虚拟化的存在。 虚拟化的级别越偏上层，速度越快，用户越容易感知。也就是虚拟幻的包装，如何一个虚拟化完全包装底层，呈现给用户一个新的操作系统，那么用户会知道他用的什么吗？&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;cpu虚拟化和完全虚拟化时，用户几乎可以阿不察觉到虚拟化的存在&lt;/li&gt;
&lt;li&gt;半虚拟化时，guest内核必须存在补丁&lt;ul&gt;
&lt;li&gt;系统虚拟化时，用户不能控制自己的内核&lt;/li&gt;
&lt;li&gt;语言沙盒时，用户没有使用api的自由&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;docker的原理&quot;&gt;&lt;a href=&quot;#docker的原理&quot; class=&quot;headerlink&quot; title=&quot;docker的原理&quot;&gt;&lt;/a&gt;docker的原理&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;doceker实现结构&lt;br&gt;–&amp;gt;lxc&lt;br&gt;–&amp;gt;namespace: 仅沙盒隔离，不限制资源。&lt;br&gt;–&amp;gt;cgroup: 仅限制资源，不沙盒隔离。&lt;br&gt;–&amp;gt;aufs&lt;br&gt;–&amp;gt;image管理  &lt;/li&gt;
&lt;li&gt;底层技术&lt;blockquote&gt;
&lt;p&gt;Docker使用Go语言编写，并且使用了一系列Linux内核提供的性能来实现我们已经看到的这些功能。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;lxc&lt;blockquote&gt;
&lt;p&gt;LXC是Linux containers的简称，是一种基于容器的操作系统层级的虚拟化技术,linux原生支持的容器.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;XC可以在操作系统层次上为进程提供的虚拟的执行环境，一个虚拟的执行环境就是一个容器。可以为容器绑定特定的cpu和memory节点，分配特定比例的cpu时间、IO时间，限制可以使用的内存大小（包括内存和是swap空间），提供device访问控制，提供独立的namespace（网络、pid、ipc、mnt、uts）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;命名空间(Namespaces)&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Docker充分利用了一项称为namespaces的技术来提供隔离的工作空间，我们称之为 container(容器)。当你运行一个容器的时候，Docker为该容器创建了一个命名空间集合。其实我们在c++也见过类似的namespace    &lt;/li&gt;
&lt;li&gt;这样提供了一个隔离层，每一个应用在它们自己的命名空间中运行而且不会访问到命名空间之外。&lt;br&gt;通俗来讲，就是给将每一个应用放在小房子的，也就是容器，使不同应用不会冲突。  &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一些Docker使用到的命名空间有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;pid命名空间: 使用在进程隔离(PID: Process ID)。&lt;/li&gt;
&lt;li&gt;net命名空间: 使用在管理网络接口(NET: Networking&lt;/li&gt;
&lt;li&gt;ipc命名空间: 使用在管理进程间通信资源 (IPC: InterProcess Communication)&lt;/li&gt;
&lt;li&gt;mnt命名空间: 使用在管理挂载点 (MNT: Mount)。&lt;/li&gt;
&lt;li&gt;uts命名空间: 使用在隔离内核和版本标识 (UTS: Unix Timesharing System)。&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;群组控制(cgroup)&lt;blockquote&gt;
&lt;p&gt;Docker还使用到了cgroups技术来管理群组。使应用隔离运行的关键是让它们只使用你想要的资源。这样可以确保在机器上运行的容器都是良民(good multi-tenant citizens)。群组控制允许Docker分享或者限制容器使用硬件资源。例如，限制指定的容器的内容使用&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;联合文件系统(UnionFS)&lt;blockquote&gt;
&lt;p&gt;联合文件系统(UnionFS)是用来操作创建层的，使它们轻巧快速。Docker使用UnionFS提供容器的构造块。Docker可以使用很多种类的UnionFS包括AUFS, btrfs, vfs, and DeviceMapper。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;结语&quot;&gt;&lt;a href=&quot;#结语&quot; class=&quot;headerlink&quot; title=&quot;结语&quot;&gt;&lt;/a&gt;结语&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;为什么使用go语言实现docker&lt;br&gt;部署简单，依赖性小，开发效率高(相比C/C++)，性能好(相比JAVA)  &lt;/li&gt;
&lt;li&gt;docker与LXC的联系&lt;br&gt;在我理解，docker是LXC的一个高速引擎&lt;/li&gt;
&lt;li&gt;为什么我只解析了docker实现思想&lt;br&gt;我不会go语言，也不了解LXC，我只是一个使用者，只是在自己的理解下探讨docker实现了什么。&lt;/li&gt;
&lt;/ul&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;从虚拟化的种类和层级说起&quot;&gt;&lt;a href=&quot;#从虚拟化的种类和层级说起&quot; class=&quot;headerlink&quot; title=&quot;从虚拟化的种类和层级说起&quot;&gt;&lt;/a&gt;从虚拟化的种类和层级说起&lt;/h2&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;cpu虚拟化：可以模拟不同CPU，例如bochs&lt;/li&gt;
&lt;li&gt;完全虚拟化：只能模拟同样CPU，但是可以执行不同系统，例如vmware&lt;/li&gt;
&lt;li&gt;半虚拟化&lt;/li&gt;
&lt;li&gt;硬件虚拟化：可以当作获得硬件加速的完全虚拟化&lt;/li&gt;
&lt;li&gt;系统虚拟化：host和guest共享一样的内核，例如Openvz&lt;/li&gt;
&lt;li&gt;语言沙盒：只能在语言的范围内使用&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;虚拟化的级别越偏底层，速度越慢，用户越难察觉到虚拟化的存在。 虚拟化的级别越偏上层，速度越快，用户越容易感知。也就是虚拟幻的包装，如何一个虚拟化完全包装底层，呈现给用户一个新的操作系统，那么用户会知道他用的什么吗？&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;cpu虚拟化和完全虚拟化时，用户几乎可以阿不察觉到虚拟化的存在&lt;/li&gt;
&lt;li&gt;半虚拟化时，guest内核必须存在补丁&lt;ul&gt;
&lt;li&gt;系统虚拟化时，用户不能控制自己的内核&lt;/li&gt;
&lt;li&gt;语言沙盒时，用户没有使用api的自由
    
    </summary>
    
      <category term="docker" scheme="https://iceziyao.github.io/categories/docker/"/>
    
    
      <category term="docker" scheme="https://iceziyao.github.io/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>浅析docker使用</title>
    <link href="https://iceziyao.github.io/2016/04/03/Docker/docker01/"/>
    <id>https://iceziyao.github.io/2016/04/03/Docker/docker01/</id>
    <published>2016-04-02T16:00:00.000Z</published>
    <updated>2016-08-06T14:50:42.253Z</updated>
    
    <content type="html">&lt;h2 id=&quot;docker是什么？&quot;&gt;&lt;a href=&quot;#docker是什么？&quot; class=&quot;headerlink&quot; title=&quot;docker是什么？&quot;&gt;&lt;/a&gt;docker是什么？&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;简单的说Docker是一个构建在LXC之上的,基于进程容器(Processcontainer)的轻量级VM解决方案&lt;br&gt;Docker的初衷也就是将各种应用程序和他们所依赖的运行环境打包成标准的Container/image,进而发布到不同的平台上运行。  也是由go写成的轻量级容器&lt;/li&gt;
&lt;li&gt;Docker container和普通的虚拟机Image相比, 最大的区别是它并不包含操作系统内核   &lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;普通虚拟机将整个操作系统运行在虚拟的硬件平台上, 进而提供完整的运行环境供应用程序运行, 而Docker则直接在宿主平台上加载运行应用程序. 本质上他在底层使用LXC启动一个Linux Container,通过cgroup等机制对不同的container内运行的应用程序进行隔离,权限管理和quota分配等  &lt;/li&gt;
&lt;li&gt;每个container拥有自己独立的各种命名空间(亦即资源)包括:&lt;br&gt;PID 进程, MNT 文件系统, NET 网络, IPC , UTS 主机名 等&lt;br&gt;与任何容器技术一样，就该程序而言，它有自己的文件系统、存储系统、处理器和内存等部件。容器与虚拟机之间的区别主要在于，虚拟机管理程序对整个设备进行抽象处理，而容器只是对操作系统内核进行抽象处理。  &lt;/li&gt;
&lt;li&gt;虚拟机管理程序能做容器做不了的一件事就是，使kernel-3.10.0-229.el7.x86_64用不同的操作系统或内核。所以，举例说，你可以使用微软Azure，同时运行Windows Server2012的实例和SUSE Linux企业级服务器的实例。至于Docker，所有容器都必须使用同样的操作系统和内核。&lt;/li&gt;
&lt;li&gt;Docker 概念及相互作用&lt;/li&gt;
&lt;li&gt;主机， 运行容器的机器。&lt;/li&gt;
&lt;li&gt;镜像，文件的层次结构，以及包含如何运行容器的元数据&lt;/li&gt;
&lt;li&gt;容器，一个从镜像中启动，包含正在运行的程序的进程&lt;/li&gt;
&lt;li&gt;Registry， 镜像仓库&lt;/li&gt;
&lt;li&gt;卷，容器外的存储  &lt;/li&gt;
&lt;li&gt;Dockerfile， 用于创建镜像的脚本  &lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;docker能用来干什么？&quot;&gt;&lt;a href=&quot;#docker能用来干什么？&quot; class=&quot;headerlink&quot; title=&quot;docker能用来干什么？&quot;&gt;&lt;/a&gt;docker能用来干什么？&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;快速交付你的应用程序&lt;br&gt;Docker可以为你的开发过程提供完美的帮助。Docker允许开发者在本地包含了应用程序和服务的容器进行开发，之后可以集成到连续的一体化和部署工作流中。&lt;/li&gt;
&lt;li&gt;开发和拓展更加简单&lt;br&gt;Docker的以容器为基础的平台允许高度可移植的工作。Docker容器可以在开发者机器上运行，也可以在实体或者虚拟机上运行，也可以在云平台上运行。&lt;br&gt;Docker的可移植、轻量特性同样让动态地管理负载更加简单。你可以用Docker快速地增加应用规模或者关闭应用程序和服务。Docker的快速意味着变动几乎是实时的。&lt;/li&gt;
&lt;li&gt;达到高密度和更多负载&lt;br&gt;Docker轻巧快速，它提供了一个可行的、 符合成本效益的替代基于虚拟机管理程序的虚拟机。这在高密度的环境下尤其有用。例如，构建你自己的云平台或者PaaS，在中小的部署环境下同样可以获取到更多的资源性能。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;docker主要组成有哪些？&quot;&gt;&lt;a href=&quot;#docker主要组成有哪些？&quot; class=&quot;headerlink&quot; title=&quot;docker主要组成有哪些？&quot;&gt;&lt;/a&gt;docker主要组成有哪些？&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Docker有两个主要的部件：  &lt;blockquote&gt;
&lt;p&gt;Docker: 开源的容器虚拟化平台。&lt;br&gt;Docker Hub: 用于分享、管理Docker容器的Docker SaaS平台。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;Docker的内部&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Docker镜像 (Docker images)。&lt;/li&gt;
&lt;li&gt;Docker仓库 (Docker registeries)。&lt;/li&gt;
&lt;li&gt;Docker容器(Docker containers)。&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;Docker镜像&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Docker镜像是一个只读的模板。举个例子，一个镜像可以包含一个运行在Apache上的Web应用和其使用的Ubuntu操作系统。&lt;/li&gt;
&lt;li&gt;镜像是用来创建容器的。Docker提供了简单的放来来建立新的镜像或者升级现有的镜像，你也可以下载别人已经创建好的镜像。Docker镜像是Docker的 构造 部分&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;Docker仓库&lt;blockquote&gt;
&lt;p&gt;Docker仓库用来保存镜像。可以理解为代码控制中的代码仓库。同样的，Docker仓库也有公有和私有的概念。公有的Docker仓库名字是Docker Hub。Docker Hub提供了庞大的镜像集合供使用。这些镜像可以是你自己创建的，或者你也可以在别人的镜像基础上创建。Docker仓库是Docker的 分发 部分。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;Docker容器&lt;blockquote&gt;
&lt;p&gt;Docker容器和文件夹很类似。一个Docker容器包含了所有的某个应用运行所需要的环境。每一个Docker容器都是从Docker镜像创建 的。Docker容器可以运行、开始、停止、移动和删除。每一个Docker容器都是独立和安全的应用平台。Docker容器是Docker的 运行 部分。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;安装docker&quot;&gt;&lt;a href=&quot;#安装docker&quot; class=&quot;headerlink&quot; title=&quot;安装docker&quot;&gt;&lt;/a&gt;安装docker&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;首先更新yum源，添加rhel7.1的iso镜像，来更新内核kernel(因为docker对内核有要求，rhel7.0时启动慢)  &lt;blockquote&gt;
&lt;p&gt;1.自己下载cestos7.1的镜像，构建本地yum&lt;br&gt;2.使用163或者网易的yum源&lt;br&gt;yum update kernel -y&lt;br&gt;rpm -q kernel&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;kernel-3.10.0-123.el7.x86_64&lt;br&gt;kernel-3.10.0-229.el7.x86_64  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;重启，选择kernel-3.10.0-229.el7.x86_64进入系统&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;更新相关组件  &lt;blockquote&gt;
&lt;p&gt;yum update device-mapper -y&lt;br&gt;rpm -qa | grep device-mapper&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;device-mapper-persistent-data-0.3.2-1.el7.x86_64&lt;br&gt;device-mapper-libs-1.02.93-3.el7.x86_64&lt;br&gt;device-mapper-multipath-0.4.9-66.el7.x86_64&lt;br&gt;device-mapper-event-libs-1.02.93-3.el7.x86_64&lt;br&gt;device-mapper-multipath-libs-0.4.9-66.el7.x86_64&lt;br&gt;device-mapper-event-1.02.93-3.el7.x86_64&lt;br&gt;device-mapper-1.02.93-3.el7.x86_64  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;安装docker  &lt;blockquote&gt;
&lt;p&gt;3.1 执行Docker安装脚本&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt; curl -sSL &lt;a href=&quot;https://get.docker.com/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://get.docker.com/&lt;/a&gt; | sh&lt;br&gt;yum install -y docker-selinux&lt;br&gt;这个脚本会添加 docker.repo 配置并安装Docker。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;3.2 自动添加添加yum仓库&lt;br&gt;&lt;pre&gt;&lt;code&gt;&lt;br&gt;cat &amp;gt;/etc/yum.repos.d/docker.repo &amp;lt;&amp;lt;-EOF&lt;br&gt;[dockerrepo]&lt;br&gt;name=Docker Repository&lt;br&gt;baseurl=&lt;a href=&quot;https://yum.dockerproject.org/repo/main/centos/7&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://yum.dockerproject.org/repo/main/centos/7&lt;/a&gt;&lt;br&gt;enabled=1&lt;br&gt;gpgcheck=1&lt;br&gt;gpgkey=&lt;a href=&quot;https://yum.dockerproject.org/gpg&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://yum.dockerproject.org/gpg&lt;/a&gt;&lt;br&gt;EOF&lt;br&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br&gt;安装Docker包&lt;br&gt;yum install -y docker-engine&lt;br&gt;yum install -y docker-selinux&lt;br&gt;yum list installed | grep docker  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;docker-engine.x86_64             1.8.1-1.el7.centos                    @dockerrepo&lt;br&gt;docker-selinux.x86_64            1.7.1-108.el7.centos                  @extras  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;3.3 rpm安装&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;yum install docker-engine-1.8.3-1.el7.centos.x86_64.rpm  -y&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;启动docker&lt;blockquote&gt;
&lt;p&gt;systemctl start docker&lt;br&gt;docker version   &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Client:&lt;br&gt;Version:      1.8.1&lt;br&gt;API version:  1.20&lt;br&gt;Go version:   go1.4.2&lt;br&gt;Git commit:   d12ea79&lt;br&gt;Built:        Thu Aug 13 02:19:43 UTC 2015&lt;br&gt;OS/Arch:      linux/amd64  &lt;/p&gt;
&lt;p&gt;Server:&lt;br&gt;Version:      1.8.1&lt;br&gt;API version:  1.20&lt;br&gt;Go version:   go1.4.2&lt;br&gt;Git commit:   d12ea79&lt;br&gt;Built:        Thu Aug 13 02:19:43 UTC 2015&lt;br&gt;OS/Arch:      linux/amd64  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;docker使用&quot;&gt;&lt;a href=&quot;#docker使用&quot; class=&quot;headerlink&quot; title=&quot;docker使用&quot;&gt;&lt;/a&gt;docker使用&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;有关镜像的操作  &lt;blockquote&gt;
&lt;p&gt;$ docker images  # 查看所有镜像.&lt;br&gt;$ docker import  # 从tarball创建镜像&lt;br&gt;$ docker build   # 通过Dockerfile创建镜像&lt;br&gt;$ docker commit  # 从容器中创建镜像&lt;br&gt;$ docker rmi     # 删除镜像&lt;br&gt;$ docker history # 列出镜像的变更历史  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;运行的容器  &lt;blockquote&gt;
&lt;p&gt;$ docker create  # 创建一个容器，但不启动它&lt;br&gt;$ docker run     #  创建并启动一个容器&lt;br&gt;$ docker stop    # 停止容器&lt;br&gt;$ docker start   #  启动容器&lt;br&gt;$ docker restart # 重启容器&lt;br&gt;$ docker rm      # 删除容器&lt;br&gt;$ docker kill    #  给容器发送kill信号&lt;br&gt;$ docker attach  # 连接到正在运行的容器中&lt;br&gt;$ docker wait    # 阻塞直到容器停止为止&lt;br&gt;$ docker exec    # 在运行的容器中执行一条命令  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;检查容器  &lt;blockquote&gt;
&lt;p&gt;$ docker ps      # 显示运行的容器&lt;br&gt;$ docker inspect # 显示容器信息（包括ip地址）&lt;br&gt;$ docker logs    # 获取容器中的日志&lt;br&gt;$ docker events  # 获取容器事件&lt;br&gt;$ docker port    # 显示容器的公开端口&lt;br&gt;$ docker top     # 显示容器中运行的进程&lt;br&gt;$ docker diff    # 查看容器文件系统中改变的文件&lt;br&gt;$ docker stats   # 查看各种纬度数据、内存、CPU、文件系统等  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;之后的会继续更新博客&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;docker是什么？&quot;&gt;&lt;a href=&quot;#docker是什么？&quot; class=&quot;headerlink&quot; title=&quot;docker是什么？&quot;&gt;&lt;/a&gt;docker是什么？&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;简单的说Docker是一个构建在LXC之上的,基于进程容器(Processcontainer)的轻量级VM解决方案&lt;br&gt;Docker的初衷也就是将各种应用程序和他们所依赖的运行环境打包成标准的Container/image,进而发布到不同的平台上运行。  也是由go写成的轻量级容器&lt;/li&gt;
&lt;li&gt;Docker container和普通的虚拟机Image相比, 最大的区别是它并不包含操作系统内核
    
    </summary>
    
      <category term="docker" scheme="https://iceziyao.github.io/categories/docker/"/>
    
    
      <category term="docker" scheme="https://iceziyao.github.io/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>Lvs负载均衡</title>
    <link href="https://iceziyao.github.io/2016/02/01/Lvs/lvs1/"/>
    <id>https://iceziyao.github.io/2016/02/01/Lvs/lvs1/</id>
    <published>2016-01-31T16:00:00.000Z</published>
    <updated>2016-08-06T14:49:36.591Z</updated>
    
    <content type="html">&lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h2&gt;&lt;p&gt;LVS是Linux Virtual Server的简称，也就是Linux虚拟服务器, 是一个由章文嵩博士发起的自由软件项目。&lt;br&gt;在Linux2.4内核以前，使用LVS时必须要重新编译内核以支持LVS功能模块，但是从Linux2.4内核以后，已经完全内置了LVS的各个功能模块，无需给内核打任何补丁，可以直接使用LVS提供的各种功能。&lt;br&gt;使用LVS技术要达到的目标是:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;通过LVS提供的负载均衡技术和Linux操作系统实现一个高性能、高可用的服务器群集，它具有良好可靠性、可扩展性和可操作性。从而以低廉的成本实现最优的服务性能。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;LVS体系结构&quot;&gt;&lt;a href=&quot;#LVS体系结构&quot; class=&quot;headerlink&quot; title=&quot;LVS体系结构&quot;&gt;&lt;/a&gt;LVS体系结构&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;LVS体系结构下图所示：&lt;br&gt;&lt;img src=&quot;/upload/Lvs.png&quot; alt=&quot;Lvs&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;LVS 集群分为三层结构:  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;负载调度器(load balancer)：它是整个LVS 集群对外的前端机器，负责将client请求发送到一组服务器[多台LB IP]上执行，而client端认为是返回来一个同一个IP【通常把这个IP 称为虚拟IP/VIP】&lt;/li&gt;
&lt;li&gt;服务器池(server pool)：一组真正执行client&lt;/li&gt;
&lt;li&gt;共享存储(shared stored)：它为 server pool 提供了一个共享的存储区，很容易让服务器池拥有相同的内容，提供相同的服务&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;工作模式&quot;&gt;&lt;a href=&quot;#工作模式&quot; class=&quot;headerlink&quot; title=&quot;工作模式&quot;&gt;&lt;/a&gt;工作模式&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;DR&lt;/li&gt;
&lt;li&gt;NAT&lt;/li&gt;
&lt;li&gt;隧道模式&lt;/li&gt;
&lt;li&gt;FULL NAT 模式&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;算法&quot;&gt;&lt;a href=&quot;#算法&quot; class=&quot;headerlink&quot; title=&quot;算法&quot;&gt;&lt;/a&gt;算法&lt;/h2&gt;</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h2&gt;&lt;p&gt;LVS是Linux Virtual Server的简称，也就是Linux虚拟服务器, 是一个由章文嵩博士发起的自由软件项目。&lt;br&gt;在Linux2.4内核以前，使用LVS时必须要重新编译内核以支持LVS功能模块，但是从Linux2.4内核以后，已经完全内置了LVS的各个功能模块，无需给内核打任何补丁，可以直接使用LVS提供的各种功能。&lt;br&gt;使用LVS技术要达到的目标是:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;通过LVS提供的负载均衡技术和Linux操作系统实现一个高性能、高可用的服务器群集，它具有良好可靠性、可扩展性和可操作性。从而以低廉的成本实现最优的服务性能。&lt;br&gt;
    
    </summary>
    
      <category term="负载均衡" scheme="https://iceziyao.github.io/categories/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"/>
    
    
      <category term="负载均衡" scheme="https://iceziyao.github.io/tags/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"/>
    
  </entry>
  
  <entry>
    <title>Haproxy负载均衡</title>
    <link href="https://iceziyao.github.io/2016/01/16/haproxy/"/>
    <id>https://iceziyao.github.io/2016/01/16/haproxy/</id>
    <published>2016-01-15T16:00:00.000Z</published>
    <updated>2016-08-06T14:49:04.539Z</updated>
    
    <content type="html">&lt;h4 id=&quot;HAProxy简介&quot;&gt;&lt;a href=&quot;#HAProxy简介&quot; class=&quot;headerlink&quot; title=&quot;HAProxy简介&quot;&gt;&lt;/a&gt;HAProxy简介&lt;/h4&gt;&lt;p&gt;&lt;em&gt;HAProxy提供高可用性、负载均衡以及基于TCP和HTTP应用的代理，支持虚拟主机，它是免费、快速并且可靠的一种解决方案。HAProxy特别适用于那些负载特大的web站点，这些站点通常又需要会话保持或七层处理。HAProxy运行在时下的硬件上，完全可以支持数以万计的并发连接。并且它的运行模式使得它可以很简单安全的整合进您当前的架构中， 同时可以保护你的web服务器不被暴露到网络上.&lt;/em&gt;&lt;br&gt;&lt;em&gt;HAProxy实现了一种事件驱动、单一进程模型，此模型支持非常大的并发连接数。多进程或多线程模型受内存限制 、系统调度器限制以及无处不在的锁限制，很少能处理数千并发连接。事件驱动模型因为在有更好的资源和时间管理的用户端(User-Space) 实现所有这些任务，所以没有这些问题。此模型的弊端是，在多核系统上，这些程序通常扩展性较差。这就是为什么他们必须进行优化以 使每个CPU时间片(Cycle)做更多的工作。&lt;/em&gt;&lt;br&gt;————百度百科&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;HAProxy是免费、极速且可靠的用于为TCP和基于HTTP应用程序提供高可用、负载均衡和代理服务的解决方案，尤其适用于高负载且需要持久连接或7层处理机制的web站点。&lt;br&gt;1.1 HAProxy目前主要有两个版本&lt;br&gt;1.1.1  提供较好的弹性：衍生于1.2版本，并提供了额外的新特性，其中大多数是期待已久的。&lt;br&gt;    客户端侧的长连接(client-side keep-alive)&lt;br&gt;    TCP加速(TCP speedups)&lt;br&gt;    响应池(response buffering)&lt;br&gt;    RDP协议&lt;br&gt;    基于源的粘性(source-based stickiness)&lt;br&gt;    更好的统计数据接口(a much better stats interfaces)&lt;br&gt;    更详细的健康状态检测机制(more verbose health checks)&lt;br&gt;    基于流量的健康评估机制(traffic-based health)&lt;br&gt;    支持HTTP认证&lt;br&gt;    服务器管理命令行接口(server management from the CLI)&lt;br&gt;    基于ACL的持久性(ACL-based persistence)&lt;br&gt;    日志分析器&lt;br&gt;  1.1.2 内容交换和超强负载：&lt;br&gt;  衍生于1.2版本，并提供了额外的新特性。&lt;br&gt;    内容交换(content switching)：基于任何请求标准挑选服务器池；&lt;br&gt;    ACL：编写内容交换规则；&lt;br&gt;    负载均衡算法(load-balancing algorithms)：更多的算法支持；&lt;br&gt;    内容探测(content inspection)：阻止非授权协议；&lt;br&gt;    透明代理(transparent proxy)：在Linux系统上允许使用客户端IP直接连入服务器；&lt;br&gt;    内核TCP拼接(kernel TCP splicing)：无copy方式在客户端和服务端之间转发数据以实现数G级别的数据速率；&lt;br&gt;    分层设计(layered design)：分别实现套接字、TCP、HTTP处理以提供更好的健壮性、更快的处理机制及便捷的演进能力；&lt;br&gt;    快速、公平调度器(fast and fair scheduler)：为某些任务指定优先级可实现理好的QoS；&lt;br&gt;    会话速率限制(session rate limiting)：适用于托管环境；&lt;br&gt;1.2 性能&lt;br&gt;HAProxy借助于OS上几种常见的技术来实现性能的最大化。&lt;br&gt;    单进程、事件驱动模型显著降低了上下文切换的开销及内存占用。&lt;br&gt;    O(1)事件检查器(event checker)允许其在高并发连接中对任何连接的任何事件实现即时探测。&lt;br&gt;    在任何可用的情况下，单缓冲(single buffering)机制能以不复制任何数据的方式完成读写操作，这会节约大量的CPU时钟周期及内存带宽；&lt;br&gt;    借助于Linux 2.6 (&amp;gt;= 2.6.27.19)上的splice()系统调用，HAProxy可以实现零复制转发(Zero-copy forwarding)，在Linux 3.5及以上的OS中还可以实现零复制启动(zero-starting)；&lt;br&gt;    MRU内存分配器在固定大小的内存池中可实现即时内存分配，这能够显著减少创建一个会话的时长；&lt;br&gt;    树型存储：侧重于使用作者多年前开发的弹性二叉树，实现了以O(log(N))的低开销来保持计时器命令、保持运行队列命令及管理轮询及最少连接队列；&lt;br&gt;    优化的HTTP首部分析：优化的首部分析功能避免了在HTTP首部分析过程中重读任何内存区域；&lt;br&gt;    精心地降低了昂贵的系统调用，大部分工作都在用户空间完成，如时间读取、缓冲聚合及文件描述符的启用和禁用等；&lt;br&gt;所有的这些细微之处的优化实现了在中等规模负载之上依然有着相当低的CPU负载，甚至于在非常高的负载场景中，5%的用户空间占用率和95%的系统空间占用率也是非常普遍的现象，这意味着HAProxy进程消耗比系统空间消耗低20倍以上。因此，对OS进行性能调优是非常重要的。即使用户空间的占用率提高一倍，其CPU占用率也仅为10%，这也解释了为何7层处理对性能影响有限这一现象。由此，在高端系统上HAProxy的7层性能可轻易超过硬件负载均衡设备。&lt;br&gt;在生产环境中，在7层处理上使用HAProxy作为昂贵的高端硬件负载均衡设备故障故障时的紧急解决方案也时长可见。硬件负载均衡设备在“报文”级别处理请求，这在支持跨报文请求(request across multiple packets)有着较高的难度，并且它们不缓冲任何数据，因此有着较长的响应时间。对应地，软件负载均衡设备使用TCP缓冲，可建立极长的请求，且有着较大的响应时间。&lt;br&gt;可以从三个因素来评估负载均衡器的性能：&lt;br&gt;(1)    会话率&lt;br&gt;(2)    会话并发能力&lt;br&gt;(3) 数据率  &lt;/p&gt;
&lt;h4 id=&quot;配置HAProxy&quot;&gt;&lt;a href=&quot;#配置HAProxy&quot; class=&quot;headerlink&quot; title=&quot;配置HAProxy&quot;&gt;&lt;/a&gt;配置HAProxy&lt;/h4&gt;&lt;p&gt;2.1 配置文件格式&lt;br&gt;HAProxy的配置处理3类来主要参数来源：&lt;br&gt;    ——最优先处理的命令行参数，&lt;br&gt;    ——“global”配置段，用于设定全局配置参数；&lt;br&gt;    ——proxy相关配置段，如“defaults”、“listen”、“frontend”和“backend”；&lt;br&gt;2.2 时间格式&lt;br&gt;一些包含了值的参数表示时间，如超时时长。这些值一般以毫秒为单位，但也可以使用其它的时间单位后缀。&lt;br&gt;    us: 微秒(microseconds)，即1/1000000秒；&lt;br&gt;    ms: 毫秒(milliseconds)，即1/1000秒；&lt;br&gt;    s: 秒(seconds)；&lt;br&gt;    m: 分钟(minutes)；&lt;br&gt;    h：小时(hours)；&lt;br&gt;    d: 天(days)；&lt;br&gt;2.3 例子&lt;br&gt;下面的例子配置了一个监听在所有接口的80端口上HTTP proxy服务，它转发所有的请求至后端监听在127.0.0.1:8000上的”server”。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
    global
    daemon
    maxconn 25600
defaults
    mode http
    timeout connect 5000ms
    timeout client 50000ms
    timeout server 50000ms
frontend http-in
    bind *:80
    default_backend servers
backend servers
    server server1 127.0.0.1:8080 maxconn 32
&lt;/code&gt;&lt;/pre&gt;
2.4 全局配置
&quot;&quot;“global”配置中的参数为进程级别的参数，且通常与其运行的OS相关。  
 \* 进程管理及安全相关的参数  
   \- chroot &lt;jail dir=&quot;&quot;&gt;：修改haproxy的工作目录至指定的目录并在放弃权限之前执行chroot()操作，可以提升haproxy的安全级别，不过需要注意的是要确保指定的目录为空目录且任何用户均不能有写权限；  
   \- daemon：让haproxy以守护进程的方式工作于后台，其等同于“-D”选项的功能，当然，也可以在命令行中以“-db”选项将其禁用；  
   \- gid &lt;number&gt;：以指定的GID运行haproxy，建议使用专用于运行haproxy的GID，以免因权限问题带来风险；  
   \- group &lt;group name=&quot;&quot;&gt;：同gid，不过指定的组名；  
   \- log  &lt;address&gt; &lt;facility&gt; [max level [min level]]：定义全局的syslog服务器，最多可以定义两个；  
   \- log-send-hostname [&lt;string&gt;]：在syslog信息的首部添加当前主机名，可以为“string”指定的名称，也可以缺省使用当前主机名；  
   \- nbproc &lt;number&gt;：指定启动的haproxy进程个数，只能用于守护进程模式的haproxy；默认只启动一个进程，鉴于调试困难等多方面的原因，一般只在单进程仅能打开少数文件描述符的场景中才使用多进程模式；  
   \- pidfile：  
   \- uid：以指定的UID身份运行haproxy进程；  
   \- ulimit-n：设定每进程所能够打开的最大文件描述符数目，默认情况下其会自动进行计算，因此不推荐修改此选项；  
   \- user：同uid，但使用的是用户名；  
   \- stats：  
   \- node：定义当前节点的名称，用于HA场景中多haproxy进程共享同一个IP地址时；  
   \- description：当前实例的描述信息；  
 \* 性能调整相关的参数  
   \- maxconn &lt;number&gt;：设定每个haproxy进程所接受的最大并发连接数，其等同于命令行选项“-n”；“ulimit -n”自动计算的结果正是参照此参数设定的；  
   \- maxpipes &lt;number&gt;：haproxy使用pipe完成基于内核的tcp报文重组，此选项则用于设定每进程所允许使用的最大pipe个数；每个pipe会打开两个文件描述符，因此，“ulimit -n”自动计算时会根据需要调大此值；默认为maxconn/4，其通常会显得过大；  
   \- noepoll：在Linux系统上禁用epoll机制；  
   \- nokqueue：在BSE系统上禁用kqueue机制；  
   \- nopoll：禁用poll机制；  
   \- nosepoll：在Linux禁用启发式epoll机制；  
   \- nosplice：禁止在Linux套接字上使用内核tcp重组，这会导致更多的recv/send系统调用；不过，在Linux 2.6.25-28系列的内核上，tcp重组功能有bug存在；  
   \- spread-checks &lt;0..50, in=&quot;&quot; percent=&quot;&quot;&gt;：在haproxy后端有着众多服务器的场景中，在精确的时间间隔后统一对众服务器进行健康状况检查可能会带来意外问题；此选项用于将其检查的时间间隔长度上增加或减小一定的随机时长；  
   \- tune.bufsize &lt;number&gt;：设定buffer的大小，同样的内存条件小，较小的值可以让haproxy有能力接受更多的并发连接，较大的值可以让某些应用程序使用较大的cookie信息；默认为16384，其可以在编译时修改，不过强烈建议使用默认值；  
   \- tune.chksize &lt;number&gt;：设定检查缓冲区的大小，单位为字节；更大的值有助于在较大的页面中完成基于字符串或模式的文本查找，但也会占用更多的系统资源；不建议修改；  
   \- tune.maxaccept &lt;number&gt;：设定haproxy进程内核调度运行时一次性可以接受的连接的个数，较大的值可以带来较大的吞吐率，默认在单进程模式下为100，多进程模式下为8，设定为-1可以禁止此限制；一般不建议修改；  
   \- tune.maxpollevents  &lt;number&gt;：设定一次系统调用可以处理的事件最大数，默认值取决于OS；其值小于200时可节约带宽，但会略微增大网络延迟，而大于200时会降低延迟，但会稍稍增加网络带宽的占用量；  
   \- tune.maxrewrite &lt;number&gt;：设定为首部重写或追加而预留的缓冲空间，建议使用1024左右的大小；在需要使用更大的空间时，haproxy会自动增加其值；  
   \- tune.rcvbuf.client &lt;number&gt;：  
   \- tune.rcvbuf.server &lt;number&gt;：设定内核套接字中服务端或客户端接收缓冲的大小，单位为字节；强烈推荐使用默认值；  
   \- tune.sndbuf.client：  
   \- tune.sndbuf.server：  
 \* Debug相关的参数  
   \- debug  
   \- quiet   
2.5 代理  
代理相关的配置可以如下配置段中。
 (1) defaults name  
 (2) frontend name  
 (3) backend  name  
 (4) listen   name  
 “defaults”段用于为所有其它配置段提供默认参数，这配置默认配置参数可由下一个“defaults”所重新设定。
 “frontend”段用于定义一系列监听的套接字，这些套stats_auth接字可接受客户端请求并与之建立连接。  
 “backend”段用于定义一系列“后端”服务器，代理将会将对应客户端的请求转发至这些服务器。  
 “listen”段通过关联“前端”和“后端”定义了一个完整的代理，通常只对TCP流量有用。  
 所有代理的名称只能使用大写字母、小写字母、数字、-(中线)、\_(下划线)、\.(点号)和\:(冒号)。此外，ACL名称会区分字母大小写。  

### 配置文件中的关键字参考  
3.1 balance  
`balance &lt;algorithm&gt; [ &lt;arguments&gt; ]`    
`balance url_param &lt;param&gt; [check_post   [&lt;max_wait&gt;]]`    
3.2 bind  
`bind [&lt;address&gt;]:&lt;port_range&gt; [, ...]`  
`bind [&lt;address&gt;]:&lt;port_range&gt; [, ...] interface &lt;interface&gt;`   
\-此指令仅能用于frontend和listen区段，用于定义一个或几个监听的套接字。  
`&lt;address&gt;`：可选选项，其可以为主机名、IPv4地址、IPv6地址或*；省略此选项、将其指定为*或0.0.0.0时，将监听当前系统的所有IPv4地址；
`&lt;port_range&gt;`：可以是一个特定的TCP端口，也可是一个端口范围(如5005-5010)，代理服务器将通过指定的端口来接收客户端请求；需要注意的是，每组监听的套接字&lt;address:port&gt;在同一个实例上只能使用一次，而且小于1024的端口需要有特定权限的用户才能使用，这可能需要通过uid参数来定义；
`&lt;interface&gt;：`指定物理接口的名称，仅能在Linux系统上使用；其不能使用接口别名，而仅能使用物理接口名称，而且只有管理有权限指定绑定的物理接口；  
3.3 mode  
`mode { tcp|http|health } `
设定实例的运行模式或协议。当实现内容交换时，前端和后端必须工作于同一种模式(一般说来都是HTTP模式)，否则将无法启动实例。  
tcp：实例运行于纯TCP模式，在客户端和服务器端之间将建立一个全双工的连接，且不会对7层报文做任何类型的检查；此为默认模式，通常用于SSL、SSH、SMTP等应用；  
http：实例运行于HTTP模式，客户端请求在转发至后端服务器之前将被深度分析，所有不与RFC格式兼容的请求都会被拒绝；  
health：实例工作于health模式，其对入站请求仅响应“OK”信息并关闭连接，且不会记录任何日志信息；此模式将用于响应外部组件的健康状态检查请求；目前业讲，此模式已经废弃，因为tcp或http模式中的monitor关键字可完成类似功能；  
3.4 hash-type
`hash-type &lt;method&gt;`  
定义用于将hash码映射至后端服务器的方法；其不能用于frontend区段；可用方法有map-based和consistent，在大多数场景下推荐使用默认的map-based方法  
map-based：hash表是一个包含了所有在线服务器的静态数组。其hash值将会非常平滑，会将权重考虑在列，但其为静态方法，对在线服务器的权重进行调整将不会生效，这意味着其不支持慢速启动。此外，挑选服务器是根据其在数组中的位置进行的，因此，当一台服务器宕机或添加了一台新的服务器时，大多数连接将会被重新派发至一个与此前不同的服务器上，对于缓存服务器的工作场景来说，此方法不甚适用。  
consistent：hash表是一个由各服务器填充而成的树状结构；基于hash键在hash树中查找相应的服务器时，最近的服务器将被选中。此方法是动态的，支持在运行时修改服务器权重，因此兼容慢速启动的特性。添加一个新的服务器时，仅会对一小部分请求产生影响，因此，尤其适用于后端服务器为cache的场景。不过，此算法不甚平滑，派发至各服务器的请求未必能达到理想的均衡效果，因此，可能需要不时的调整服务器的权重以获得更好的均衡性。  
3.5 log  
`log global`  
`log &lt;address&gt; &lt;facility&gt; [&lt;level&gt; [&lt;minlevel&gt;]]`  
为每个实例启用事件和流量日志，因此可用于所有区段。每个实例最多可以指定两个log参数，不过，如果使用了“log global”且&quot;global&quot;段已经定了两个log参数时，多余了log参数将被忽略。  
global：当前实例的日志系统参数同&quot;global&quot;段中的定义时，将使用此格式；每个实例仅能定义一次“log global”语句，且其没有任何额外参数；  
`&lt;address&gt;`：定义日志发往的位置，其格式之一可以为`&lt;ipv4_address:port&gt;`，其中的port为UDP协议端口，默认为514；格式之二为Unix套接字文件路径，但需要留心chroot应用及用户的读写权限；  
`&lt;facility&gt;`：可以为syslog系统的标准facility之一；
`&lt;level&gt;`：定义日志级别，即输出信息过滤器，默认为所有信息；指定级别时，所有等于或高于此别的日志信息将会被发送；   
3.6 maxconn  
`maxconn &lt;conns&gt;`  
设定一个前端的最大并发连接数，因此，其不能用于backend区段。对于大型站点来说，可以尽可能提高此值以便让haproxy管理连接队列，从而避免无法应答用户请求。当然，此最大值不能超出“global”段中的定义。此外，需要留心的是，haproxy会为每个连接维持两个缓冲，每个缓冲的大小为8KB，再加上其它的数据，每个连接将大约占用17KB的RAM空间。这意味着经过适当优化后，有着1GB的可用RAM空间时将能维护40000-50000并发连接。  
如果为`&lt;conns&gt;`指定了一个过大值，极端场景下，其最终占据的空间可能会超出当前主机的可用内存，这可能会带来意想不到的结果；因此，将其设定了一个可接受值方为明智决定。其默认为2000。  
3.7 default_backend  
default_backend `&lt;backend&gt;`  
在没有匹配的&quot;use_backend&quot;规则时为实例指定使用的默认后端，因此，其不可应用于backend区段。在&quot;frontend&quot;和&quot;backend&quot;之间进行内容交换时，通常使用&quot;use\-backend&quot;定义其匹配规则；而没有被规则匹配到的请求将由此参数指定的后端接收。  
`&lt;backend&gt;`：指定使用的后端的名称；  
使用案例：  
&lt;pre&gt;&lt;code&gt;
use_backend     dynamic  if  url_dyn
use_backend     static   if  url_css url_img extension_img
default_backend dynamic
&lt;/code&gt;&lt;/pre&gt;  
3.8 服务  
&lt;pre&gt;&lt;code&gt;
server &lt;name&gt; &lt;address&gt;[:port] [param*]
为后端声明一个server，因此，不能用于defaults和frontend区段。
&lt;name&gt;：为此服务器指定的内部名称，其将出现在日志及警告信息中；如果设定了&quot;http-send-server-name&quot;，它还将被添加至发往此服务器的请求首部中；
&lt;address&gt;：此服务器的的IPv4地址，也支持使用可解析的主机名，只不过在启动时需要解析主机名至相应的IPv4地址；
[:port]：指定将连接请求所发往的此服务器时的目标端口，其为可选项；未设定时，将使用客户端请求时的同一相端口；
[param*]：为此服务器设定的一系参数；其可用的参数非常多，具体请参考官方文档中的说明，下面仅说明几个常用的参数；
服务器或默认服务器参数：
backup：设定为备用服务器，仅在负载均衡场景中的其它server均不可用于启用此server；
check：启动对此server执行健康状态检查，其可以借助于额外的其它参数完成更精细的设定，如：
    inter &lt;delay&gt;：设定健康状态检查的时间间隔，单位为毫秒，默认为2000；也可以使用fastinter和downinter来根据服务器端状态优化此时间延迟；
    rise &lt;count&gt;：设定健康状态检查中，某离线的server从离线状态转换至正常状态需要成功检查的次数；
    fall &lt;count&gt;：确认server从正常状态转换为不可用状态需要检查的次数；
cookie &lt;value&gt;：为指定server设定cookie值，此处指定的值将在请求入站时被检查，第一次为此值挑选的server将在后续的请求中被选中，其目的在于实现持久连接的功能；
maxconn &lt;maxconn&gt;：指定此服务器接受的最大并发连接数；如果发往此服务器的连接数目高于此处指定的值，其将被放置于请求队列，以等待其它连接被释放；
maxqueue &lt;maxqueue&gt;：设定请求队列的最大长度；
observe &lt;mode&gt;：通过观察服务器的通信状况来判定其健康状态，默认为禁用，其支持的类型有“layer4”和“layer7”，“layer7”仅能用于http代理场景；
redir &lt;prefix&gt;：启用重定向功能，将发往此服务器的GET和HEAD请求均以302状态码响应；需要注意的是，在prefix后面不能使用/，且不能使用相对地址，以免造成循环；例如：
    server srv1 172.16.100.6:80 redir http://imageserver.magedu.com check
weight &lt;weight&gt;：权重，默认为1，最大值为256，0表示不参与负载均衡；
检查方法：
option httpchk
option httpchk &lt;uri&gt;
option httpchk &lt;method&gt; &lt;uri&gt;
option httpchk &lt;method&gt; &lt;uri&gt; &lt;version&gt;：不能用于frontend段，例如：
backend https_relay
    mode tcp
    option httpchk OPTIONS * HTTP/1.1\r\nHost:\ www.magedu.com
    server apache1 192.168.1.1:443 check port 80
使用案例：
server first  172.16.100.7:1080 cookie first  check inter 1000
server second 172.16.100.8:1080 cookie second check inter 1000
&lt;/version&gt;&lt;/uri&gt;&lt;/method&gt;&lt;/uri&gt;&lt;/method&gt;&lt;/uri&gt;&lt;/weight&gt;&lt;/prefix&gt;&lt;/mode&gt;&lt;/maxqueue&gt;&lt;/maxconn&gt;&lt;/value&gt;&lt;/count&gt;&lt;/count&gt;&lt;/delay&gt;&lt;/address&gt;&lt;/name&gt;&lt;/address&gt;&lt;/name&gt;&lt;/code&gt;&lt;/pre&gt;  
3.9 capture request header  
&lt;pre&gt;&lt;code&gt;
capture request header &lt;name&gt; len &lt;length&gt;
捕获并记录指定的请求首部最近一次出现时的第一个值，仅能用于“frontend”和“listen”区段。捕获的首部值使用花括号{}括起来后添加进日志中。如果需要捕获多个首部值，它们将以指定的次序出现在日志文件中，并以竖线“|”作为分隔符。不存在的首部记录为空字符串，最常需要捕获的首部包括在虚拟主机环境中使用的“Host”、上传请求首部中的“Content-length”、快速区别真实用户和网络机器人的“User-agent”，以及代理环境中记录真实请求来源的“X-Forward-For”。
&lt;name&gt;：要捕获的首部的名称，此名称不区分字符大小写，但建议与它们出现在首部中的格式相同，比如大写首字母。需要注意的是，记录在日志中的是首部对应的值，而非首部名称。
&lt;length&gt;：指定记录首部值时所记录的精确长度，超出的部分将会被忽略。
可以捕获的请求首部的个数没有限制，但每个捕获最多只能记录64个字符。为了保证同一个frontend中日志格式的统一性，首部捕获仅能在frontend中定义。
&lt;/length&gt;&lt;/name&gt;&lt;/length&gt;&lt;/name&gt;&lt;/code&gt;&lt;/pre&gt;
3.10 capture response header  
&lt;pre&gt;&lt;code&gt;
capture response header &lt;name&gt; len &lt;length&gt;
捕获并记录响应首部，其格式和要点同请求首部。
&lt;/length&gt;&lt;/name&gt;&lt;/code&gt;&lt;/pre&gt;  
3.11 stats enable
&lt;pre&gt;&lt;code&gt;
启用基于程序编译时默认设置的统计报告，不能用于“frontend”区段。只要没有另外的其它设定，它们就会使用如下的配置：
  \- stats uri   : /haproxy?stats
  \- stats realm : &quot;HAProxy Statistics&quot;
  \- stats auth  : no authentication
  \- stats scope : no restriction   
尽管“stats enable”一条就能够启用统计报告，但还是建议设定其它所有的参数，以免其依赖于默认设定而带来非期后果。下面是一个配置案例。  
  backend public_www
    server websrv1 172.16.100.11:80
    stats enable
    stats hide-version
    stats scope   .
    stats uri     /haproxyadmin?stats
    stats realm   Haproxy\ Statistics
    stats auth    statsadmin:password
    stats auth    statsmaster:password
&lt;/code&gt;&lt;/pre&gt;  
3.12 stats hide-version
&lt;pre&gt;&lt;code&gt;
stats hide-version  
启用统计报告并隐藏HAProxy版本报告，不能用于“frontend”区段。默认情况下，统计页面会显示一些有用信息，包括HAProxy的版本号，然而，向所有人公开HAProxy的精确版本号是非常有风险的，因为它能帮助恶意用户快速定位版本的缺陷和漏洞。尽管“stats hide-version”一条就能够启用统计报告，但还是建议设定其它所有的参数，以免其依赖于默认设定而带来非期后果。具体请参照“stats enable”一节的说明。
&lt;/code&gt;&lt;/pre&gt;
3.13 stats realm  
&lt;pre&gt;&lt;code&gt;
stats realm &lt;realm&gt;
启用统计报告并高精认证领域，不能用于“frontend”区段。haproxy在读取realm时会将其视作一个单词，因此，中间的任何空白字符都必须使用反斜线进行转义。此参数仅在与“stats auth”配置使用时有意义。
&lt;realm&gt;：实现HTTP基本认证时显示在浏览器中的领域名称，用于提示用户输入一个用户名和密码。
尽管“stats realm”一条就能够启用统计报告，但还是建议设定其它所有的参数，以免其依赖于默认设定而带来非期后果。具体请参照“stats enable”一节的说明。
&lt;/realm&gt;&lt;/realm&gt;&lt;/code&gt;&lt;/pre&gt;
3.14 stats scope  
&lt;pre&gt;&lt;code&gt;
stats scope { &lt;name&gt; | &quot;.&quot; }
启用统计报告并限定报告的区段，不能用于“frontend”区段。当指定此语句时，统计报告将仅显示其列举出区段的报告信息，所有其它区段的信息将被隐藏。如果需要显示多个区段的统计报告，此语句可以定义多次。需要注意的是，区段名称检测仅仅是以字符串比较的方式进行，它不会真检测指定的区段是否真正存在。
name&gt;：可以是一个“listen”、“frontend”或“backend”区段的名称，而“.”则表示stats scope语句所定义的当前区段。  
尽管“stats scope”一条就能够启用统计报告，但还是建议设定其它所有的参数，以免其依赖于默认设定而带来非期后果。下面是一个配置案例。
backend private_monitoring
    stats enable
    stats uri     /haproxyadmin?stats
    stats refresh 10s
&lt;/name&gt;&lt;/code&gt;&lt;/pre&gt;
3.15 stats auth  
&lt;pre&gt;&lt;code&gt;
stats auth &lt;user&gt;:&lt;passwd&gt;
启用带认证的统计报告功能并授权一个用户帐号，其不能用于“frontend”区段。
&lt;user&gt;：授权进行访问的用户名；
&lt;passwd&gt;：此用户的访问密码，明文格式；
此语句将基于默认设定启用统计报告功能，并仅允许其定义的用户访问，其也可以定义多次以授权多个用户帐号。可以结合“stats realm”参数在提示用户认证时给出一个领域说明信息。在使用非法用户访问统计功能时，其将会响应一个“401 Forbidden”页面。其认证方式为HTTP Basic认证，密码传输会以明文方式进行，因此，配置文件中也使用明文方式存储以说明其非保密信息故此不能相同于其它关键性帐号的密码。
尽管“stats auth”一条就能够启用统计报告，但还是建议设定其它所有的参数，以免其依赖于默认设定而带来非期后果。
&lt;/passwd&gt;&lt;/user&gt;&lt;/passwd&gt;&lt;/user&gt;&lt;/code&gt;&lt;/pre&gt;
3.16 stats admin  
&lt;pre&gt;&lt;code&gt;
stats admin { if | unless } &lt;cond&gt;
在指定的条件满足时启用统计报告页面的管理级别功能，它允许通过web接口启用或禁用服务器，不过，基于安全的角度考虑，统计报告页面应该尽可能为只读的。此外，如果启用了HAProxy的多进程模式，启用此管理级别将有可能导致异常行为。
目前来说，POST请求方法被限制于仅能使用缓冲区减去保留部分之外的空间，因此，服务器列表不能过长，否则，此请求将无法正常工作。因此，建议一次仅调整少数几个服务器。下面是两个案例，第一个限制了仅能在本机打开报告页面时启用管理级别功能，第二个定义了仅允许通过认证的用户使用管理级别功能。
backend stats_localhost
    stats enable
    stats admin if LOCALHOST
backend stats_auth
    stats enable
    stats auth  haproxyadmin:password
    stats admin if TRUE
&lt;/cond&gt;&lt;/code&gt;&lt;/pre&gt;
3.17 option httplog  
&lt;pre&gt;&lt;code&gt;
option httplog [ clf ]
启用记录HTTP请求、会话状态和计时器的功能。
clf：使用CLF格式来代替HAProxy默认的HTTP格式，通常在使用仅支持CLF格式的特定日志分析器时才需要使用此格式。
默认情况下，日志输入格式非常简陋，因为其仅包括源地址、目标地址和实例名称，而“option httplog”参数将会使得日志格式变得丰富许多，其通常包括但不限于HTTP请求、连接计时器、会话状态、连接数、捕获的首部及cookie、“frontend”、“backend”及服务器名称，当然也包括源地址和端口号等。
&lt;/code&gt;&lt;/pre&gt;
3.18 option logasap  
&lt;pre&gt;&lt;code&gt;
        option logasap  
    no option logasap  
启用或禁用提前将HTTP请求记入日志，不能用于“backend”区段。  
默认情况下，HTTP请求是在请求结束时进行记录以便能将其整体传输时长和字节数记入日志，由此，传较大的对象时，其记入日志的时长可能会略有延迟。“option logasap”参数能够在服务器发送complete首部时即时记录日志，只不过，此时将不记录整体传输时长和字节数。此情形下，捕获“Content-Length”响应首部来记录传输的字节数是一个较好选择。下面是一个例子。  
  listen http_proxy 0.0.0.0:80
      mode http
      option httplog
      option logasap
      log 172.16.100.9 local2
&lt;/code&gt;&lt;/pre&gt;
3.19 option forwardfor  
&lt;pre&gt;&lt;code&gt;
option forwardfor [ except &lt;network&gt; ] [ header &lt;name&gt; ] [ if-none ]
允许在发往服务器的请求首部中插入“X-Forwarded-For”首部。  
&lt;network&gt;：可选参数，当指定时，源地址为匹配至此网络中的请求都禁用此功能。  
&lt;name&gt;：可选参数，可使用一个自定义的首部，如“X-Client”来替代“X-Forwarded-For”。有些独特的web服务器的确需要用于一个独特的首部
if-none：仅在此首部不存在时才将其添加至请求报文问道中
HAProxy工作于反向代理模式，其发往服务器的请求中的客户端IP均为HAProxy主机的地址而非真正客户端的地址，这会使得服务器端的日志信息记录不了真正的请求来源，“X-Forwarded-For”首部则可用于解决此问题。HAProxy可以向每个发往服务器的请求上添加此首部，并以客户端IP为其value
需要注意的是，HAProxy工作于隧道模式，其仅检查每一个连接的第一个请求，因此，仅第一个请求报文被附加此首部。如果想为每一个请求都附加此首部，请确保同时使用了“option httpclose”、“option forceclose”和“option http-server-close”几个option。  
下面是一个例子
frontend www
    mode http
    option forwardfor except 127.0.0.1
&lt;/name&gt;&lt;/network&gt;&lt;/name&gt;&lt;/network&gt;&lt;/code&gt;&lt;/pre&gt;
3.20 errorfile  
&lt;pre&gt;&lt;code&gt;
errorfile &lt;code&gt; &lt;file&gt;
在用户请求不存在的页面时，返回一个页面文件给客户端而非由haproxy生成的错误代码；可用于所有段中
&lt;code&gt;：指定对HTTP的哪些状态码返回指定的页面；这里可用的状态码有200、400、403、408、500、502、503和504；
&lt;file&gt;：指定用于响应的页面文件；
例如
errorfile 400 /etc/haproxy/errorpages/400badreq.http
errorfile 403 /etc/haproxy/errorpages/403forbid.http
errorfile 503 /etc/haproxy/errorpages/503sorry.http
&lt;/file&gt;&lt;/code&gt;&lt;/file&gt;&lt;/code&gt;&lt;/code&gt;&lt;/pre&gt;
3.21 errorloc 和 errorloc302  
&lt;pre&gt;&lt;code&gt;
errorloc &lt;code&gt; &lt;url&gt;
errorloc302 &lt;code&gt; &lt;url&gt;
请求错误时，返回一个HTTP重定向至某URL的信息；可用于所有配置段中。
&lt;code&gt;：指定对HTTP的哪些状态码返回指定的页面；这里可用的状态码有200、400、403、408、500、502、503和504；
&lt;url&gt;：Location首部中指定的页面位置的具体路径，可以是在当前服务器上的页面的相对路径，也可以使用绝对路径；需要注意的是，如果URI自身错误时产生某特定状态码信息的话，有可能会导致循环定向；
需要留意的是，这两个关键字都会返回302状态吗，这将使得客户端使用同样的HTTP方法获取指定的URL，对于非GET法的场景(如POST)来说会产生问题，因为返回客户的URL是不允许使用GET以外的其它方法的。如果的确有这种问题，可以使用errorloc303来返回303状态码给客户端。
&lt;/url&gt;&lt;/code&gt;&lt;/url&gt;&lt;/code&gt;&lt;/url&gt;&lt;/code&gt;&lt;/code&gt;&lt;/pre&gt;
3.22 errorloc303
&lt;pre&gt;&lt;code&gt;
`errorloc303 &lt;code&gt; &lt;url&gt;`  
请求错误时，返回一个HTTP重定向至某URL的信息给客户端；可用于所有配置段中。  
`&lt;code&gt;`：指定对HTTP的哪些状态码返回指定的页面；这里可用的状态码有400、403、408、500、502、503和504；  
&lt;url&gt;：Location首部中指定的页面位置的具体路径，可以是在当前服务器上的页面的相对路径，也可以使用绝对路径；需要注意的是，如果URI自身错误时产生某特定状态码信息的话，有可能会导致循环定向；  
例如：
backend webserver
  server 172.16.100.6 172.16.100.6:80 check maxconn 3000 cookie srv01
  server 172.16.100.7 172.16.100.7:80 check maxconn 3000 cookie srv02
  errorloc 403 /etc/haproxy/errorpages/sorry.htm
  errorloc 503 /etc/haproxy/errorpages/sorry.htm
&lt;/url&gt;&lt;/code&gt;&lt;/url&gt;&lt;/code&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;一个配置示例：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
\#---------------------------------------------------------------------
\# Global settings
\#---------------------------------------------------------------------
global
    # to have these messages end up in /var/log/haproxy.log you will
    # need to:
    #
    # 1) configure syslog to accept network log events.  This is done
    #    by adding the &#39;-r&#39; option to the SYSLOGD_OPTIONS in
    #    /etc/sysconfig/syslog
    #
    # 2) configure local2 events to go to the /var/log/haproxy.log
    #   file. A line like the following can be added to
    #   /etc/sysconfig/syslog
    #
    #    local2.*                       /var/log/haproxy.log
    #
    log         127.0.0.1 local2
    chroot      /var/lib/haproxy
    pidfile     /var/run/haproxy.pid
    maxconn     4000
    user        haproxy
    group       haproxy
    daemon
defaults
    mode                    http
    log                     global
    option                  httplog
    option                  dontlognull
    option http-server-close
    option forwardfor       except 127.0.0.0/8
    option                  redispatch
    retries                 3
    timeout http-request    10s
    timeout queue           1m
    timeout connect         10s
    timeout client          1m
    timeout server          1m
    timeout http-keep-alive 10s
    timeout check           10s
    maxconn                 30000
listen stats
    mode http
    bind 0.0.0.0:1080
    stats enable
    stats hide-version
    stats uri     /haproxyadmin?stats
    stats realm   Haproxy\ Statistics
    stats auth    admin:admin
    stats admin   if TRUE
frontend http-in
    bind \*:80
    mode http
    log global
    option httpclose
    option logasap
    option dontlognull
    capture request  header Host len 20
    capture request  header Referer len 60
    default_backend servers
frontend healthcheck
    bind :1099
    mode http
    option httpclose
    option forwardfor
    default_backend servers
backend servers
    balance roundrobin
    server websrv1 192.168.10.11:80 check maxconn 2000
    server websrv2 192.168.10.12:80 check maxconn 2000
&lt;/code&gt;&lt;/pre&gt;  
负载均衡MySQL服务的配置示例  
&lt;pre&gt;&lt;code&gt;
\#---------------------------------------------------------------------
\# Global settings
\#---------------------------------------------------------------------
global
    \# to have these messages end up in /var/log/haproxy.log you will
    \# need to:
    \#
    \# 1) configure syslog to accept network log events.  This is done
    \#    by adding the &#39;-r&#39; option to the SYSLOGD_OPTIONS in
    \#    /etc/sysconfig/syslog
    \#
    \# 2) configure local2 events to go to the /var/log/haproxy.log
    \#   file. A line like the following can be added to
    \#   /etc/sysconfig/syslog
    \#
    \#    local2.*                       /var/log/haproxy.log
    \#
    log         127.0.0.1 local2
    chroot      /var/lib/haproxy
    pidfile     /var/run/haproxy.pid
    maxconn     4000
    user        haproxy
    group       haproxy
    daemon
defaults
    mode                    tcp
    log                     global
    option                  httplog
    option                  dontlognull
    retries                 3
    timeout http-request    10s
    timeout queue           1m
    timeout connect         10s
    timeout client          1m
    timeout server          1m
    timeout http-keep-alive 10s
    timeout check           10s
    maxconn                 600
listen stats
    mode http
    bind 0.0.0.0:1080
    stats enable
    stats hide-version
    stats uri     /haproxyadmin?stats
    stats realm   Haproxy\ Statistics
    stats auth    admin:admin
    stats admin if TRUE
frontend mysql
    bind \*:3306
    mode tcp
    log global
    default_backend mysqlservers
backend mysqlservers
    balance leastconn
    server dbsrv1 192.168.10.11:3306 check port 3306 intval 2 rise 1 fall 2 maxconn 300
    server dbsrv2 192.168.10.12:3306 check port 3306 intval 2 rise 1 fall 2 maxconn 300
&lt;/code&gt;&lt;/pre&gt;
&lt;/backend&gt;&lt;/backend&gt;&lt;/conns&gt;&lt;/conns&gt;&lt;/level&gt;&lt;/facility&gt;&lt;/ipv4_address:port&gt;&lt;/address&gt;&lt;/minlevel&gt;&lt;/level&gt;&lt;/facility&gt;&lt;/address&gt;&lt;/method&gt;&lt;/interface&gt;&lt;/address:port&gt;&lt;/port_range&gt;&lt;/address&gt;&lt;/interface&gt;&lt;/port_range&gt;&lt;/address&gt;&lt;/port_range&gt;&lt;/address&gt;&lt;/max_wait&gt;&lt;/arguments&gt;&lt;/algorithm&gt;&lt;/number&gt;&lt;/number&gt;&lt;/number&gt;&lt;/number&gt;&lt;/number&gt;&lt;/number&gt;&lt;/number&gt;&lt;/0..50,&gt;&lt;/number&gt;&lt;/number&gt;&lt;/number&gt;&lt;/string&gt;&lt;/facility&gt;&lt;/address&gt;&lt;/group&gt;&lt;/number&gt;&lt;/jail&gt;</content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;HAProxy简介&quot;&gt;&lt;a href=&quot;#HAProxy简介&quot; class=&quot;headerlink&quot; title=&quot;HAProxy简介&quot;&gt;&lt;/a&gt;HAProxy简介&lt;/h4&gt;&lt;p&gt;&lt;em&gt;HAProxy提供高可用性、负载均衡以及基于TCP和HTTP应用的代理，支持虚拟主机，它是免费、快速并且可靠的一种解决方案。HAProxy特别适用于那些负载特大的web站点，这些站点通常又需要会话保持或七层处理。HAProxy运行在时下的硬件上，完全可以支持数以万计的并发连接。并且它的运行模式使得它可以很简单安全的整合进您当前的架构中， 同时可以保护你的web服务器不被暴露到网络上.&lt;/em&gt;&lt;br&gt;&lt;em&gt;HAProxy实现了一种事件驱动、单一进程模型，此模型支持非常大的并发连接数。多进程或多线程模型受内存限制 、系统调度器限制以及无处不在的锁限制，很少能处理数千并发连接。事件驱动模型因为在有更好的资源和时间管理的用户端(User-Space) 实现所有这些任务，所以没有这些问题。此模型的弊端是，在多核系统上，这些程序通常扩展性较差。这就是为什么他们必须进行优化以 使每个CPU时间片(Cycle)做更多的工作。&lt;/em&gt;&lt;br&gt;————百度百科
    
    </summary>
    
      <category term="负载均衡" scheme="https://iceziyao.github.io/categories/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"/>
    
    
      <category term="负载均衡" scheme="https://iceziyao.github.io/tags/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"/>
    
  </entry>
  
  <entry>
    <title>高可用集群系列之基础篇1</title>
    <link href="https://iceziyao.github.io/2016/01/16/HA/%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A401/"/>
    <id>https://iceziyao.github.io/2016/01/16/HA/高可用集群01/</id>
    <published>2016-01-15T16:00:00.000Z</published>
    <updated>2016-08-06T14:50:31.530Z</updated>
    
    <content type="html">&lt;h3 id=&quot;什么是集群&quot;&gt;&lt;a href=&quot;#什么是集群&quot; class=&quot;headerlink&quot; title=&quot;什么是集群?&quot;&gt;&lt;/a&gt;什么是集群?&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;集群（cluster）就是一组计算机，它们作为一个整体向用户提供一组网络资源。这些单个的计算机系统就是集群的节点（node）。一个理想的集群是，用户从来不会意识到集群系统底层的节点，在他/她们看来，集群是一个系统，而非多个计算机系统。并且集群系统的管理员可以随意增加和删改集群系统的节点。&lt;br&gt;　　更详细的说，集群（一组协同工作的计算机）是充分利用计算资源的一个重要概念，因为它能够将工作负载从一个超载的系统（或节点）迁移到集群中的另一个系统上。其处理能力是与专用计算机(小型机,大型机)可相比,但其性价比高于专用计算机.常见的硬件有:结点,网络,存储.软件有:机群系统,节点系统,应用支撑软件。&lt;br&gt;　　Cluster集群技术可如下定义：一组相互独立的服务器在网络中表现为单一的系统，并以单一系统的模式加以管理。此单一系统为客户工作站提供高可靠性的服务。大多数模式下，集群中所有的计算机拥有一个共同的名称，集群内任一系统上运行的服务可被所有的网络客户所使用。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;集群系统的主要优点&quot;&gt;&lt;a href=&quot;#集群系统的主要优点&quot; class=&quot;headerlink&quot; title=&quot;集群系统的主要优点:&quot;&gt;&lt;/a&gt;集群系统的主要优点:&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;(1)高可扩展性：&lt;br&gt;    (2)高可用性HA：集群中的一个节点失效，它的任务可传递给其他节点。可以有效防止单点失效。&lt;br&gt;    (3)高性能：负载平衡集群允许系统同时接入更多的用户。&lt;br&gt;    (4)高性价比：可以采用廉价的符合工业标准的硬件构造高性能的系统。  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;集群系统的分类&quot;&gt;&lt;a href=&quot;#集群系统的分类&quot; class=&quot;headerlink&quot; title=&quot;集群系统的分类&quot;&gt;&lt;/a&gt;集群系统的分类&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;1)、高可用(High Availability)集群,简称HA集群。&lt;br&gt;    这类集群致力于提供高度可靠的服务。就是利用集群系统的容错性对外提供7*24小时不间断的服务，如高可用的文件服务器、数据库服务等关键应用。&lt;br&gt;    负载均衡集群：使任务可以在集群中尽可能平均地分摊不同的计算机进行处理，充分利用集群的处理能力，提高对任务的处理效率。&lt;br&gt;    在实际应用中这几种集群类型可能会混合使用，以提供更加高效稳定的服务。如在一个使用的网络流量负载均衡集群中，就会包含高可用的网络文件系统、高可用的网络服务。&lt;br&gt;    (2)、性能计算(High Perfermance Computing)集群，简称HPC集群，也称为科学计算集群。&lt;br&gt;    在这种集群上运行的是专门开发的并行应用程序，它可以把一个问题的数据分布到多台的计算机上，利用这些计算机的共同资源来完成计算任务，从而可以解决单机不能胜任的工作（如问题规模太大，单机计算速度太慢）。&lt;br&gt;    这类集群致力于提供单个计算机所不能提供的强大的计算能力。如天气预报、石油勘探与油藏模拟、分子模拟、生物计算等。  &lt;/p&gt;
&lt;h3 id=&quot;什么是高可用性-HA&quot;&gt;&lt;a href=&quot;#什么是高可用性-HA&quot; class=&quot;headerlink&quot; title=&quot;什么是高可用性 (HA)&quot;&gt;&lt;/a&gt;什么是高可用性 (HA)&lt;/h3&gt;&lt;p&gt;计算机系统的可用性(availability)是通过系统的可靠性(reliability)和可维护性(maintainability)来度量的。工程上通常用平均无故障时间(MTTF)来度量系统的可靠性,用平均维修时间（MTTR）来度量系统的可维护性。于是可用性被定义为：MTTF/(MTTF+MTTR)*100%  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;HA的容错备援运作过程  &lt;blockquote&gt;
&lt;p&gt;自动侦测(Auto-Detect)阶段 由主机上的软件通过冗余侦测线，经由复杂的监听程序。逻辑判断，来相互侦测对方运行的情况，所检查的项目有：主机硬件(CPU和周边)、主机网络、主机操作系统、数据库引擎及其它应用程序、主机与磁盘阵列连线。为确保侦测的正确性，而防止错误的判断，可设定安全侦测时间，包括侦测时间间隔，侦测次数以调整安全系数，并且由主机的冗余通信连线，将所汇集的讯息记录下来，以供维护参考。&lt;br&gt;  自动切换(Auto-Switch)阶段 某一主机如果确认对方故障，则正常主机除继续进行原来的任务，还将依据各种容错备援模式接管预先设定的备援作业程序，并进行后续的程序及服务。&lt;br&gt;  自动恢复(Auto-Recovery)阶段 在正常主机代替故障主机工作后，故障主机可离线进行修复工作。在故障主机修复后，透过冗余通讯线与原正常主机连线，自动切换回修复完成的主机上。整个回复过程完成由EDI-HA自动完成，亦可依据预先配置，选择回复动作为半自动或不回复。  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;HA三种工作方式：&quot;&gt;&lt;a href=&quot;#HA三种工作方式：&quot; class=&quot;headerlink&quot; title=&quot;HA三种工作方式：&quot;&gt;&lt;/a&gt;HA三种工作方式：&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;（1）、主从方式 （非对称方式）&lt;br&gt;工作原理：主机工作，备机处于监控准备状况；当主机宕机时，备机接管主机的一切工作，待主机恢复正常后，按使用者的设定以自动或手动方式将服务切换到主机上运行，数据的一致性通过共享存储系统解决。&lt;br&gt;（2）、双机双工方式（互备互援）&lt;br&gt;工作原理：两台主机同时运行各自的服务工作且相互监测情况，当任一台主机宕机时，另一台主机立即接管它的一切工作，保证工作实时，应用服务系统的关键数据存放在共享存储系统中。&lt;br&gt;（3）、集群工作方式（多服务器互备方式）&lt;br&gt;工作原理：多台主机一起工作，各自运行一个或几个服务，各为服务定义一个或多个备用主机，当某个主机故障时，运行在其上的服务就可以被其它主机接管。  &lt;/p&gt;
&lt;/blockquote&gt;
</content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;什么是集群&quot;&gt;&lt;a href=&quot;#什么是集群&quot; class=&quot;headerlink&quot; title=&quot;什么是集群?&quot;&gt;&lt;/a&gt;什么是集群?&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;集群（cluster）就是一组计算机，它们作为一个整体向用户提供一组网络资源。这些单个的计算机系统就是集群的节点（node）。一个理想的集群是，用户从来不会意识到集群系统底层的节点，在他/她们看来，集群是一个系统，而非多个计算机系统。并且集群系统的管理员可以随意增加和删改集群系统的节点。&lt;br&gt;　　更详细的说，集群（一组协同工作的计算机）是充分利用计算资源的一个重要概念，因为它能够将工作负载从一个超载的系统（或节点）迁移到集群中的另一个系统上。其处理能力是与专用计算机(小型机,大型机)可相比,但其性价比高于专用计算机.常见的硬件有:结点,网络,存储.软件有:机群系统,节点系统,应用支撑软件。&lt;br&gt;　　Cluster集群技术可如下定义：一组相互独立的服务器在网络中表现为单一的系统，并以单一系统的模式加以管理。此单一系统为客户工作站提供高可靠性的服务。大多数模式下，集群中所有的计算机拥有一个共同的名称，集群内任一系统上运行的服务可被所有的网络客户所使用。&lt;br&gt;
    
    </summary>
    
      <category term="集群" scheme="https://iceziyao.github.io/categories/%E9%9B%86%E7%BE%A4/"/>
    
    
      <category term="HA" scheme="https://iceziyao.github.io/tags/HA/"/>
    
  </entry>
  
  <entry>
    <title>高可用集群系列之基础篇2</title>
    <link href="https://iceziyao.github.io/2016/01/16/HA/%E9%AB%98%E5%8F%AF%E7%94%A8%E5%9F%BA%E7%A1%80/"/>
    <id>https://iceziyao.github.io/2016/01/16/HA/高可用基础/</id>
    <published>2016-01-15T16:00:00.000Z</published>
    <updated>2016-08-06T14:50:28.516Z</updated>
    
    <content type="html">&lt;h2 id=&quot;基础概念&quot;&gt;&lt;a href=&quot;#基础概念&quot; class=&quot;headerlink&quot; title=&quot;基础概念&quot;&gt;&lt;/a&gt;基础概念&lt;/h2&gt;&lt;h3 id=&quot;心跳&quot;&gt;&lt;a href=&quot;#心跳&quot; class=&quot;headerlink&quot; title=&quot;心跳&quot;&gt;&lt;/a&gt;心跳&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;什么是心跳&lt;br&gt;就是将多台服务器用网络连接起来，而后每一台服务器都不停的将自己依然在线的信息很简短很小的通告给同一个网络中的备用服务器的主机，告诉其实主机自己依然在线，其它服务器收到这个心跳信息就认为本机是在线的。所谓心跳就是一群人在深夜行走，相互看不见对方，每个人隔一段时间呼唤一声，告诉同伴自己的状况.  &lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;心跳信息怎么传递&lt;br&gt;其实就是进程中的通信两台主机是没法通信的，只能利用网络功能，通过进程监听在某一套接字上，实现数据发送，数据请求，所以多台服务器就得运行同等的进程，这两个进程不停的进行通信，主节点(主服务器)不停的向对方同等的节点发送自己的心跳信息，那这个软件就叫高可用的集群的基准层次，也叫心跳信息传递层以及事物信息的传递层，这是运行在集群中的各节点上的进程，这个进程是个服务软件，关机后需要将其启动起来，主机间才可以传递信息的，一般是主节点传给备节点。  &lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;资源&quot;&gt;&lt;a href=&quot;#资源&quot; class=&quot;headerlink&quot; title=&quot;资源&quot;&gt;&lt;/a&gt;资源&lt;/h3&gt;&lt;h4 id=&quot;什么是资源&quot;&gt;&lt;a href=&quot;#什么是资源&quot; class=&quot;headerlink&quot; title=&quot;什么是资源&quot;&gt;&lt;/a&gt;什么是资源&lt;/h4&gt;&lt;p&gt;其实资源就是启动一个服务需要的子项目&lt;br&gt;以web服务为例子,ip是资源,web服务是资源,共享存储是资源,网页,图片,session是资源.&lt;br&gt;如果主节点挂了，多个备节点怎么样来选择一个备节点来做为提供服务的一个节点呢，而这种应该选择哪个备用节点来做为提供服务的机制就叫做&lt;strong&gt; 集群事物决策 &lt;/strong&gt; 的过程。&lt;br&gt;&lt;strong&gt; 因此，实现一个高可用集群一般需要ip、服务（脚本）和文件系统（存储数据），当然有些高可用集群不需要存储设备的。&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&quot;资源等级&quot;&gt;&lt;a href=&quot;#资源等级&quot; class=&quot;headerlink&quot; title=&quot;资源等级&quot;&gt;&lt;/a&gt;资源等级&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;primitive：可以理解为主资源，有时候看到的会是native，都是一个意思，该资源只在主节点上有。（当然备份节点一旦将资源夺过来了，也就成了主节点，因此，主节点是相对来说的）&lt;/li&gt;
&lt;li&gt;group：组资源，将多个资源绑定在一个同一个组上面且运行在同一个节点上。&lt;/li&gt;
&lt;li&gt;clone：是将primitive资源克隆n份且运行在每一个节点上&lt;/li&gt;
&lt;li&gt;master/slave：也是将primitive克隆2份、其中master和slave节点各运行一份，且只能在这2个节点上运行。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&quot;资源约束&quot;&gt;&lt;a href=&quot;#资源约束&quot; class=&quot;headerlink&quot; title=&quot;资源约束&quot;&gt;&lt;/a&gt;资源约束&lt;/h4&gt;&lt;p&gt;对于某些集群服务来说，启动相关的资源是有先后顺序的。例如启动一个mysql集群服务，首先应该先挂载共享存储设备，否则即时mysql服务启动起来了，用户也访问不了数据。因此,要对资源一个约束.  &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;位置约束（location）：资源对节点的倾向程度，通常可以使用一个分数（score）来定义，当score为正值时，表示资源倾向与此节点；负值表示资源倾向逃离于此节点。也可以将score定义为-inf(负无穷大)和inf（正无穷大）。例如：有三个节点rs1、rs2、rs3当rs1是主节点且发生故障时，则比较rs2和rs3的score值，谁是正值，则资源将会转移到哪个节点上去。  &lt;/li&gt;
&lt;li&gt;排列约束（colocation）：用来定义资源是否可以在一起，通常也是使用一个score来定义的。当score是正值表示资源可以在一起；否则表示不可以在一起。通过定义资源类型为group也可以来将所有资源绑定在一起。  &lt;/li&gt;
&lt;li&gt;顺序约束（order）：用来定义资源启动和停止的顺序。web为例子,备用节点上线后,VIP必须先转移到本地,其次共享存储到位,最后才是开启web服务器.  &lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&quot;资源转移&quot;&gt;&lt;a href=&quot;#资源转移&quot; class=&quot;headerlink&quot; title=&quot;资源转移&quot;&gt;&lt;/a&gt;资源转移&lt;/h4&gt;&lt;p&gt;将有故障节点的VIP设置到另一个节点上去，并在另一个节点启用相应的服务，挂载相应的存储设备等等都可以叫做资源转移。  &lt;/p&gt;
&lt;h2 id=&quot;HA实现原理&quot;&gt;&lt;a href=&quot;#HA实现原理&quot; class=&quot;headerlink&quot; title=&quot;HA实现原理&quot;&gt;&lt;/a&gt;HA实现原理&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;在高可用集群的各节点中定义了一个抽象层,信息传递层(Messaing Layer),用来传递集群之间的事务(Transaction)信息.事务信息中包含了节点的心跳信息(是否在线),节点的主机名、IP等一系列信息&lt;/li&gt;
&lt;li&gt;通过一个程序获取信息传递层的信息，进行服务调配，资源管理.(资源管理层)&lt;/li&gt;
&lt;li&gt;服务代理，通过策略代理各节点服务。(资源代理层)&lt;br&gt;信息层传递信息，资源管理层通过监听信息层的信息进行相应规则的资源调配和服务迁移。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;Messaging-Layer（信息传递层）&quot;&gt;&lt;a href=&quot;#Messaging-Layer（信息传递层）&quot; class=&quot;headerlink&quot; title=&quot;Messaging  Layer（信息传递层）&quot;&gt;&lt;/a&gt;Messaging  Layer（信息传递层）&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;主要的作用是传递当前节点的心跳信息，并告知给对方，这样对方就知道其他节点是否在线。如果不在线，则可以实现资源转移，这样另一台节点就可以充当主节点，并正常提供服务。传递心跳信息一般使用一根心跳线连接，该线接口可以使用串行接口也可以是以太网接口来连接。每一个节点上都包含信息层。&lt;br&gt;常见软件:  &lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;hearbeat&lt;/li&gt;
&lt;li&gt;keepalived&lt;/li&gt;
&lt;li&gt;ultramonkey&lt;/li&gt;
&lt;li&gt;Corosync&lt;/li&gt;
&lt;li&gt;cman&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;ha-aware-CRM-资源管理层&quot;&gt;&lt;a href=&quot;#ha-aware-CRM-资源管理层&quot; class=&quot;headerlink&quot; title=&quot;ha-aware/CRM (资源管理层)&quot;&gt;&lt;/a&gt;ha-aware/CRM (资源管理层)&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Cluster  Resource Messager,资源管理器，它主要是用来提供那些不具有高可用的服务提供高可用性的。它需要借助Messaging  Layer来实现工作，因此工作在Messaging Layer上层。&lt;/li&gt;
&lt;li&gt;资源管理器的主要工作是根据messaging Layer传递的健康信息来决定服务的启动、停止和资源转移、资源的定义和资源分配。在每一个节点上都包含一个CRM，且每个CRM都维护这一个CIB（Cluster Internet  Base，集群信息库），只有在主节点上的CIB是可以修改的，其他节点上的CIB都是从主节点那里复制而来的。在CRM中还包含LRM和DC等组件。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;CIB&quot;&gt;&lt;a href=&quot;#CIB&quot; class=&quot;headerlink&quot; title=&quot;CIB&quot;&gt;&lt;/a&gt;CIB&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;集群信息库 XML文档&lt;br&gt;集群资源管理器必须借助于Messageing Layer通告给每一个节点，自动的广播或组播给每一个节点，这样就保证了每一个节点上的信息都是一样的，而这些数据在计算机中又怎么样来交互数据的呢，这里就要基于扩展标记语言来实现数据的格式传递的，这种叫半结构化数据基于XML的，所以在各节点之间实现配置信息保存都是通过XML文件保存的，而要能够理解这个XML文件保存的信息使用到一个工具叫CIB(Cluster Information Base集群信息库)；只要能连接到CRM上都可以去配置这个XML文件，首先它会先保存到DC的XML中，然后再由DC同步支每个节点上的XML文件中去的；&lt;br&gt;对于CIB，只有工作在DC（主节点）上的文档是可以修改的，其他CIB都是复制DC上的那个文档而来的。  &lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;LRM&quot;&gt;&lt;a href=&quot;#LRM&quot; class=&quot;headerlink&quot; title=&quot;LRM&quot;&gt;&lt;/a&gt;LRM&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Local Resource  Messager，叫做本地资源管理器，它是CRM的一个子组件，用来获取某个资源的状态，并且管理本地资源的。&lt;br&gt;对于LRM,是执行CRM传递过来的在本地执行某个资源的执行和停止的具体执行人，当某个节点发生故障之后，是由DC通过PE（策略引擎）和TE（实施引擎）来决定是否抢夺资源。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;DC&quot;&gt;&lt;a href=&quot;#DC&quot; class=&quot;headerlink&quot; title=&quot;DC&quot;&gt;&lt;/a&gt;DC&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;事务调节员.当DC所在的主机挂了就会先选出一个DC，再由DC做出事物的决策。&lt;br&gt;任何DC上会额外运行两个进程，一个叫PE(Policy Engine策略引擎)，所谓策略引擎就是将底层信息层收集整个集群中所有节点上的信息在本地生成一个大图big pic来策略节点运行在哪个节点上，并通知其实节点上的资源管理器来实现资源的启动和关闭等操作；一个叫TE(Transition Engine 实施引擎)，它主要是把PE做出的决策通告给对应节点的CRM；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;PE和TE是DC的子组件&lt;/p&gt;
&lt;h4 id=&quot;PE（策略引擎）&quot;&gt;&lt;a href=&quot;#PE（策略引擎）&quot; class=&quot;headerlink&quot; title=&quot;PE（策略引擎）&quot;&gt;&lt;/a&gt;PE（策略引擎）&lt;/h4&gt;&lt;p&gt;来定义资源转移的一整套转移方式，但只是做策略者，并不亲自来参加资源转移的过程，而是让TE来执行自己的策略。&lt;/p&gt;
&lt;h4 id=&quot;TE-实施引擎）&quot;&gt;&lt;a href=&quot;#TE-实施引擎）&quot; class=&quot;headerlink&quot; title=&quot;TE (实施引擎）&quot;&gt;&lt;/a&gt;TE (实施引擎）&lt;/h4&gt;&lt;p&gt;执行PE做出的策略的并且只有DC上才运行PE和TE。&lt;/p&gt;
&lt;h3 id=&quot;实施软件&quot;&gt;&lt;a href=&quot;#实施软件&quot; class=&quot;headerlink&quot; title=&quot;实施软件&quot;&gt;&lt;/a&gt;实施软件&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;可以提供CRM的软件有：  &lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;heartbeat v1自带的资源管理为haresource&lt;/li&gt;
&lt;li&gt;heartbeat v2自带的资源管理有haresource和crm&lt;/li&gt;
&lt;li&gt;Pacemaker  &lt;/li&gt;
&lt;li&gt;Cman 是红帽开发的一个资源管理器,是红帽开发的一个资源管理器,6.x版本后红帽也开始使用强大的pacemaker  &lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;资源代理层（Resource-Agents）&quot;&gt;&lt;a href=&quot;#资源代理层（Resource-Agents）&quot; class=&quot;headerlink&quot; title=&quot;资源代理层（Resource Agents）&quot;&gt;&lt;/a&gt;资源代理层（Resource Agents）&lt;/h2&gt;&lt;p&gt;集群资源代理(能够管理本节点上的属于集群资源的某一资源的启动，停止和状态信息的脚本)&lt;/p&gt;
&lt;h3 id=&quot;LSB&quot;&gt;&lt;a href=&quot;#LSB&quot; class=&quot;headerlink&quot; title=&quot;LSB&quot;&gt;&lt;/a&gt;LSB&lt;/h3&gt;&lt;p&gt;常见的如/etc/init.d/下的标准linux脚本风格。&lt;/p&gt;
&lt;h3 id=&quot;OCF&quot;&gt;&lt;a href=&quot;#OCF&quot; class=&quot;headerlink&quot; title=&quot;OCF&quot;&gt;&lt;/a&gt;OCF&lt;/h3&gt;&lt;p&gt;比LSB更高级  &lt;/p&gt;
&lt;h3 id=&quot;Legacy-heartbeat&quot;&gt;&lt;a href=&quot;#Legacy-heartbeat&quot; class=&quot;headerlink&quot; title=&quot;Legacy heartbeat&quot;&gt;&lt;/a&gt;Legacy heartbeat&lt;/h3&gt;&lt;p&gt;heartbeat自带的  &lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;基础概念&quot;&gt;&lt;a href=&quot;#基础概念&quot; class=&quot;headerlink&quot; title=&quot;基础概念&quot;&gt;&lt;/a&gt;基础概念&lt;/h2&gt;&lt;h3 id=&quot;心跳&quot;&gt;&lt;a href=&quot;#心跳&quot; class=&quot;headerlink&quot; title=&quot;心跳&quot;&gt;&lt;/a&gt;心跳&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;什么是心跳&lt;br&gt;就是将多台服务器用网络连接起来，而后每一台服务器都不停的将自己依然在线的信息很简短很小的通告给同一个网络中的备用服务器的主机，告诉其实主机自己依然在线，其它服务器收到这个心跳信息就认为本机是在线的。所谓心跳就是一群人在深夜行走，相互看不见对方，每个人隔一段时间呼唤一声，告诉同伴自己的状况.
    
    </summary>
    
      <category term="集群" scheme="https://iceziyao.github.io/categories/%E9%9B%86%E7%BE%A4/"/>
    
    
      <category term="HA" scheme="https://iceziyao.github.io/tags/HA/"/>
    
  </entry>
  
  <entry>
    <title>Memcached简介</title>
    <link href="https://iceziyao.github.io/2016/01/01/lnmp/Memcached/"/>
    <id>https://iceziyao.github.io/2016/01/01/lnmp/Memcached/</id>
    <published>2016-01-01T13:49:33.000Z</published>
    <updated>2016-08-06T14:50:03.790Z</updated>
    
    <content type="html">&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Memcached是一款开源、高性能、分布式内存对象缓存系统，可应用各种需要缓存的场景，其主要目的是通过降低对Database的访问来加速web应用程序。它是一个基于内存的“键值对”存储，用于存储数据库调用、API调用或页面引用结果的直接数据，如字符串、对象等。&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;memcached是以LiveJournal旗下Danga Interactive 公司的Brad Fitzpatric 为首开发的一款软件。现在&lt;br&gt;已成为mixi、hatena、Facebook、Vox、LiveJournal等众多服务中提高Web应用扩展性的重要因素。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Memcached是一款开发工具，它既不是一个代码加速器，也不是数据库中间件。其设计哲学思想主要反映在如下方面：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;简单key/value存储：服务器不关心数据本身的意义及结构，只要是可序列化数据即可。存储项由“键、过期时间、可选的标志及数据”四个部分组成；  &lt;/li&gt;
&lt;li&gt;功能的实现一半依赖于客户端，一半基于服务器端：客户负责发送存储项至服务器端、从服务端获取数据以及无法连接至服务器时采用相应的动作；服务端负责接收、存储数据，并负责数据项的超时过期；  &lt;/li&gt;
&lt;li&gt;各服务器间彼此无视：不在服务器间进行数据同步；  &lt;/li&gt;
&lt;li&gt;O(1)的执行效率  &lt;/li&gt;
&lt;li&gt;清理超期数据：默认情况下，Memcached是一个LRU缓存，同时，它按事先预订的时长清理超期数据；&lt;br&gt;但事实上，memcached不会删除任何已缓存数据，只是在其过期之后不再为客户所见；&lt;br&gt;而且，memcached也不会真正按期限清理缓存，而仅是当get命令到达时检查其时长；   &lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;Memcached提供了为数不多的几个命令来完成与服务器端的交互，这些命令基于memcached的协议实现。  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;存储类命令：set, add, replace, append, prepend&lt;br&gt;获取数据类命令：get, delete, incr/decr&lt;br&gt;统计类命令：stats, stats items, stats slabs, stats sizes&lt;br&gt;清理命令： flush_all  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;一、安装libevent&lt;br&gt;memcached依赖于libevent API，因此要事先安装之，项目主页：&lt;a href=&quot;http://libevent.org/，读者可自行选择需要的版本下载。本文采用的是目前最新版本的源码包libevent-2.0.16-stable.tar.gz。安装过程：&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://libevent.org/，读者可自行选择需要的版本下载。本文采用的是目前最新版本的源码包libevent-2.0.16-stable.tar.gz。安装过程：&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
# tar xf libevent-2.0.20-stable.tar.gz
# cd libevent-2.0.20
# ./configure --prefix=/usr/local/libevent
# make &amp;&amp; make install

# echo &quot;/usr/local/libevent/lib&quot; &gt; /etc/ld.so.conf.d/libevent.conf
# ldconfig
&lt;/code&gt;&lt;/pre&gt;
二、安装配置memcached

1. 安装memcached
&lt;pre&gt;&lt;code&gt;
# tar xf memcached-1.4.15.tar.gz
# cd memcached-1.4.15
# ./configure --prefix=/usr/local/memcached --with-libevent=/usr/local/libevent
# make &amp;&amp; make install
&lt;/code&gt;&lt;/pre&gt;
2. memcached SysV的startup脚本代码如下所示，将其建立为/etc/init.d/memcached文件：
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;11&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;12&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;13&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;14&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;15&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;16&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;17&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;18&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;19&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;20&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;21&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;22&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;23&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;24&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;25&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;26&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;27&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;28&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;29&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;30&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;31&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;32&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;33&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;34&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;35&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;36&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;37&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;38&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;39&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;40&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;41&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;42&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;43&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;44&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;45&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;46&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;47&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;48&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;49&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;50&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;51&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;52&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;53&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;54&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;55&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;56&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;57&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;58&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;59&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;60&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;61&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;62&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;63&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;64&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;65&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;66&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;67&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;68&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;69&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;70&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;71&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;72&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;73&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;#!/bin/bash&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;#&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# Init file for memcached&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;#&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# chkconfig: - 86 14&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# description: Distributed memory caching daemon&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;#&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# processname: memcached&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# config: /etc/sysconfig/memcached&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;. /etc/rc.d/init.d/functions&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;## Default variables&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;PORT=&amp;quot;11211&amp;quot;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;USER=&amp;quot;nobody&amp;quot;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;MAXCONN=&amp;quot;1024&amp;quot;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;CACHESIZE=&amp;quot;64&amp;quot;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;OPTIONS=&amp;quot;&amp;quot;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;RETVAL=0&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;prog=&amp;quot;/usr/local/memcached/bin/memcached&amp;quot;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;desc=&amp;quot;Distributed memory caching&amp;quot;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;lockfile=&amp;quot;/var/lock/subsys/memcached&amp;quot;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;start() &amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        echo -n $&amp;quot;Starting $desc (memcached): &amp;quot;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        daemon $prog -d -p $PORT -u $USER -c $MAXCONN -m $CACHESIZE -o &amp;quot;$OPTIONS&amp;quot;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        RETVAL=$?&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        echo&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        [ $RETVAL -eq 0 ] &amp;amp;&amp;amp; touch $lockfile&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        return $RETVAL&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;#125;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;stop() &amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        echo -n $&amp;quot;Shutting down $desc (memcached): &amp;quot;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        killproc $prog&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        RETVAL=$?&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        echo&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        [ $RETVAL -eq 0 ] &amp;amp;&amp;amp; rm -f $lockfile&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        return $RETVAL&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;#125;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;restart() &amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        stop&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        start&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;#125;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;reload() &amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        echo -n $&amp;quot;Reloading $desc ($prog): &amp;quot;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        killproc $prog -HUP&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        RETVAL=$?&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        echo&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        return $RETVAL&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;#125;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;case &amp;quot;$1&amp;quot; in&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  start)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        start&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        ;;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  stop)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        stop&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        ;;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  restart)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        restart&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        ;;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  condrestart)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        [ -e $lockfile ] &amp;amp;&amp;amp; restart&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        RETVAL=$?&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        ;;       &lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  reload)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        reload&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        ;;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  status)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        status $prog&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        RETVAL=$?&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        ;;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;   \*)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        echo $&amp;quot;Usage: $0 &amp;#123;start|stop|restart|condrestart|status&amp;#125;&amp;quot;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        RETVAL=1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;esac&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;exit $RETVAL&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

使用如下命令配置memcached成为系统服务：
&lt;pre&gt;&lt;code&gt;
# chmod +x /etc/init.d/memcached
# chkconfig --add memcached
# service memcached start
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;使用telnet命令测试memcached的使用&lt;br&gt;Memcached提供一组基本命令用于基于命令行调用其服务或查看服务器状态等。&lt;br&gt;&lt;code&gt;telnet 127.0.0.1 11211&lt;/code&gt;  &lt;blockquote&gt;
&lt;p&gt;add命令：&lt;br&gt;add keyname flag  timeout  datasize&lt;br&gt;如：&lt;br&gt;add mykey 0 10 12&lt;br&gt;Hello world!&lt;br&gt;get命令：&lt;br&gt;get keyname&lt;br&gt;如：get mykey&lt;br&gt;VALUE mykey 0 12&lt;br&gt;Hello world!&lt;br&gt;END  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;4.memcached的常用选项说明&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
-l &lt;ip_addr&gt;：指定进程监听的地址；
-d: 以服务模式运行；
-u &lt;username&gt;：以指定的用户身份运行memcached进程；
-m &lt;num&gt;：用于缓存数据的最大内存空间，单位为MB，默认为64MB；
-c &lt;num&gt;：最大支持的并发连接数，默认为1024；
-p &lt;num&gt;: 指定监听的TCP端口，默认为11211；
-U &lt;num&gt;：指定监听的UDP端口，默认为11211，0表示关闭UDP端口；
-t &lt;threads&gt;：用于处理入站请求的最大线程数，仅在memcached编译时开启了支持线程才有效；
-f &lt;num&gt;：设定Slab Allocator定义预先分配内存空间大小固定的块时使用的增长因子；
-M：当内存空间不够使用时返回错误信息，而不是按LRU算法利用空间；
-n: 指定最小的slab chunk大小；单位是字节；
-S: 启用sasl进行用户认证；
&lt;/num&gt;&lt;/threads&gt;&lt;/num&gt;&lt;/num&gt;&lt;/num&gt;&lt;/num&gt;&lt;/username&gt;&lt;/ip_addr&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;三、安装Memcache的PHP扩展&lt;/p&gt;
&lt;p&gt;①安装PHP的memcache扩展&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
# tar xf memcache-2.2.5.tgz
# cd memcache-2.2.5
/usr/local/php/bin/phpize
# ./configure --with-php-config=/usr/local/php/bin/php-config --enable-memcache
# make &amp;&amp; make install
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上述安装完后会有类似以下的提示：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Installing shared extensions:     /usr/local/php/lib/php/extensions/no-debug-non-zts-20090626/  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;②编辑/usr/local/php/lib/php.ini，在“动态模块”相关的位置添加如下一行来载入memcache扩展：&lt;br&gt;extension=/usr/local/php/lib/php/extensions/no-debug-non-zts-20090626/memcache.so&lt;br&gt;而后对memcached功能进行测试，在网站目录中建立测试页面test.php，添加如下内容：  &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
&lt;?php
$mem = new Memcache;
$mem-&gt;connect(&quot;127.0.0.1&quot;, 11211)  or die(&quot;Could not connect&quot;);
$version = $mem-&gt;getVersion();
echo &quot;Server&#39;s version: &quot;.$version.&quot;&lt;br&gt;\n&quot;;
$mem-&gt;set(&#39;testkey&#39;, &#39;Hello World&#39;, 0, 600) or die(&quot;Failed to save data at the memcached server&quot;);
echo &quot;Store data in the cache (data will expire in 600 seconds)&lt;br&gt;\n&quot;;
$get_result = $mem-&gt;get(&#39;testkey&#39;);
echo &quot;$get_result is from memcached server.&quot;;         
?&gt;
&lt;/code&gt;&lt;/pre&gt;  

&lt;p&gt;如果有输出”Hello World is from memcached”&lt;br&gt;等信息，则表明memcache已经能够正常工作&lt;/p&gt;
&lt;p&gt;四. 使用libmemcached的客户端工具:&lt;/p&gt;
&lt;p&gt;访问memcached的传统方法是使用基于perl语言开发的Cache::memcached模块，这个模块在大多数perl代码中都能良好的工作，但也有着众所周知的性能方面的问题。libMemcached则是基于C语言开发的开源的C/C++代码访问memcached的库文件，同时，它还提供了数个可以远程使用的memcached管理工具，如memcat, memping，memstat，memslap等。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;编译安装libmemcached&lt;pre&gt;&lt;code&gt;
# tar xf libmemcached-1.0.2.tar.gz
# cd libmemcached-1.0.2
# ./configure
# make &amp;&amp; make install
# ldconfig
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;客户端工具&lt;pre&gt;&lt;code&gt;
# memcat --servers=127.0.0.1:11211 mykey
# memping
# memslap
# memstat
&lt;/code&gt;&lt;/pre&gt;

&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;五. Nginx整合memcached:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
server {
        listen       80;
        server_name  www.magedu.com;
        #charset koi8-r;
        #access_log  logs/host.access.log  main;
        location / {
                set $memcached_key $uri;
                memcached_pass     127.0.0.1:11211;
                default_type       text/html;
                error_page         404 @fallback;
        }
        location @fallback {
                proxy_pass http://172.16.0.1;
        }
}
&lt;/code&gt;&lt;/pre&gt;
</content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;&lt;p&gt;Memcached是一款开源、高性能、分布式内存对象缓存系统，可应用各种需要缓存的场景，其主要目的是通过降低对Database的访问来加速web应用程序。它是一个基于内存的“键值对”存储，用于存储数据库调用、API调用或页面引用结果的直接数据，如字符串、对象等。&lt;/p&gt;
    
    </summary>
    
      <category term="缓存" scheme="https://iceziyao.github.io/categories/%E7%BC%93%E5%AD%98/"/>
    
    
      <category term="缓存" scheme="https://iceziyao.github.io/tags/%E7%BC%93%E5%AD%98/"/>
    
  </entry>
  
  <entry>
    <title>PHP编译出错</title>
    <link href="https://iceziyao.github.io/2016/01/01/lnmp/php/"/>
    <id>https://iceziyao.github.io/2016/01/01/lnmp/php/</id>
    <published>2015-12-31T16:00:00.000Z</published>
    <updated>2016-08-06T14:50:20.161Z</updated>
    
    <content type="html">&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;pre&gt;&lt;code&gt;
   /libxmlrpc/encoding.c:101:undefined reference to &#39;libiconv_close&#39;
   　　collect2: ld returned 1 exit status
   　　make:*** [sapi/fpm/php-fpm] Error 1
   　　解决方法：
   　　#make ZEND_EXTRA_LIBS=&#39;-liconv&#39;
   　　错误一、编译php出错
   　　/php-5.3.2/ext/fileinfo/libmagic/apprentice.c:147:internal compiler
   error:Segmentation fault
   　　Please submit a full bug report,
   　　with preprocessed source if appropriate.
   　　See &lt;url:http: bugzilla.redhat.com=&quot;&quot; bugzilla=&quot;&quot;&gt; for instructions.
   　　The bug is not reproducible,so it is likely a hardware or OS problem.
   　　make:*** [ext/fileinfo/libmagic/apprentice.lo] Error 1
   　　解决方法：内存大于1G即可，这是php5.3.2的一个bug
    或者在./configure加上选项:--disable-fileinfo
    　　--------------------------------------------------------------------
    　　错误二、重新构造configure文件出错
    　　./buildconf --force
    　　Forcing buildconf
    　　buildconf:checking installation…
    　　buildconf:autoconf version 2.59 （ok）
    　　buildconf:Your version of autoconf likely contains buggy cache code.
    　　Running vcsclean for you.
    　　To avoid this,install autoconf-2.13.
    　　Can&#39;t figure out your VCS, not cleaning.
    　　解决方法：编译安装autoconf-2.13
    　　再将autoconf-2.13的auotconf文件至/usr/local/autoconf
    　　--------------------------------------------------------------------
    　　错误三、编译时缺少库
    　　configure: error: libXpm.（a|so） not found.
    　　解决方法：yum install libXpm-devel
    　　--------------------------------------------------------------------
    　　错误四、编译时缺少gmp.h文件
    　　configure: error: Unable to locate gmp.h
    　　解决方法：yum install gmp-devel
    　　--------------------------------------------------------------------
    　　错误五
    　　Configure: error: xml2-config not found. Please check your libxml2
    installation.
    　　解决方法：
    　　#yum install libxml2 libxml2-devel （For Redhat &amp; Fedora）
    　　# aptitude install libxml2-dev      （For ubuntu）
    　　--------------------------------------------------------------------
    　　错误六
    　　Checking for pkg-config… /usr/bin/pkg-config
    　　configure: error: Cannot find OpenSSL’s &lt;evp.h&gt;
    　　解决方法：
    　　#yum install openssl openssl-devel
    　　--------------------------------------------------------------------
    　　错误七
    　　Configure: error: Please reinstall the BZip2 distribution
    　　解决方法：
    　　# yum install bzip2 bzip2-devel
    　　--------------------------------------------------------------------
    　　错误八
    　　Configure: error: Please reinstall the libcurl distribution -
    　　easy.h should be in &lt;curl-dir&gt;/include/curl/
    　　解决方法：
    　　# yum install curl curl-devel   （For Redhat &amp; Fedora）
    　　# install libcurl4-gnutls-dev    （For Ubuntu）
    　　--------------------------------------------------------------------
    　　错误九：
    　　Configure: error: libjpeg.（also） not found.
    　　解决方法：
    　　# yum install libjpeg libjpeg-devel
    　　--------------------------------------------------------------------
    　　错误十
    　　Configure: error: libpng.（also） not found.
    　　--------------------------------------------------------------------
    　　解决方法：
    　　# yum install libpng libpng-devel
    　　--------------------------------------------------------------------
    　　错误十一
    　　Configure: error: freetype.h not found.
    　　解决方法：
    　　#yum install freetype-devel
    　　--------------------------------------------------------------------
    　　错误十二
    　　Configure: error: Unable to locate gmp.h
    　　解决方法：
    　　# yum install gmp-devel
    　　--------------------------------------------------------------------
    　　错误十三
    　　Configure: error: Cannot find MySQL header files under /usr.
    　　Note that the MySQL client library is not bundled anymore!
    　　解决方法：
    　　# yum install mysql-devel            （For Redhat &amp; Fedora）
    　　# apt-get install libmysql++-dev      （For Ubuntu）
    　　--------------------------------------------------------------------
    　　错误十四
    　　Configure: error: Please reinstall the ncurses distribution
    　　解决方法：
    　　# yum install ncurses ncurses-devel
    　　--------------------------------------------------------------------
    　　错误十五
    　　Checking for unixODBC support… configure: error: ODBC header file ‘
    /usr/include/sqlext.h’ not found!
    　　解决方法：
    　　# yum install unixODBC-devel
    　　--------------------------------------------------------------------
    　　错误十六
    　　Configure: error: Cannot find pspell
    　　解决方法：
    　　# yum install pspell-devel
    　　--------------------------------------------------------------------
    　　错误十七
    　　configure: error: mcrypt.h not found. Please reinstall libmcrypt.
    　　解决方法：
    　　# yum install libmcrypt libmcrypt-devel    （For Redhat &amp; Fedora）
    　　# apt-get install libmcrypt-dev
    　　--------------------------------------------------------------------
    　　错误十八
    　　Configure: error: snmp.h not found. Check your SNMP installation.
    　　解决方法：
    　　# yum install net-snmp net-snmp-devel
    　　--------------------------------------------------------------------
    　　错误十九
    　　configure:error:Cannot find ldap.h
    　　解决方法：
    　　#yum install openldap-devel openldap
    　　错误二十
    　　configure:error:xslt-config not found. Please reinstall the libxslt
    &gt;= 1.1.0 distribution
    　　解决方法：
    　　#yum install libxslt libxslt-devel
    　　错误二十一
    　　checking for libevent &gt;=1.4.11 install prefix… configure: error:
    Could not find libevent &gt;=1.4.11 in /usr/local/php
    　　解决方法：
    　　安装libevent-1.4.11以上版本至/usr/local
    　　tar xzvf libevent-1.4.14-stable.tar.gz
    　　cd libevent-1.4.14-stable
    　　./configure --prefix=/usr/local
    　　make&amp;&amp;make install
    　　在编译。/configure时添加--with-libevent-dir=/usr/local即可
    　　错误二十二
    　　cc1: out of memory allocating 2036 bytes after a total of 81846272
    bytes
    　　make: *** [ext/date/lib/parse_date.lo] Error 1
    　　报错：
    　　/usr/bin/ld: cannot find -lltdl
    　　collect2: ld returned 1 exit status
    　　make:*** [sapi/fpm/php-fpm] Error 1
    　　解决方法：
    　　安装ltdl
    　　#cd /libmcrypt-2.5.7/libltdl/
    　　#./configure --enable-ltdl-install
    　　#ldconfig
    　　#cd php-5.3.6
    　　#make ZEND_EXTRA_LIBS=&#39;-liconv&#39;
&lt;/curl-dir&gt;&lt;/evp.h&gt;&lt;/url:http:&gt;&lt;/code&gt;&lt;/pre&gt;
</content>
    
    <summary type="html">
    
      &lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;pre&gt;&lt;code&gt;
   /libxmlrpc/encoding.c:101:undefined reference to &#39;libiconv_close&#39;
   　　collect2: ld returned 1 exit status

    
    </summary>
    
      <category term="lnmp" scheme="https://iceziyao.github.io/categories/lnmp/"/>
    
    
      <category term="php" scheme="https://iceziyao.github.io/tags/php/"/>
    
  </entry>
  
  <entry>
    <title>TCP连接的建立与中止</title>
    <link href="https://iceziyao.github.io/2016/01/01/Net/Tcp11/"/>
    <id>https://iceziyao.github.io/2016/01/01/Net/Tcp11/</id>
    <published>2015-12-31T16:00:00.000Z</published>
    <updated>2016-08-06T14:49:58.509Z</updated>
    
    <content type="html">&lt;h2 id=&quot;TCP协议&quot;&gt;&lt;a href=&quot;#TCP协议&quot; class=&quot;headerlink&quot; title=&quot;TCP协议&quot;&gt;&lt;/a&gt;TCP协议&lt;/h2&gt;&lt;p&gt;TCP是一个面向连接的协议，所以在连接双方发送数据之前，都需要首先建立一条连接。这和前面讲到的协议完全不同。前面讲的所有协议都只是发送数据而已，大多数都不关心发送的数据是不是送到，UDP尤其明显，从编程的角度来说，UDP编程也要简单的多，UDP都不用考虑数据分片。&lt;br&gt;TCP/IP协议详解一书中用telnet登陆退出来解释TCP协议连接的建立和中止的过程，可以看到，TCP连接的建立可以简单的称为三次握手，而连接的中止则可以叫做四次握手。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;连接&quot;&gt;&lt;a href=&quot;#连接&quot; class=&quot;headerlink&quot; title=&quot;连接&quot;&gt;&lt;/a&gt;连接&lt;/h1&gt;&lt;h2 id=&quot;连接的建立&quot;&gt;&lt;a href=&quot;#连接的建立&quot; class=&quot;headerlink&quot; title=&quot;连接的建立&quot;&gt;&lt;/a&gt;连接的建立&lt;/h2&gt;&lt;h3 id=&quot;三次握手&quot;&gt;&lt;a href=&quot;#三次握手&quot; class=&quot;headerlink&quot; title=&quot;三次握手&quot;&gt;&lt;/a&gt;三次握手&lt;/h3&gt;&lt;p&gt;所谓三次握手（Three-Way Handshake）即建立TCP连接，就是指建立一个TCP连接时，需要客户端和服务端总共发送3个包以确认连接的建立。在socket编程中，这一过程由客户端执行connect来触发&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;TCP三次握手&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;客户端的TCP进程也首先创建传输控制模块TCB，然后向服务端发出连接请求报文段，该报文段首部中的SYN=1，ACK=0，同时选择一个初始序号 seq=i。TCP规定，SYN=1的报文段不能携带数据，但要消耗掉一个序号。这时，TCP客户进程进入SYN—SENT（同步已发送）状态，这是 TCP连接的第一次握手。&lt;/li&gt;
&lt;li&gt;服务端收到客户端发来的请求报文后，如果同意建立连接，则向客户端发送确认。确认报文中的SYN=1，ACK=1，确认号ack=i+1，同时为自己 选择一个初始序号seq=j。同样该报文段也是SYN=1的报文段，不能携带数据，但同样要消耗掉一个序号。这时，TCP服务端进入SYN—RCVD（同 步收到）状态，这是TCP连接的第二次握手。&lt;/li&gt;
&lt;li&gt;TCP客户端进程收到服务端进程的确认后，还要向服务端给出确认。确认报文段的ACK=1，确认号ack=j+1，而自己的序号为seq=i+1。 TCP的标准规定，ACK报文段可以携带数据，但如果不携带数据则不消耗序号，因此，如果不携带数据，则下一个报文段的序号仍为seq=i+1。这 时，TCP连接已经建立，客户端进入ESTABLISHED（已建立连接）状态。这是TCP连接的第三次握手，可以看出第三次握手客户端已经可以发送携带 数据的报文段了。&lt;br&gt;当服务端收到确认后，也进入ESTABLISHED（已建立连接）状态。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;为什么要三次握手&lt;br&gt;目的是为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;已失效的连接请求报文段&lt;/strong&gt; 的产生在这样一种情况下：   &lt;blockquote&gt;
&lt;p&gt;client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。本来这是一个早已失效的报文段。但server收到此失效的连接请求报文段后，就误认为是client再次发出的一个新的连接请求。于是就向client发出确认报文段，同意建立连接。若不采用“三次握手”，那么只要server发出确认，新的连接就建立了。由于现在client并没有发出建立连接的请求，因此不会理睬server的确认，也不会向server发送数据。但server却以为新的运输连接已经建立，并一直等待client发来数据。这样，server的很多资源就白白浪费掉了。采用“三次握手”的办法可以防止上述现象发生。例如刚才那种情况，client不会向server的确认发出确认。server由于收不到确认，就知道client并没有要求建立连接。&lt;br&gt;.&lt;br&gt;三次握手是双方建立连接认证的最小保证。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;TCP三次握手失败&lt;br&gt;我们总是要考虑网络是不可靠的。所以三次握手是存在失败的概率的。&lt;ul&gt;
&lt;li&gt;如果server端接到了clien发的SYN后回了SYN-ACK后，之后server没有收到clien发送的ACK，会怎么样？  &lt;blockquote&gt;
&lt;p&gt;此时server端处于SYN—RCVD,根据TCP的重发机制，在server发送SYN-ACK后，会启动一个重传定时器，当在指定时间内没有收到客户端发来的ACK报文时，就会重新发送SYN-ACK报文，并重置记时器。当然，这也不是无休止的，在Linux下，默认重试次数为5次，重试的间隔时间从1s开始每次都翻售，5次的重试时间间隔为1s, 2s, 4s, 8s, 16s，总共31s，第5次发出后还要等32s都知道第5次也超时了。Server重发SYN+ACK包的次数，可以通过设置/proc/sys/net/ipv4/tcp_synack_retries修改，默认值为5。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;那么client端会怎么样呢？&lt;blockquote&gt;
&lt;p&gt;客户端认为连接建立，写数据时，会触发RST&lt;br&gt;如果重发指定次数后，仍然未收到ACK应答，那么一段时间后，Server自动关闭这个连接。&lt;br&gt;但是Client认为这个连接已经建立，如果Client端向Server写数据，Server端将以RST包响应，方能感知到Server的错误。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;SYN攻击&lt;br&gt;当正常TCP连接开始时，目的地主机将收到源主机发出的SYN(synchronize/start)信息包，并发回同步应答(同步承认)。 连接建立之前，目的地主机必须监听SYN ACK的ACK（确认）。&lt;br&gt;等待同步应答（SYN ACK）的确认（ACK）时，目的地主机上的大小有限的连接队列将记录等待完成的连接。 因为ACK预计在同步应答后几毫秒内到达，此队列通常迅速倒空。&lt;br&gt;TCP SYN攻击利用了此设计，由攻击源主机（相对于受害主机）生成带有随机源地址的TCP同步信息包。 受害目的地主机发送同步应答回到随机源地址，并且在连接队列中添加新条目。 因为同步应答指定用于不正确或不存在的主机，因此“三方握手”的最后部件永远不会完成，并且条目保留在连接队列中，直到计时器到期，保留时间通常为一分钟。 从随机IP地址快速生成欺骗性TCP同步信息包，有可能填满连接队列，并拒绝合法用户请求的TCP服务。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;连接的中断&quot;&gt;&lt;a href=&quot;#连接的中断&quot; class=&quot;headerlink&quot; title=&quot;连接的中断&quot;&gt;&lt;/a&gt;连接的中断&lt;/h2&gt;&lt;h3 id=&quot;四次挥手&quot;&gt;&lt;a href=&quot;#四次挥手&quot; class=&quot;headerlink&quot; title=&quot;四次挥手&quot;&gt;&lt;/a&gt;四次挥手&lt;/h3&gt;&lt;p&gt;所谓四次挥手（Four-Way Wavehand）即终止TCP连接，就是指断开一个TCP连接时，需要客户端和服务端总共发送4个包以确认连接的断开。在socket编程中，这一过程由客户端或服务端任一方执行close来触发，&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;TCP四次挥手&lt;br&gt;由于TCP连接时全双工的，因此，每个方向都必须要单独进行关闭，这一原则是当一方完成数据发送任务后，发送一个FIN来终止这一方向的连接，收到一个FIN只是意味着这一方向上没有数据流动了，即不会再收到数据了，但是在这个TCP连接上仍然能够发送数据，直到这一方向也发送了FIN。首先进行关闭的一方将执行主动关闭，而另一方则执行被动关闭，上图描述的即是如此。&lt;ul&gt;
&lt;li&gt;第一次挥手：Client发送一个FIN，用来关闭Client到Server的数据传送，Client进入FIN_WAIT_1状态。&lt;/li&gt;
&lt;li&gt;第二次挥手：Server收到FIN后，发送一个ACK给Client，确认序号为收到序号+1（与SYN相同，一个FIN占用一个序号），Server进入CLOSE_WAIT状态。&lt;/li&gt;
&lt;li&gt;第三次挥手：Server发送一个FIN，用来关闭Server到Client的数据传送，Server进入LAST_ACK状态。&lt;/li&gt;
&lt;li&gt;第四次挥手：Client收到FIN后，Client进入TIME_WAIT状态，接着发送一个ACK给Server，确认序号为收到序号+1，Server进入CLOSED状态，完成四次挥手。&lt;br&gt;其实四次挥手只是两次挥手的叠交，一方为被动关闭。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;为什么要四次挥手&quot;&gt;&lt;a href=&quot;#为什么要四次挥手&quot; class=&quot;headerlink&quot; title=&quot;为什么要四次挥手&quot;&gt;&lt;/a&gt;为什么要四次挥手&lt;/h3&gt;&lt;p&gt;TCP协议是一种面向连接的、可靠的、基于字节流的运输层通信协议。TCP是全双工模式，这就意味着，当client发出FIN报文段时，只是表示client已经没有数据要发送了，client告诉server，数据传输完毕；但是server还有数据要穿，所以client还要继续接受server的数据；当server返回ACK报文段时，表示它已经知道client没有数据发送了，但是server还是可以发送数据到client的；当server也发送了FIN报文段时，这个时候就表示server也没有数据要发送了，就会告诉client，我也没有数据要发送了，之后彼此就会愉快的中断这次TCP连接。如果要正确的理解四次分手的原理，就需要了解四次分手过程中的状态变化。  &lt;/p&gt;
&lt;h3 id=&quot;四次挥手的状态&quot;&gt;&lt;a href=&quot;#四次挥手的状态&quot; class=&quot;headerlink&quot; title=&quot;四次挥手的状态&quot;&gt;&lt;/a&gt;四次挥手的状态&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;FIN_WAIT_1: 这个状态要好好解释一下，其实FIN_WAIT_1和FIN_WAIT_2状态的真正含义都是表示等待对方的FIN报文。而这两种状态的区别是：FIN_WAIT_1状态实际上是当SOCKET在ESTABLISHED状态时，它想主动关闭连接，向对方发送了FIN报文，此时该SOCKET即进入到FIN_WAIT_1状态。而当对方回应ACK报文后，则进入到FIN_WAIT_2状态，当然在实际的正常情况下，无论对方何种情况下，都应该马上回应ACK报文，所以FIN_WAIT_1状态一般是比较难见到的，而FIN_WAIT_2状态还有时常常可以用netstat看到。（主动方）&lt;/li&gt;
&lt;li&gt;FIN_WAIT_2：上面已经详细解释了这种状态，实际上FIN_WAIT_2状态下的SOCKET，表示半连接，也即有一方要求close连接，但另外还告诉对方，我暂时还有点数据需要传送给你(ACK信息)，稍后再关闭连接。（主动方）&lt;/li&gt;
&lt;li&gt;CLOSE_WAIT：这种状态的含义其实是表示在等待关闭。怎么理解呢？当对方close一个SOCKET后发送FIN报文给自己，你系统毫无疑问地会回应一个ACK报文给对方，此时则进入到CLOSE_WAIT状态。接下来呢，实际上你真正需要考虑的事情是察看你是否还有数据发送给对方，如果没有的话，那么你也就可以 close这个SOCKET，发送FIN报文给对方，也即关闭连接。所以你在CLOSE_WAIT状态下，需要完成的事情是等待你去关闭连接。（被动方）&lt;/li&gt;
&lt;li&gt;LAST_ACK: 这个状态还是比较容易好理解的，它是被动关闭一方在发送FIN报文后，最后等待对方的ACK报文。当收到ACK报文后，也即可以进入到CLOSED可用状态了。（被动方）&lt;/li&gt;
&lt;li&gt;TIME_WAIT: 表示收到了对方的FIN报文，并发送出了ACK报文，就等2MSL后即可回到CLOSED可用状态了。如果FINWAIT1状态下，收到了对方同时带FIN标志和ACK标志的报文时，可以直接进入到TIME_WAIT状态，而无须经过FIN_WAIT_2状态。（主动方）&lt;br&gt;注：&lt;br&gt;为什么TIME_WAIT状态需要经过2MSL(最大报文段生存时间)才能返回到CLOSE状态？&lt;br&gt;答：虽然按道理，四个报文都发送完毕，我们可以直接进入CLOSE状态了，但是我们必须假象网络是不可靠的，有可以最后一个ACK丢失。所以TIME_WAIT状态就是用来重发可能丢失的ACK报文。&lt;br&gt;如果目前连接的通信双方都已经调用了close()，假定双方都到达CLOSED状态，而没有TIME_WAIT状态时，就会出现如下的情况。现在有一个新的连接被建立起来，使用的IP地址与端口与先前的完全相同，后建立的连接又称作是原先连接的一个化身。还假定原先的连接中有数据报残存于网络之中，这样新的连接收到的数据报中有可能是先前连接的数据报。为了防止这一点，TCP不允许从处于TIME_WAIT状态的socket建立一个连接。处于TIME_WAIT状态的socket在等待两倍的MSL时间以后（之所以是两倍的MSL，是由于MSL是一个数据报在网络中单向发出到认定丢失的时间，一个数据报有可能在发送图中或是其响应过程中成为残余数据报，确认一个数据报及其响应的丢弃的需要两倍的MSL），将会转变为CLOSED状态。这就意味着，一个成功建立的连接，必然使得先前网络中残余的数据报都丢失了。&lt;/li&gt;
&lt;/ul&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;TCP协议&quot;&gt;&lt;a href=&quot;#TCP协议&quot; class=&quot;headerlink&quot; title=&quot;TCP协议&quot;&gt;&lt;/a&gt;TCP协议&lt;/h2&gt;&lt;p&gt;TCP是一个面向连接的协议，所以在连接双方发送数据之前，都需要首先建立一条连接。这和前面讲到的协议完全不同。前面讲的所有协议都只是发送数据而已，大多数都不关心发送的数据是不是送到，UDP尤其明显，从编程的角度来说，UDP编程也要简单的多，UDP都不用考虑数据分片。&lt;br&gt;TCP/IP协议详解一书中用telnet登陆退出来解释TCP协议连接的建立和中止的过程，可以看到，TCP连接的建立可以简单的称为三次握手，而连接的中止则可以叫做四次握手。&lt;br&gt;
    
    </summary>
    
      <category term="网络" scheme="https://iceziyao.github.io/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="tcp" scheme="https://iceziyao.github.io/tags/tcp/"/>
    
  </entry>
  
  <entry>
    <title>Tcp协议概述</title>
    <link href="https://iceziyao.github.io/2015/12/25/Net/tcp10/"/>
    <id>https://iceziyao.github.io/2015/12/25/Net/tcp10/</id>
    <published>2015-12-24T16:00:00.000Z</published>
    <updated>2016-08-06T14:49:54.535Z</updated>
    
    <content type="html">&lt;h4 id=&quot;tcp协议族位于传输层&quot;&gt;&lt;a href=&quot;#tcp协议族位于传输层&quot; class=&quot;headerlink&quot; title=&quot;tcp协议族位于传输层&quot;&gt;&lt;/a&gt;tcp协议族位于传输层&lt;/h4&gt;&lt;h2 id=&quot;tcp报文格式&quot;&gt;&lt;a href=&quot;#tcp报文格式&quot; class=&quot;headerlink&quot; title=&quot;tcp报文格式&quot;&gt;&lt;/a&gt;tcp报文格式&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;TCP是一种可靠的、面向连接的字节流服务。源主机在传送数据前需要先和目标主机建立连接。然后，在此连接上，被编号的数据段按序收发。同时，要求对每个数据段进行确认，保证了可靠性。如果在指定的时间内没有收到目标主机对所发数据段的确认，源主机将再次发送该数据段.  &lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/upload/tcp.jpg&quot; alt=&quot;tcp&quot;&gt;  &lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;源、目标端口号字段：占16比特。TCP协议通过使用”端口”来标识源端和目标端的应用进程。端口号可以使用0到65535之间的任何数字。在收到服务请求时，操作系统动态地为客户端的应用程序分配端口号。在服务器端，每种服务在”众所周知的端口”（Well-Know Port）为用户提供服务。  &lt;/li&gt;
&lt;li&gt;顺序号字段：占32比特。用来标识从TCP源端向TCP目标端发送的数据字节流，它表示在这个报文段中的第一个数据字节。  &lt;/li&gt;
&lt;li&gt;确认号字段：占32比特。只有ACK标志为1时，确认号字段才有效。它包含目标端所期望收到源端的下一个数据字节  &lt;/li&gt;
&lt;li&gt;头部长度字段：占4比特。给出头部占32比特的数目。没有任何选项字段的TCP头部长度为20字节；最多可以有60字节的TCP头部。&lt;/li&gt;
&lt;li&gt;标志位字段（U、A、P、R、S、F）：占6比特。各比特的含义如下   &lt;ul&gt;
&lt;li&gt;URG：紧急指针（urgent pointer）有效  &lt;/li&gt;
&lt;li&gt;ACK：确认序号有效  &lt;/li&gt;
&lt;li&gt;PSH：接收方应该尽快将这个报文段交给应用层  &lt;/li&gt;
&lt;li&gt;RST：重建连接  &lt;/li&gt;
&lt;li&gt;SYN：发起一个连接  &lt;/li&gt;
&lt;li&gt;FIN：释放一个连接  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;窗口大小字段：占16比特。此字段用来进行流量控制。单位为字节数，这个值是本机期望一次接收的字节数  &lt;/li&gt;
&lt;li&gt;TCP校验和字段：占16比特。对整个TCP报文段，即TCP头部和TCP数据进行校验和计算，并由目标端进行验证  &lt;/li&gt;
&lt;li&gt;紧急指针字段：占16比特。它是一个偏移量，和序号字段中的值相加表示紧急数据最后一个字节的序号  &lt;/li&gt;
&lt;li&gt;选项字段：占32比特。可能包括”窗口扩大因子”、”时间戳”等选项。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;TCP传输&quot;&gt;&lt;a href=&quot;#TCP传输&quot; class=&quot;headerlink&quot; title=&quot;TCP传输&quot;&gt;&lt;/a&gt;TCP传输&lt;/h2&gt;&lt;p&gt;TCP和UDP处在同一层—运输层，但是TCP和UDP最不同的地方是，TCP提供了一种可靠的数据传输服务，TCP是面向连接的，也就是说，利用TCP通信的两台主机首先要经历一个“拨打电话”的过程，等到通信准备结束才开始传输数据，最后结束通话。所以TCP要比UDP可靠的多，UDP是把数据直接发出去，而不管对方是不是在收信，就算是UDP无法送达，也不会产生ICMP差错报文&lt;/p&gt;
&lt;h3 id=&quot;TCP保证可靠性的简单工作原理&quot;&gt;&lt;a href=&quot;#TCP保证可靠性的简单工作原理&quot; class=&quot;headerlink&quot; title=&quot;TCP保证可靠性的简单工作原理&quot;&gt;&lt;/a&gt;TCP保证可靠性的简单工作原理&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;应用数据被分割成TCP认为最适合发送的数据块。这和UDP完全不同，应用程序产生的 数据报长度将保持不变。由TCP传递给IP的信息单位称为报文段或段&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;当TCP发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能 及时收到一个确认，将重发这个报文段。在第21章我们将了解TCP协议中自适应的超时 及重传策略。&lt;/li&gt;
&lt;li&gt;当TCP收到发自TCP连接另一端的数据，它将发送一个确认。这个确认不是立即发送，通常将推迟几分之一秒，这将在1 9.3节讨论。&lt;/li&gt;
&lt;li&gt;TCP将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输 过程中的任何变化。如果收到段的检验和有差错， T P将丢弃这个报文段和不确认收到此报文段（希望发端超时并重发）。&lt;/li&gt;
&lt;li&gt;既然TCP报文段作为IP数据报来传输，而IP数据报的到达可能会失序，因此TCP报文段 的到达也可能会失序。如果必要， TCP将对收到的数据进行重新排序，将收到的数据以正确的顺序交给应用层。&lt;/li&gt;
&lt;li&gt;TCP还能提供流量控制。TCP连接的每一方都有固定大小的缓冲空间。TCP的接收端只允许另一端发送接收端缓冲区所能接纳的数据。这将防止较快主机致使较慢主机的缓冲区溢出。  &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;从这段话中可以看到，TCP中保持可靠性的方式就是&lt;strong&gt;超时重发&lt;/strong&gt;，虽然TCP也可以用各种各样的ICMP报文来处理这些，但是这也不是可靠的，最可靠的方式就是只要不得到确认，就重新发送数据报，直到得到对方的确认为止。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;连接&quot;&gt;&lt;a href=&quot;#连接&quot; class=&quot;headerlink&quot; title=&quot;连接&quot;&gt;&lt;/a&gt;连接&lt;/h3&gt;&lt;p&gt;TCP的首部和UDP首部一样，都有发送端口号和接收端口号。但是显然，TCP的首部信息要比UDP的多，可以看到，TCP协议提供了发送和确认所需要的所有必要的信息。这在P171-173有详细地介绍。可以想象一个TCP数据的发送应该是如下的一个过程。&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;双方建立连接&lt;ul&gt;
&lt;li&gt;发送方给接受方TCP数据报，然后等待对方的确认TCP数据报，如果没有，就重新发，如果有，就发送下一个数据报。&lt;/li&gt;
&lt;li&gt;接受方等待发送方的数据报，如果得到数据报并检验无误，就发送ACK(确认)数据报，并等待下一个TCP数据报的到来。直到接收到FIN(发送完成数据报)&lt;/li&gt;
&lt;li&gt;中止连接&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;可以想见，为了建立一个TCP连接，系统可能会建立一个新的进程（最差也是一个线程），来进行数据的传送&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;tcp协议族位于传输层&quot;&gt;&lt;a href=&quot;#tcp协议族位于传输层&quot; class=&quot;headerlink&quot; title=&quot;tcp协议族位于传输层&quot;&gt;&lt;/a&gt;tcp协议族位于传输层&lt;/h4&gt;&lt;h2 id=&quot;tcp报文格式&quot;&gt;&lt;a href=&quot;#tcp报文格式&quot; class=&quot;headerlink&quot; title=&quot;tcp报文格式&quot;&gt;&lt;/a&gt;tcp报文格式&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;TCP是一种可靠的、面向连接的字节流服务。源主机在传送数据前需要先和目标主机建立连接。然后，在此连接上，被编号的数据段按序收发。同时，要求对每个数据段进行确认，保证了可靠性。如果在指定的时间内没有收到目标主机对所发数据段的确认，源主机将再次发送该数据段.
    
    </summary>
    
      <category term="网络" scheme="https://iceziyao.github.io/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="tcp" scheme="https://iceziyao.github.io/tags/tcp/"/>
    
  </entry>
  
  <entry>
    <title>nginx配置文件详解</title>
    <link href="https://iceziyao.github.io/2015/12/23/lnmp/nginx%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/"/>
    <id>https://iceziyao.github.io/2015/12/23/lnmp/nginx配置文件详解/</id>
    <published>2015-12-23T13:49:33.000Z</published>
    <updated>2016-08-06T14:50:16.766Z</updated>
    
    <content type="html">&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;pre&gt;&lt;code&gt;


    #运行用户
    user nginx;   
    #启动进程,通常设置成和cpu的数量相等
    worker_processes  1;

    #全局错误日志及PID文件
    error_log  /var/log/nginx/error.log;
    pid        /var/run/nginx.pid;

    #工作模式及连接数上限
    events {
        use   epoll;             #epoll是多路复用IO(I/O Multiplexing)中的一种方式,但是仅用于linux2.6以上内核,可以大大提高nginx的性能
        worker_connections  1024;#单个后台worker process进程的最大并发链接数
        # multi_accept on;
    }

    #设定http服务器，利用它的反向代理功能提供负载均衡支持
    http {
         #设定mime类型,类型由mime.type文件定义
        include       /etc/nginx/mime.types;
        default_type  application/octet-stream;
        #设定日志格式
        access_log    /var/log/nginx/access.log;

        #sendfile 指令指定 nginx 是否调用 sendfile 函数（zero copy 方式）来输出文件，对于普通应用，
        #必须设为 on,如果用来进行下载等应用磁盘IO重负载应用，可设置为 off，以平衡磁盘与网络I/O处理速度，降低系统的uptime.
        sendfile        on;
        #tcp_nopush     on;

        #连接超时时间
        #keepalive_timeout  0;
        keepalive_timeout  65;
        tcp_nodelay        on;

        #开启gzip压缩
        gzip  on;
        gzip_disable &quot;MSIE [1-6]\.(?!.*SV1)&quot;;

        #设定请求缓冲
        client_header_buffer_size    1k;
        large_client_header_buffers  4 4k;

        include /etc/nginx/conf.d/*.conf;
        include /etc/nginx/sites-enabled/*;

        #设定负载均衡的服务器列表
         upstream mysvr {
        #weigth参数表示权值，权值越高被分配到的几率越大
        #本机上的Squid开启3128端口
        server 192.168.8.1:3128 weight=5;
        server 192.168.8.2:80  weight=1;
        server 192.168.8.3:80  weight=6;
        }


       server {
        #侦听80端口
            listen       80;
            #定义使用www.xx.com访问
            server_name  www.xx.com;

            #设定本虚拟主机的访问日志
            access_log  logs/www.xx.com.access.log  main;

        #默认请求
        location / {
              root   /root;      #定义服务器的默认网站根目录位置
              index index.php index.html index.htm;   #定义首页索引文件的名称

              fastcgi_pass  www.xx.com;
             fastcgi_param  SCRIPT_FILENAME  $document_root/$fastcgi_script_name;
              include /etc/nginx/fastcgi_params;
            }

        # 定义错误提示页面
        error_page   500 502 503 504 /50x.html;
            location = /50x.html {
            root   /root;
        }

        #静态文件，nginx自己处理
        location ~ ^/(images|javascript|js|css|flash|media|static)/ {
            root /var/www/virtual/htdocs;
            #过期30天，静态文件不怎么更新，过期可以设大一点，如果频繁更新，则可以设置得小一点。
            expires 30d;
        }
        #PHP 脚本请求全部转发到 FastCGI处理. 使用FastCGI默认配置.
        location ~ \.php$ {
            root /root;
            fastcgi_pass 127.0.0.1:9000;
            fastcgi_index index.php;
            fastcgi_param SCRIPT_FILENAME /home/www/www$fastcgi_script_name;
            include fastcgi_params;
        }
        #设定查看Nginx状态的地址
        location /NginxStatus {
            stub_status              on;
            access_log               on;
            auth_basic              &quot;NginxStatus&quot;;
            auth_basic_user_file  conf/htpasswd;
        }
        #禁止访问 .htxxx 文件
        location ~ /\.ht {
            deny all;
        }

         }
    }

以上是一些基本的配置,使用Nginx最大的好处就是负载均衡

如果要使用负载均衡的话,可以修改配置http节点如下：

    #设定http服务器，利用它的反向代理功能提供负载均衡支持
    http {
         #设定mime类型,类型由mime.type文件定义
        include       /etc/nginx/mime.types;
        default_type  application/octet-stream;
        #设定日志格式
        access_log    /var/log/nginx/access.log;

        #省略上文有的一些配置节点

        #。。。。。。。。。。

        #设定负载均衡的服务器列表
        upstream mysvr {
        #weigth参数表示权值，权值越高被分配到的几率越大
        server 192.168.8.1x:3128 weight=5;#本机上的Squid开启3128端口
        server 192.168.8.2x:80  weight=1;
        server 192.168.8.3x:80  weight=6;
        }

        upstream mysvr2 {
        #weigth参数表示权值，权值越高被分配到的几率越大

            server 192.168.8.x:80  weight=1;
            server 192.168.8.x:80  weight=6;
        }

       #第一个虚拟服务器
       server {
        #侦听192.168.8.x的80端口
            listen       80;
            server_name  192.168.8.x;

            #对aspx后缀的进行负载均衡请求
            location ~ .*\.aspx$ {

                root   /root;      #定义服务器的默认网站根目录位置
                index index.php index.html index.htm;   #定义首页索引文件的名称

                proxy_pass  http://mysvr ;#请求转向mysvr 定义的服务器列表

                #以下是一些反向代理的配置可删除.

                proxy_redirect off;

                #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP
                proxy_set_header Host $host;
                proxy_set_header X-Real-IP $remote_addr;
                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
                client_max_body_size 10m;       #允许客户端请求的最大单文件字节数
                client_body_buffer_size 128k;   #缓冲区代理缓冲用户端请求的最大字节数，
                proxy_connect_timeout 90;       #nginx跟后端服务器连接超时时间(代理连接超时)
                proxy_send_timeout 90;          #后端服务器数据回传时间(代理发送超时)
                proxy_read_timeout 90;          #连接成功后，后端服务器响应时间(代理接收超时)
                proxy_buffer_size 4k;           #设置代理服务器（nginx）保存用户头信息的缓冲区大小
                proxy_buffers 4 32k;            #proxy_buffers缓冲区，网页平均在32k以下的话，这样设置
                proxy_busy_buffers_size 64k;    #高负荷下缓冲大小（proxy_buffers*2）
                proxy_temp_file_write_size 64k; #设定缓存文件夹大小，大于这个值，将从upstream服务器传

           }

         }
    }

&lt;/code&gt;&lt;/pre&gt;
</content>
    
    <summary type="html">
    
      &lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;pre&gt;&lt;code&gt;


    #运行用户
    user nginx;   
    #启动进程,通常设置成和cpu的数量相等
    worker_processes  1;

    #全局错误日志及PID文件
    error_
    
    </summary>
    
      <category term="nginx" scheme="https://iceziyao.github.io/categories/nginx/"/>
    
    
      <category term="nginx" scheme="https://iceziyao.github.io/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>nginx负载均衡</title>
    <link href="https://iceziyao.github.io/2015/12/23/lnmp/nginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"/>
    <id>https://iceziyao.github.io/2015/12/23/lnmp/nginx负载均衡/</id>
    <published>2015-12-23T13:49:33.000Z</published>
    <updated>2016-08-06T14:50:07.903Z</updated>
    
    <content type="html">&lt;h3 id=&quot;安装nginx&quot;&gt;&lt;a href=&quot;#安装nginx&quot; class=&quot;headerlink&quot; title=&quot;安装nginx&quot;&gt;&lt;/a&gt;安装nginx&lt;/h3&gt;&lt;p&gt;请参考&lt;a href=&quot;http://www.yaolinux.cn/blog/lnmp%25E6%259E%25B6%25E6%259E%2584.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;lnmp架构&lt;/a&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;nginx 反向代理&lt;br&gt;nginx的负载均衡基于反向代理  &lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;1.1 正向代理  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt; 正向代理 是一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端必须要进行一些特别的设置才能使用正向代理。  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;1.2反向代理&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;反向代理正好相反，对于客户端而言它就像是原始服务器，并且客户端不需要进行任何特别的设置。客户端向反向代理的命名空间(name-space)中的内容发送普通请求，接着反向代理将判断向何处(原始服务器)转交请求，并将获得的内容返回给客户端，就像这些内容原本就是它自己的一样。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;区别:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;正向代理的典型用途是为在防火墙内的局域网客户端提供访问Internet的途径。正向代理还可以使用缓冲特性减少网络使用率。反向代理的典型用途是将防火墙后面的服务器提供给Internet用户访问。反向代理还可以为后端的多台服务器提供负载平衡，或为后端较慢的服务器提供缓冲服务。另外，反向代理还可以启用高级URL策略和管理技术，从而使处于不同web服务器系统的web页面同时存在于同一个URL空间下。&lt;br&gt;正向代理允许客户端通过它访问任意网站并且隐藏客户端自身，因此你必须采取安全措施以确保仅为经过授权的客户端提供服务。反向代理对外都是透明的，访问者并不知道自己访问的是一个代理。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;upstream&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;2.1 负载均衡算法&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;2.1.1 轮循&lt;br&gt;当weight不指定时，各服务器weight相同，&lt;br&gt;每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。  &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
upstream bakend {
server server1.example.com;
server server2.example.com;
}
&lt;/code&gt;&lt;/pre&gt;
2.1.2 weight    
指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。
如果后端服务器down掉，能自动剔除。
比如以下配置，则1.11服务器的访问量为1.10服务器的两倍。  
&lt;pre&gt;&lt;code&gt;
upstream bakend {
server server1.example.com weight=1;
server server2.example.com weight=2;
}
&lt;/code&gt;&lt;/pre&gt;
2.1.3 ip_hash        
每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session不能跨服务器的问题。  
&lt;pre&gt;&lt;code&gt;
upstream bakend {
ip_hash
server server1.example.com;
server server2.example.com;
}
&lt;/code&gt;&lt;/pre&gt;
2.1.4 fair  
按后端服务器的响应时间来分配请求，响应时间短的优先分配。  
&lt;pre&gt;&lt;code&gt;
upstream bakend {
server server1.example.com;
server server2.example.com;
fair;
}
&lt;/code&gt;&lt;/pre&gt;
2.1.5 url_hash  
按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存服务器时比较有效。
在upstream中加入hash语句，hash_method是使用的hash算法。  
&lt;pre&gt;&lt;code&gt;
upstream bakend {
server server1.example.com;
server server2.example.com;
hash $request_uri;
hash_method crc32;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;/blockquote&gt;
&lt;p&gt;2.2 参数&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;1.down 表示单前的server暂时不参与负载&lt;br&gt;2.weight 默认为1.weight越大，负载的权重就越大。&lt;br&gt;3.max_fails ：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream 模块定义的错误&lt;br&gt;4.fail_timeout:max_fails次失败后，暂停的时间。&lt;br&gt;5.backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。&lt;br&gt;nginx支持同时设置多组的负载均衡，用来给不用的server来使用。&lt;br&gt;client_body_in_file_only 设置为On 可以讲client post过来的数据记录到文件中用来做debug&lt;br&gt;client_body_temp_path 设置记录文件的目录 可以设置最多3层目录&lt;br&gt;location 对URL进行匹配.可以进行重定向或者进行新的代理 负载均衡  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;示例&lt;br&gt;3.1 网络拓扑&lt;br&gt;反向代理服务器 server1.example.com&lt;br&gt;后端服务器：&lt;br&gt;server2.example.com&lt;br&gt;server3.example.com&lt;br&gt;3.2 配置&lt;br&gt;3.2.1 server1&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
user nginx;
worker_processes 1;
events {
 use epoll;
 worker_connections  1024;
}
http {
 include       mime.types;
 default_type  application/octet-stream;
 sendfile        on;
 keepalive_timeout  65;
 upstream nginx.com{
        server server2.example.com:80;
        server server3.example.com:80;
 }  
 server {
     listen       80;
     server_name  localhost;
     location / {
         proxy_pass http://nginx.com;
     proxy_set_header  X-Real-IP  $remote_addr;
   }
 error_page   500 502 503 504  /50x.html;
 location = /50x.html {
         root   html;
 }  
}  
}  
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
</content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;安装nginx&quot;&gt;&lt;a href=&quot;#安装nginx&quot; class=&quot;headerlink&quot; title=&quot;安装nginx&quot;&gt;&lt;/a&gt;安装nginx&lt;/h3&gt;&lt;p&gt;请参考&lt;a href=&quot;http://www.yaolinux.cn/blog/lnmp%25E6%259E%25B6%25E6%259E%2584.html&quot;&gt;lnmp架构&lt;/a&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;nginx 反向代理&lt;br&gt;nginx的负载均衡基于反向代理
    
    </summary>
    
    
      <category term="nginx" scheme="https://iceziyao.github.io/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>多播和广播</title>
    <link href="https://iceziyao.github.io/2015/12/06/Net/tcp4/"/>
    <id>https://iceziyao.github.io/2015/12/06/Net/tcp4/</id>
    <published>2015-12-05T16:00:00.000Z</published>
    <updated>2016-08-06T14:49:49.006Z</updated>
    
    <content type="html">&lt;h3 id=&quot;单播-unicast&quot;&gt;&lt;a href=&quot;#单播-unicast&quot; class=&quot;headerlink&quot; title=&quot;单播(unicast)&quot;&gt;&lt;/a&gt;单播(unicast)&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;单播是说，对特定的主机进行数据传送。例如给某一个主机发送IP数据包。&lt;br&gt;这时候，数据链路层给出的数据头里面是非常具体的目的地址，对于以太网来 说，&lt;br&gt;就是网卡的MAC地址（不是FF-FF-FF-FF-FF-FF这样的地址）。&lt;br&gt;现在的具有路由功能的主机应该可以将单播数据定向转发，&lt;br&gt;而目的主机的网络接口则可以过滤掉和自己MAC地址不一致的数据。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h3 id=&quot;广播-unicast&quot;&gt;&lt;a href=&quot;#广播-unicast&quot; class=&quot;headerlink&quot; title=&quot;广播(unicast)&quot;&gt;&lt;/a&gt;广播(unicast)&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;广播是主机针对某一个网络上的所有主机发送数据包。这个网络可能是网络，可能是子网，还可能是所有的子网。如果是网络，例如A类网址的广播就是 netid.255.255.255，如果是子网，则是netid.netid.subnetid.255；如果是所有的子网（B类IP）则是则是 netid.netid.255.255。广播所用的MAC地址FF-FF-FF-FF-FF-FF。网络内所有的主机都会收到这个广播数据，网卡只要把 MAC地址为FF-FF-FF-FF-FF-FF的数据交给内核就可以了。一般说来ARP，或者路由协议RIP应该是以广播的形式播发的。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;多播-multicast&quot;&gt;&lt;a href=&quot;#多播-multicast&quot; class=&quot;headerlink&quot; title=&quot;多播(multicast)&quot;&gt;&lt;/a&gt;多播(multicast)&lt;/h3&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;可以说广播是多播的特例，多播就是给一组特定的主机（多播组）发送数据，这样，数据的播发范围会小一些(实际上播发的范围一点也没有变小)，多播的MAC地址是最高字节的低位为一，例 如01-00-00-00-00-00。多播组的地址是D类IP，规定是224.0.0.0-239.255.255.255。  &lt;/li&gt;
&lt;li&gt;虽然多播比较特殊，但是究其原理，多播的数据还是要通过数据链路层进行MAC地址绑定然后进行发送。所以一个以太网卡在绑定了一个多播IP地址之后，必 定还要绑定一个多播的MAC地址，才能使得其可以像单播那样工作。这个多播的IP和多播MAC地址有一个对应的算法，在书的p133到p134之间。可以看到 这个对应不是一一对应的，主机还是要对多播数据进行过滤。  &lt;/li&gt;
&lt;li&gt;个人觉得：广播和多播的性质是一样的，路由器会把数据放到局域网里面，然后网卡对这些数据进行过滤，只拿到自己打算要的数据，比如自己感兴趣的多 播数据，自己感兴趣的组播数据。当一个主机运行了一个处理某一个多播IP的进程的时候，这个进程会给网卡绑定一个虚拟的多播mac地址，并做出来一个多播 ip。这样，网卡就会让带有这个多播mac地址的数据进来，从而实现通信，而那些没有监听这些数据的主机就会把这些数据过滤掉。&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;IGMP协议&quot;&gt;&lt;a href=&quot;#IGMP协议&quot; class=&quot;headerlink&quot; title=&quot;IGMP协议&quot;&gt;&lt;/a&gt;IGMP协议&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;IGMP的作用在于，让其他所有需要知道自己处于哪个多播组的主机和路由器知道自己的状态。一般多播路由器根本不需要知道某一个多播组里面有多少个主机，而只要知道自己的子网内还有没有处于某个多播组的主机就可以了。只要某一个多播组还有一台主机，多播路由器就会把数据传输出去，这样，接受方就会通过网卡过滤功能来得到自己想要的数据。为了知道多播组的信息，多播路由器需要定时的发送IGMP查询，IGMP的格式可以看书，各个多播组里面的主机要根据查询来回复自己的状态。路由器来决定有几个多播组，自己要对某一个多播组发送什么样的数据。&lt;/p&gt;
&lt;/blockquote&gt;
</content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;单播-unicast&quot;&gt;&lt;a href=&quot;#单播-unicast&quot; class=&quot;headerlink&quot; title=&quot;单播(unicast)&quot;&gt;&lt;/a&gt;单播(unicast)&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;单播是说，对特定的主机进行数据传送。例如给某一个主机发送IP数据包。&lt;br&gt;这时候，数据链路层给出的数据头里面是非常具体的目的地址，对于以太网来 说，&lt;br&gt;就是网卡的MAC地址（不是FF-FF-FF-FF-FF-FF这样的地址）。&lt;br&gt;现在的具有路由功能的主机应该可以将单播数据定向转发，&lt;br&gt;而目的主机的网络接口则可以过滤掉和自己MAC地址不一致的数据。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="网络" scheme="https://iceziyao.github.io/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="tcp" scheme="https://iceziyao.github.io/tags/tcp/"/>
    
  </entry>
  
  <entry>
    <title>IP协议,ARP协议和RARP协议</title>
    <link href="https://iceziyao.github.io/2015/12/04/Net/tcp3/"/>
    <id>https://iceziyao.github.io/2015/12/04/Net/tcp3/</id>
    <published>2015-12-03T16:00:00.000Z</published>
    <updated>2016-08-06T14:49:45.957Z</updated>
    
    <content type="html">&lt;h2 id=&quot;网络层&quot;&gt;&lt;a href=&quot;#网络层&quot; class=&quot;headerlink&quot; title=&quot;网络层&quot;&gt;&lt;/a&gt;网络层&lt;/h2&gt;&lt;p&gt;把这三个协议放到一起学习是因为这三个协议处于同一层，ARP协议用来找到目标主机的Ethernet网卡Mac地址，IP则承载要发送的消息。数据链路层可以从ARP得到数据的传送信息，而从IP得到要传输的数据信息。&lt;/p&gt;
&lt;h2 id=&quot;IP&quot;&gt;&lt;a href=&quot;#IP&quot; class=&quot;headerlink&quot; title=&quot;IP&quot;&gt;&lt;/a&gt;IP&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;IP协议&lt;br&gt;IP协议是TCP/IP协议族中最为核心的协议。它提供不可靠、无连接的服务，也即依赖其他层的协议进行差错控制。在局域网环境，IP协议往往被封装在以太网帧中传送。而所有的TCP、UDP、ICMP、IGMP数据都被封装在IP数据报中传送&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Ethemet帧头 | IP头部 | TCP头部 | 上层数据 | FCS  &lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;IP路由选择&lt;br&gt;当一个IP数据包准备好了的时候，IP数据包(或者说是路由器)是如何将数据包送到目的地的呢?它是怎么选择一个合适的路径来”送货”的呢?&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;最特殊的情况是目的主机和主机直连，那么主机根本不用寻找路由，直接把数据传递过去就可以了。至于是怎么直接传递的，这就要靠ARP协议了，后面会讲到。&lt;/li&gt;
&lt;li&gt;稍微一般一点的情况是，主机通过若干个路由器(router)和目的主机连接。那么路由器就要通过ip包的信息来为ip包寻找到一个合适的目标来进行传递，比如合适的主机，或者合适的路由。路由器或者主机将会用如下的方式来处理某一个IP数据包&lt;/li&gt;
&lt;li&gt;如果IP数据包的TTL(生命周期)以到，则该IP数据包就被抛弃。&lt;/li&gt;
&lt;li&gt;搜索路由表，优先搜索匹配主机，如果能找到和IP地址完全一致的目标主机，则将该包发向目标主机&lt;/li&gt;
&lt;li&gt;搜索路由表，如果匹配主机失败，则匹配同子网的路由器，这需要“子网掩码(1.3.)”的协助。如果找到路由器，则将该包发向路由器。&lt;ul&gt;
&lt;li&gt;搜索路由表，如果匹配同子网路由器失败，则匹配同网号(第一章有讲解)路由器，如果找到路由器，则将该包发向路由器。&lt;/li&gt;
&lt;li&gt;搜索陆游表，如果以上都失败了，就搜索默认路由，如果默认路由存在，则发包  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果都失败了，就丢掉这个包。&lt;br&gt;&lt;strong&gt;这再一次证明了，ip包是不可靠的。因为它不保证送达。&lt;/strong&gt;  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;子网寻址&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;IP地址的定义是网络号+主机号。但是现在所有的主机都要求子网编址，也就是说，把主机号在细分成子网号+主机号。最终一个IP地址就成为 网络号码+子网号+主机号。例如一个B类地址：210.30.109.134。一般情况下，这个IP地址的红色部分就是网络号，而蓝色部分就是子网号，绿色部分就是主机号。至于有多少位代表子网号这个问题上，这没有一个硬性的规定，取而代之的则是子网掩码，校园网相信大多数人都用过，在校园网的设定里面有一个255.255.255.0的东西，这就是子网掩码。子网掩码是由32bit的二进制数字序列,形式为是一连串的1和一连串的0，例如：255.255.255.0(二进制就是11111111.11111111.11111111.00000000)对于刚才的那个B类地址，因为210.30是网络号，那么后面的109.134就是子网号和主机号的组合，又因为子网掩码只有后八bit为0，所以主机号就是IP地址的后八个bit，就是134，而剩下的就是子网号码–109。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;ARP协议&quot;&gt;&lt;a href=&quot;#ARP协议&quot; class=&quot;headerlink&quot; title=&quot;ARP协议&quot;&gt;&lt;/a&gt;ARP协议&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;数据链路层的以太网的协议中，每一个数据包都有一个MAC地址头么?我们知道每一块以太网卡都有一个MAC地址，这个地址是唯一的，那么IP包是如何知道这个MAC地址的?这就是ARP协议的工作。  &lt;/li&gt;
&lt;li&gt;ARP(地址解析)协议是一种解析协议，本来主机是完全不知道这个IP对应的是哪个主机的哪个接口，当主机要发送一个IP包的时候，会首先查一下自己的ARP高速缓存(就是一个IP-MAC地址对应表缓存)，如果查询的IP-MAC值对不存在，那么主机就向网络发送一个ARP协议广播包，这个广播包里面就有待查询的IP地址，而直接收到这份广播的包的所有主机都会查询自己的IP地址，如果收到广播包的某一个主机发现自己符合条件，那么就准备好一个包含自己的MAC地址的ARP包传送给发送ARP广播的主机，而广播主机拿到ARP包后会更新自己的ARP缓存(就是存放IP-MAC对应表的地方)。发送广播的主机就会用新的ARP缓存数据准备好数据链路层的的数据包发送工作。   &lt;/li&gt;
&lt;li&gt;一个典型的arp缓存信息如下，在任意一个系统里面用“arp -a”命令就可以看到&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;RARP协议&quot;&gt;&lt;a href=&quot;#RARP协议&quot; class=&quot;headerlink&quot; title=&quot;RARP协议&quot;&gt;&lt;/a&gt;RARP协议&lt;/h2&gt;&lt;p&gt;反向地址转换协议（RARP：Reverse Address Resolution Protocol） 反向地址转换协议（RARP）允许局域网的物理机器从网关服务器的 ARP 表或者缓存上请求其 IP 地址。网络管理员在局域网网关路由器里创建一个表以映射物理地址（MAC）和与其对应的 IP 地址。当设置一台新的机器时，其 RARP 客户机程序需要向路由器上的 RARP 服务器请求相应的 IP 地址。假设在路由表中已经设置了一个记录，RARP 服务器将会返回 IP 地址给机器，此机器就会存储起来以便日后使用。  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;工作原理  &lt;blockquote&gt;
&lt;p&gt;1、网络上的每台设备都会有一个独一无二的硬件地址，通常是由设备厂商分配的MAC地址。PC1从网卡上读取MAC地址，然后在网络上发送一个RARP请求的广播数据包，请求RARP服务器回复该PC的IP地址。&lt;br&gt;2、RARP服务器收到了RARP请求数据包，为其分配IP地址，并将RARP回应发送给PC1。&lt;br&gt;3、PC1收到RARP回应后，就使用得到的IP地址进行通讯。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;网络层&quot;&gt;&lt;a href=&quot;#网络层&quot; class=&quot;headerlink&quot; title=&quot;网络层&quot;&gt;&lt;/a&gt;网络层&lt;/h2&gt;&lt;p&gt;把这三个协议放到一起学习是因为这三个协议处于同一层，ARP协议用来找到目标主机的Ethernet网卡Mac地址，IP则承载要发送的消息。数据链路层可以从ARP得到数据的传送信息，而从IP得到要传输的数据信息。&lt;/p&gt;
&lt;h2 id=&quot;IP&quot;&gt;&lt;a href=&quot;#IP&quot; class=&quot;headerlink&quot; title=&quot;IP&quot;&gt;&lt;/a&gt;IP&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;IP协议&lt;br&gt;IP协议是TCP/IP协议族中最为核心的协议。它提供不可靠、无连接的服务，也即依赖其他层的协议进行差错控制。在局域网环境，IP协议往往被封装在以太网帧中传送。而所有的TCP、UDP、ICMP、IGMP数据都被封装在IP数据报中传送&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Ethemet帧头 | IP头部 | TCP头部 | 上层数据 | FCS  &lt;/p&gt;
    
    </summary>
    
      <category term="网络" scheme="https://iceziyao.github.io/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="tcp" scheme="https://iceziyao.github.io/tags/tcp/"/>
    
  </entry>
  
  <entry>
    <title>数据链路层</title>
    <link href="https://iceziyao.github.io/2015/12/03/Net/tcp2/"/>
    <id>https://iceziyao.github.io/2015/12/03/Net/tcp2/</id>
    <published>2015-12-02T16:00:00.000Z</published>
    <updated>2016-08-06T14:49:43.679Z</updated>
    
    <content type="html">&lt;h2 id=&quot;数据链路层&quot;&gt;&lt;a href=&quot;#数据链路层&quot; class=&quot;headerlink&quot; title=&quot;数据链路层&quot;&gt;&lt;/a&gt;数据链路层&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;为IP模块发送和 接收IP数据报。&lt;/li&gt;
&lt;li&gt;为ARP模块发送ARP请求和接收ARP应答。&lt;/li&gt;
&lt;li&gt;为RARP发送RARP请 求和接收RARP应答&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;数据链路层的协议还是很多的，有我们最常用的以太网（就是平时我们用的网卡）协议，也有不太常见的令牌环，还有FDDI，当然，还有国内现在相当普及的PPP协议（就是adsl宽带），以及一个loopback协议。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;详解&quot;&gt;&lt;a href=&quot;#详解&quot; class=&quot;headerlink&quot; title=&quot;详解&quot;&gt;&lt;/a&gt;详解&lt;/h2&gt;&lt;p&gt;linux里面的ifconfig -a命令&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;eth0: flags=4099&amp;lt;UP,BROADCAST,MULTICAST&amp;gt;  mtu 1500&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;ether e0:3f:49:34:3a:1f  txqueuelen 1000  (Ethernet)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;RX packets 0  bytes 0 (0.0 B)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;RX errors 0  dropped 0  overruns 0  frame 0&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;TX packets 0  bytes 0 (0.0 B)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;device interrupt 18&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;+shell&quot;&gt;lo: flags=73&amp;lt;UP,LOOPBACK,RUNNING&amp;gt;  mtu 65536
        inet 127.0.0.1  netmask 255.0.0.0
        inet6 ::1  prefixlen 128  scopeid 0x10&amp;lt;host&amp;gt;
        loop  txqueuelen 0  (Local Loopback)
        RX packets 10099  bytes 4444181 (4.2 MiB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 10099  bytes 4444181 (4.2 MiB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;以太网接口&quot;&gt;&lt;a href=&quot;#以太网接口&quot; class=&quot;headerlink&quot; title=&quot;以太网接口&quot;&gt;&lt;/a&gt;以太网接口&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;其中，eth0就是以太网接口，而lo则是loopback接口。这也说明这个主机在网络链路层上至少支持loopback协议和以太网协议。&lt;/p&gt;
&lt;p&gt;以太网（Ether-net）的定是指数字设备公司（ Digital Equipment Corp.）、英特尔公司（Intel Corp.）和Xerox公司在1982年联合公布的一个标准，这个标准里面使用了一种称作CSMA/CD的接入方法。而IEEE802提供的标准集802.3(还有一部分定义到了802.2中)也提供了一个CSMA/CD的标准。这两个标准稍有不同，TCP/IP协议对这种情况的处理方式如下:&lt;br&gt;&amp;gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;以太网的IP数据报封装在RFC894中定义，而IEEE802网络的IP数据报封装在RFC1042中定义。  &lt;/li&gt;
&lt;li&gt;一台主机一定要能发送和接收RFC894定义的数据报。&lt;br&gt;一台主机可以接收RFC894和RFC1042的封装格式的混合数据报。&lt;br&gt;一台主机也许能够发送RFC1042数据报。&lt;br&gt; 如果主机能同时发送两种类型的分组数据，&lt;br&gt; 那么发送的分组必须是可以设置的，&lt;br&gt; 而且默认条件下必须是RFC 894分组。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;ppp(点对点协议)是从SLIP的替代品。他们都提供了一种低速接入的解决方案。而每一种数据链路层协议，都有一个MTU（最大传输单元）定义，在这个定义下面，如果IP数据报过大，则要进行分片(fragmentation)，使得每片都小于MTU，注意PPP的MTU并不是一个物理定义，而是指一个逻辑定义。可以用netstat来打印出MTU的结果，比如键入netstat -in  &lt;pre&gt;&lt;code class=&quot;+shell&quot;&gt;Kernel Interface table
Iface      MTU    RX-OK RX-ERR RX-DRP RX-OVR    TX-OK TX-ERR TX-DRP TX-OVR Flg
eth0    1500        0      0      0 0             0      0      0      0 BMU
lo       65536    10103      0      0 0         10103      0      0      0 LRU
&lt;/code&gt;&lt;/pre&gt;
就可以观察到eth0的MTU是1500。而lo（环回接口）的MTU则是65536。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;环回接口（loopback）&quot;&gt;&lt;a href=&quot;#环回接口（loopback）&quot; class=&quot;headerlink&quot; title=&quot;环回接口（loopback）&quot;&gt;&lt;/a&gt;环回接口（loopback）&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;对于环回接口，有如下三点值得注意:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;传给环回地址（一般是127.0.0.1）的任何数据均作为I P输入。&lt;/li&gt;
&lt;li&gt;传给广播地址或多播地址的数据报复制一份传给环回接口，然后送到以太网上。这是 因为广播传送和多播传送的定义包含主机本身。&lt;/li&gt;
&lt;li&gt;任何传给该主机IP地址的数据均送到环回接口。&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;数据链路层&quot;&gt;&lt;a href=&quot;#数据链路层&quot; class=&quot;headerlink&quot; title=&quot;数据链路层&quot;&gt;&lt;/a&gt;数据链路层&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;为IP模块发送和 接收IP数据报。&lt;/li&gt;
&lt;li&gt;为ARP模块发送ARP请求和接收ARP应答。&lt;/li&gt;
&lt;li&gt;为RARP发送RARP请 求和接收RARP应答&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;数据链路层的协议还是很多的，有我们最常用的以太网（就是平时我们用的网卡）协议，也有不太常见的令牌环，还有FDDI，当然，还有国内现在相当普及的PPP协议（就是adsl宽带），以及一个loopback协议。&lt;br&gt;
    
    </summary>
    
      <category term="网络" scheme="https://iceziyao.github.io/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="tcp" scheme="https://iceziyao.github.io/tags/tcp/"/>
    
  </entry>
  
</feed>
